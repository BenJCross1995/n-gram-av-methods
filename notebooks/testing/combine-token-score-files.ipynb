{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9077c148",
   "metadata": {},
   "source": [
    "# Combine Token Score Files\n",
    "\n",
    "This notebook is for combining files already grouped into token size level scores into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32b92deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b15de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gemma-3-270m\", \"gpt2\", \"Qwen2.5-0.5B-Instruct\", \"Qwen2.5-1.5B-Instruct\"]\n",
    "\n",
    "corpuses = [\"Wiki\", \"Perverted Justice\", \"Enron\", \"ACL\", \"StackExchange\", \"TripAdvisor\"]\n",
    "\n",
    "data_types = [\"training\", \"test\"]\n",
    "\n",
    "base_loc = \"/Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs\"\n",
    "\n",
    "file_name = \"token_level_raw_scores.xlsx\"\n",
    "\n",
    "agg_file_name = \"raw_aggregated_scores.xlsx\"\n",
    "\n",
    "metadata_file_name = \"raw_problem_completed_metadata.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc7b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agg_problem_scores(\n",
    "    score_df: pd.DataFrame,\n",
    "    group_cols: list[str] | None = None,\n",
    "    sum_cols: list[str] | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate per-row scores up to the problem level by summing selected columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    score_df : pd.DataFrame\n",
    "        Input table with grouping columns + score columns.\n",
    "    group_cols : list[str], optional\n",
    "        Columns to group by. Defaults to the common set you described.\n",
    "    sum_cols : list[str], optional\n",
    "        Numeric columns to sum. Defaults to the three you listed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Grouped/aggregated DataFrame with summed score columns.\n",
    "    \"\"\"\n",
    "    if group_cols is None:\n",
    "        group_cols = [\"data_type\", \"corpus\", \"scoring_model\", \"problem\", \"target\", \"min_token_size\"]\n",
    "\n",
    "    if sum_cols is None:\n",
    "        sum_cols = [\"no_context_sum_log_probs\", \"known_sum_log_probs\", \"unknown_sum_log_probs\"]\n",
    "\n",
    "    missing_g = [c for c in group_cols if c not in score_df.columns]\n",
    "    missing_s = [c for c in sum_cols if c not in score_df.columns]\n",
    "    if missing_g or missing_s:\n",
    "        raise KeyError(\n",
    "            f\"Missing columns. group_cols missing={missing_g}; sum_cols missing={missing_s}\"\n",
    "        )\n",
    "\n",
    "    # Ensure sum columns are numeric-ish (coerce bad strings to NaN, then treat NaN as 0 for sums)\n",
    "    df = score_df.copy()\n",
    "    for c in sum_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    out = (\n",
    "        df.groupby(group_cols, dropna=False)[sum_cols]\n",
    "          .sum(min_count=1)          # if a group is all-NaN for a col, keep NaN (not 0)\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aab8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_token_level_files(\n",
    "    base_loc: str | Path,\n",
    "    file_name: str,\n",
    "    metadata_file_name: str,\n",
    "    aggregated_scores_file_name: str,\n",
    "    data_types: list[str],\n",
    "    corpuses: list[str],\n",
    "    models: list[str],\n",
    "    return_df: Literal=False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read token-level excel files from:\n",
    "        {base_loc}/{data_type}/{corpus}/{model}/{file_name}\n",
    "    Combine them, then save to:\n",
    "        {base_loc}/{file_name}\n",
    "\n",
    "    Skips missing input files.\n",
    "    Always overwrites the output file.\n",
    "    Returns the combined dataframe.\n",
    "    \"\"\"\n",
    "    base_loc = Path(base_loc)\n",
    "    out_path = base_loc / file_name\n",
    "    metadata_out_path = base_loc / metadata_file_name\n",
    "    agg_scores_out_path = base_loc / aggregated_scores_file_name\n",
    "\n",
    "    combined = []\n",
    "    combined_metadata = []\n",
    "    \n",
    "    for data_type in data_types:\n",
    "        for corpus in corpuses:\n",
    "            for model in models:\n",
    "                file_loc = base_loc / data_type / corpus / model / file_name\n",
    "                metadata_file_loc = base_loc / data_type / corpus / model / metadata_file_name\n",
    "                \n",
    "                # Normal score file first\n",
    "                if not file_loc.exists():\n",
    "                    print(f\"SKIP (missing): {file_loc}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    df = pd.read_excel(file_loc)\n",
    "                    combined.append(df)\n",
    "                    print(f\"READ: {file_loc}  (rows={len(df)})\")\n",
    "                except Exception as e:\n",
    "                    print(f\"WARN: failed reading {file_loc}: {e}\")\n",
    "\n",
    "                # Now metadata score file\n",
    "                if not metadata_file_loc.exists():\n",
    "                    print(f\"SKIP (missing): {file_loc}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    meta_df = pd.read_excel(metadata_file_loc)\n",
    "                    combined_metadata.append(meta_df)\n",
    "                    print(f\"READ: {metadata_file_loc}  (rows={len(df)})\")\n",
    "                except Exception as e:\n",
    "                    print(f\"WARN: failed reading {metadata_file_loc}: {e}\")                   \n",
    "                \n",
    "    if not combined:\n",
    "        raise RuntimeError(\"No readable input files found; nothing to combine.\")\n",
    "\n",
    "    results = (\n",
    "        pd.concat(combined, ignore_index=True)\n",
    "        .sort_values(\n",
    "            [\"data_type\", \"corpus\", \"scoring_model\", \"sample_id\", \"min_token_size\"],\n",
    "            ascending=[True, True, True, True, True],\n",
    "            kind=\"mergesort\"\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    agg_results = create_agg_problem_scores(results)\n",
    "    \n",
    "    meta = (\n",
    "        pd.concat(combined_metadata, ignore_index=True)\n",
    "        .sort_values(\n",
    "            [\"data_type\", \"corpus\", \"scoring_model\"],\n",
    "            ascending=[True, True, True],\n",
    "            kind=\"mergesort\"\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if out_path.exists():\n",
    "        print(f\"OVERWRITE: {out_path}\")\n",
    "\n",
    "    results.to_excel(out_path, index=False)\n",
    "    print(f\"SAVED: {out_path}  (rows={len(results)})\")\n",
    "\n",
    "    agg_results.to_excel(agg_scores_out_path, index=False)\n",
    "    print(f\"SAVED: {agg_scores_out_path}  (rows={len(agg_results)})\")\n",
    "    \n",
    "    meta.to_excel(metadata_out_path, index=False)\n",
    "    print(f\"SAVED: {metadata_out_path}  (rows={len(meta)})\")\n",
    "    \n",
    "    if return_df:\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "852607e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/gemma-3-270m/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/gpt2/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/Qwen2.5-0.5B-Instruct/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/Qwen2.5-1.5B-Instruct/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/gemma-3-270m/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/gpt2/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/Qwen2.5-0.5B-Instruct/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/Qwen2.5-1.5B-Instruct/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/gemma-3-270m/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/gpt2/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/Qwen2.5-0.5B-Instruct/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/Qwen2.5-1.5B-Instruct/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/gemma-3-270m/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/gpt2/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/Qwen2.5-0.5B-Instruct/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/Qwen2.5-1.5B-Instruct/token_level_raw_scores.xlsx\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gemma-3-270m/token_level_raw_scores.xlsx  (rows=2086)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gemma-3-270m/raw_problem_completed_metadata.xlsx  (rows=2086)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/token_level_raw_scores.xlsx  (rows=1973)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/raw_problem_completed_metadata.xlsx  (rows=1973)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/Qwen2.5-0.5B-Instruct/token_level_raw_scores.xlsx  (rows=1606)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/Qwen2.5-0.5B-Instruct/raw_problem_completed_metadata.xlsx  (rows=1606)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/Qwen2.5-1.5B-Instruct/token_level_raw_scores.xlsx  (rows=1606)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/Qwen2.5-1.5B-Instruct/raw_problem_completed_metadata.xlsx  (rows=1606)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gemma-3-270m/token_level_raw_scores.xlsx  (rows=1864)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gemma-3-270m/raw_problem_completed_metadata.xlsx  (rows=1864)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/token_level_raw_scores.xlsx  (rows=1513)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/raw_problem_completed_metadata.xlsx  (rows=1513)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/Qwen2.5-0.5B-Instruct/token_level_raw_scores.xlsx  (rows=1721)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/Qwen2.5-0.5B-Instruct/raw_problem_completed_metadata.xlsx  (rows=1721)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/Qwen2.5-1.5B-Instruct/token_level_raw_scores.xlsx  (rows=1721)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/Qwen2.5-1.5B-Instruct/raw_problem_completed_metadata.xlsx  (rows=1721)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gemma-3-270m/token_level_raw_scores.xlsx  (rows=1237)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gemma-3-270m/raw_problem_completed_metadata.xlsx  (rows=1237)\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gpt2/token_level_raw_scores.xlsx\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/Qwen2.5-0.5B-Instruct/token_level_raw_scores.xlsx  (rows=1202)\n",
      "READ: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/Qwen2.5-0.5B-Instruct/raw_problem_completed_metadata.xlsx  (rows=1202)\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/Qwen2.5-1.5B-Instruct/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/gemma-3-270m/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/gpt2/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/Qwen2.5-0.5B-Instruct/token_level_raw_scores.xlsx\n",
      "SKIP (missing): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/Qwen2.5-1.5B-Instruct/token_level_raw_scores.xlsx\n",
      "OVERWRITE: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/token_level_raw_scores.xlsx\n",
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/token_level_raw_scores.xlsx  (rows=16529)\n",
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/raw_aggregated_scores.xlsx  (rows=8220)\n",
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/raw_problem_completed_metadata.xlsx  (rows=2336)\n"
     ]
    }
   ],
   "source": [
    "combine_token_level_files(\n",
    "    base_loc=base_loc,\n",
    "    file_name=file_name,\n",
    "    metadata_file_name=metadata_file_name,\n",
    "    aggregated_scores_file_name=agg_file_name,\n",
    "    data_types=data_types,\n",
    "    corpuses=corpuses,\n",
    "    models=models,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
