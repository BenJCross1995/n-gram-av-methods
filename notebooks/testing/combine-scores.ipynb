{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e9aff6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Union, List\n",
    "from from_root import from_root\n",
    "\n",
    "sys.path.insert(0, str(from_root(\"src\")))\n",
    "\n",
    "from read_and_write_docs import read_excel_sheets, read_rds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "2c921685",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gemma-3-270m\", \"gpt2\", \"Qwen2.5-0.5B-Instruct\", \"Qwen2.5-1.5B-Instruct\"]\n",
    "\n",
    "corpuses = [\"Wiki\", \"Perverted Justice\"]\n",
    "\n",
    "data_types = [\"training\", \"test\"]\n",
    "\n",
    "base_loc = \"/Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs\"\n",
    "\n",
    "metadata_base_loc = \"/Volumes/BCross/datasets/author_verification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "48aa9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_by_corpus_dt = {\n",
    "    (\"Wiki\", \"training\"): 5000,\n",
    "    (\"Wiki\", \"test\"): 672,\n",
    "    (\"Perverted Justice\", \"training\"): 3000,\n",
    "    (\"Perverted Justice\", \"test\"): 574,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "5ca3e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_xlsx_files(\n",
    "    directory: Union[str, Path],\n",
    "    *,\n",
    "    recursive: bool = False,\n",
    "    include_temp: bool = False,\n",
    "    sort: bool = True,\n",
    ") -> List[Path]:\n",
    "    \"\"\"\n",
    "    Return all .xlsx files in a directory as a list of Paths.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : str | Path\n",
    "        Directory to search.\n",
    "    recursive : bool\n",
    "        If True, search subdirectories too.\n",
    "    include_temp : bool\n",
    "        If True, include Excel temp files like \"~$something.xlsx\".\n",
    "    sort : bool\n",
    "        If True, sort results by path.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[Path]\n",
    "        Paths to .xlsx files.\n",
    "    \"\"\"\n",
    "    directory = Path(directory)\n",
    "    if not directory.exists():\n",
    "        raise FileNotFoundError(f\"Directory not found: {directory}\")\n",
    "    if not directory.is_dir():\n",
    "        raise NotADirectoryError(f\"Not a directory: {directory}\")\n",
    "\n",
    "    pattern = \"**/*.xlsx\" if recursive else \"*.xlsx\"\n",
    "    files = list(directory.glob(pattern))\n",
    "\n",
    "    if not include_temp:\n",
    "        files = [p for p in files if not p.name.startswith(\"~$\")]\n",
    "\n",
    "    if sort:\n",
    "        files = sorted(files)\n",
    "\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0f32f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_counts_to_expected_map(base_loc, data_types, corpuses, models, expected_by_corpus_dt, *, recursive=False):\n",
    "    \"\"\"\n",
    "    Compare actual .xlsx counts on disk vs expected counts (expected varies by (corpus, data_type)).\n",
    "    Assumes directory layout: {base_loc}/{data_type}/{corpus}/{model}/raw\n",
    "    \"\"\"\n",
    "    base_loc = Path(base_loc)\n",
    "    rows = []\n",
    "\n",
    "    for data_type in data_types:\n",
    "        for corpus in corpuses:\n",
    "            expected = expected_by_corpus_dt.get((corpus, data_type), None)\n",
    "\n",
    "            for model in models:\n",
    "                data_loc = base_loc / data_type / corpus / model / \"raw\"\n",
    "\n",
    "                if data_loc.exists():\n",
    "                    actual = len(list_xlsx_files(data_loc, recursive=recursive))\n",
    "                else:\n",
    "                    actual = 0\n",
    "\n",
    "                delta = (actual - expected) if expected is not None else None\n",
    "\n",
    "                rows.append({\n",
    "                    \"data_type\": data_type,\n",
    "                    \"corpus\": corpus,\n",
    "                    \"model\": model,\n",
    "                    \"expected_num_files\": expected,\n",
    "                    \"actual_num_files\": actual,\n",
    "                    \"delta\": delta,\n",
    "                    \"missing\": (expected - actual) if expected is not None and actual < expected else 0 if expected is not None else None,\n",
    "                    \"extra\": (actual - expected) if expected is not None and actual > expected else 0 if expected is not None else None,\n",
    "                    \"status\": (\n",
    "                        \"NOT_STARTED\" if expected is not None and actual == 0\n",
    "                        else \"COMPLETED\" if expected is not None and actual == expected\n",
    "                        else \"MISSING\" if expected is not None and actual < expected\n",
    "                        else \"EXTRA\" if expected is not None and actual > expected\n",
    "                        else \"NO_EXPECTATION\"\n",
    "                    ),\n",
    "                })\n",
    "\n",
    "    df = (\n",
    "        pd.DataFrame(rows)\n",
    "        .sort_values([\"data_type\", \"corpus\", \"model\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Handy lookup: (data_type, corpus, model) -> row dict\n",
    "    lookup = {\n",
    "        (r.data_type, r.corpus, r.model): r._asdict()\n",
    "        for r in df.itertuples(index=False)\n",
    "    }\n",
    "\n",
    "    return df, lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "9b3c2f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_df, actual_lookup = compare_counts_to_expected_map(base_loc, data_types, corpuses, models, expected_by_corpus_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "6f0bd6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_type</th>\n",
       "      <th>corpus</th>\n",
       "      <th>model</th>\n",
       "      <th>expected_num_files</th>\n",
       "      <th>actual_num_files</th>\n",
       "      <th>delta</th>\n",
       "      <th>missing</th>\n",
       "      <th>extra</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>Perverted Justice</td>\n",
       "      <td>Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>Perverted Justice</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>Perverted Justice</td>\n",
       "      <td>gemma-3-270m</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>Perverted Justice</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>574</td>\n",
       "      <td>491</td>\n",
       "      <td>-83</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>MISSING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>gemma-3-270m</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>training</td>\n",
       "      <td>Perverted Justice</td>\n",
       "      <td>Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>-3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>NOT_STARTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>training</td>\n",
       "      <td>Perverted Justice</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>-3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>NOT_STARTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>training</td>\n",
       "      <td>Perverted Justice</td>\n",
       "      <td>gemma-3-270m</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>-3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>NOT_STARTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>training</td>\n",
       "      <td>Perverted Justice</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>-3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>NOT_STARTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>training</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>-5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>NOT_STARTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>training</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>-5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>NOT_STARTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>training</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>gemma-3-270m</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>-5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>NOT_STARTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>training</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>-5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>NOT_STARTED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_type             corpus                  model  expected_num_files  actual_num_files  delta  missing  extra  \\\n",
       "0       test  Perverted Justice  Qwen2.5-0.5B-Instruct                 574               574      0        0      0   \n",
       "1       test  Perverted Justice  Qwen2.5-1.5B-Instruct                 574               574      0        0      0   \n",
       "2       test  Perverted Justice           gemma-3-270m                 574               574      0        0      0   \n",
       "3       test  Perverted Justice                   gpt2                 574               491    -83       83      0   \n",
       "4       test               Wiki  Qwen2.5-0.5B-Instruct                 672               672      0        0      0   \n",
       "5       test               Wiki  Qwen2.5-1.5B-Instruct                 672               672      0        0      0   \n",
       "6       test               Wiki           gemma-3-270m                 672               672      0        0      0   \n",
       "7       test               Wiki                   gpt2                 672               672      0        0      0   \n",
       "8   training  Perverted Justice  Qwen2.5-0.5B-Instruct                3000                 0  -3000     3000      0   \n",
       "9   training  Perverted Justice  Qwen2.5-1.5B-Instruct                3000                 0  -3000     3000      0   \n",
       "10  training  Perverted Justice           gemma-3-270m                3000                 0  -3000     3000      0   \n",
       "11  training  Perverted Justice                   gpt2                3000                 0  -3000     3000      0   \n",
       "12  training               Wiki  Qwen2.5-0.5B-Instruct                5000                 0  -5000     5000      0   \n",
       "13  training               Wiki  Qwen2.5-1.5B-Instruct                5000                 0  -5000     5000      0   \n",
       "14  training               Wiki           gemma-3-270m                5000                 0  -5000     5000      0   \n",
       "15  training               Wiki                   gpt2                5000                 0  -5000     5000      0   \n",
       "\n",
       "         status  \n",
       "0     COMPLETED  \n",
       "1     COMPLETED  \n",
       "2     COMPLETED  \n",
       "3       MISSING  \n",
       "4     COMPLETED  \n",
       "5     COMPLETED  \n",
       "6     COMPLETED  \n",
       "7     COMPLETED  \n",
       "8   NOT_STARTED  \n",
       "9   NOT_STARTED  \n",
       "10  NOT_STARTED  \n",
       "11  NOT_STARTED  \n",
       "12  NOT_STARTED  \n",
       "13  NOT_STARTED  \n",
       "14  NOT_STARTED  \n",
       "15  NOT_STARTED  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "472d2fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_type</th>\n",
       "      <th>corpus</th>\n",
       "      <th>model</th>\n",
       "      <th>expected_num_files</th>\n",
       "      <th>actual_num_files</th>\n",
       "      <th>delta</th>\n",
       "      <th>missing</th>\n",
       "      <th>extra</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>Perverted Justice</td>\n",
       "      <td>Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>Perverted Justice</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>Perverted Justice</td>\n",
       "      <td>gemma-3-270m</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>Qwen2.5-1.5B-Instruct</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>gemma-3-270m</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>672</td>\n",
       "      <td>672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_type             corpus                  model  expected_num_files  actual_num_files  delta  missing  extra     status\n",
       "0      test  Perverted Justice  Qwen2.5-0.5B-Instruct                 574               574      0        0      0  COMPLETED\n",
       "1      test  Perverted Justice  Qwen2.5-1.5B-Instruct                 574               574      0        0      0  COMPLETED\n",
       "2      test  Perverted Justice           gemma-3-270m                 574               574      0        0      0  COMPLETED\n",
       "4      test               Wiki  Qwen2.5-0.5B-Instruct                 672               672      0        0      0  COMPLETED\n",
       "5      test               Wiki  Qwen2.5-1.5B-Instruct                 672               672      0        0      0  COMPLETED\n",
       "6      test               Wiki           gemma-3-270m                 672               672      0        0      0  COMPLETED\n",
       "7      test               Wiki                   gpt2                 672               672      0        0      0  COMPLETED"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completed_data = actual_df[actual_df['status'] == 'COMPLETED']\n",
    "completed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "8cb95d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_complete_to_metadata(metadata_base_loc, data_type, corpus, model, excel_files):\n",
    "    \n",
    "    metadata_loc = f\"{metadata_base_loc}/{data_type}/doc_level_metadata.rds\"\n",
    "    \n",
    "    metadata = read_rds(metadata_loc)\n",
    "    metadata = metadata[metadata['corpus'] == corpus]\n",
    "    metadata['scoring_model'] = model\n",
    "    \n",
    "    file_names = [ef.name for ef in excel_files]\n",
    "    # df with filename + completed=True\n",
    "    df = pd.DataFrame({\n",
    "        \"filename\": file_names,\n",
    "        \"completed\": True\n",
    "    })\n",
    "\n",
    "    # left join onto metadata_df and fill missing completed with False\n",
    "    metadata_df = (\n",
    "        metadata\n",
    "        .merge(df, on=\"filename\", how=\"left\")\n",
    "    )\n",
    "\n",
    "    metadata_df[\"completed\"] = metadata_df[\"completed\"].fillna(False).astype(bool)\n",
    "    metadata_df[\"scored\"] = False\n",
    "    \n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "3317d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_problem_complete_metadata(metadata: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Groups by (data_type, corpus, scoring_model, problem) and returns:\n",
    "      - num_files: total rows\n",
    "      - files_completed: count where completed == True\n",
    "      - files_scored: count where scored == True\n",
    "      - problem_completed: True if num_files == files_scored\n",
    "    \"\"\"\n",
    "    group_cols = [\"data_type\", \"corpus\", \"scoring_model\", \"problem\"]\n",
    "\n",
    "    out = (\n",
    "        metadata\n",
    "        .groupby(group_cols, dropna=False)\n",
    "        .agg(\n",
    "            num_files=(\"filename\", \"size\"),\n",
    "            files_completed=(\"completed\", lambda s: int(s.fillna(False).astype(bool).sum())),\n",
    "            files_scored=(\"scored\", lambda s: int(s.fillna(False).astype(bool).sum())),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    out[\"problem_completed\"] = out[\"num_files\"] == out[\"files_scored\"]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9f9555c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_save_token_level_raw_scores(\n",
    "    completed_df: pd.DataFrame,\n",
    "    base_loc: str | Path,\n",
    "    metadata_base_loc: str | Path,\n",
    "    *,\n",
    "    sheet_name: str = \"metadata\",\n",
    "    output_name: str = \"token_level_raw_scores.xlsx\",\n",
    "    recursive: bool = False,\n",
    "    engine: str | None = None,\n",
    "    overwrite: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    For each row in completed_df, read all .xlsx files in:\n",
    "        {base_loc}/{data_type}/{corpus}/{model}/raw\n",
    "    Extract `sheet_name`, concat, sort by sample_id then min_token_size,\n",
    "    and save to:\n",
    "        {base_loc}/{data_type}/{corpus}/{model}/{output_name}\n",
    "\n",
    "    Skips if output file already exists.\n",
    "    \"\"\"\n",
    "    base_loc = Path(base_loc)\n",
    "\n",
    "    required_cols = {\"data_type\", \"corpus\", \"model\"}\n",
    "    missing = required_cols - set(completed_df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"completed_df is missing required columns: {sorted(missing)}\")\n",
    "\n",
    "    for row in completed_df.itertuples(index=False):\n",
    "        data_type = getattr(row, \"data_type\")\n",
    "        corpus = getattr(row, \"corpus\")\n",
    "        model = getattr(row, \"model\")\n",
    "\n",
    "        raw_dir = base_loc / data_type / corpus / model / \"raw\"\n",
    "        out_path = raw_dir.parent / output_name  # removes /raw\n",
    "        metadata_out_path = base_loc / data_type / corpus / model / \"raw_problem_metadata.xlsx\"\n",
    "        summary_metadata_out_path = base_loc / data_type / corpus / model / \"raw_problem_completed_metadata.xlsx\"\n",
    "        \n",
    "        # skip if output already exists\n",
    "        if not overwrite:\n",
    "            if out_path.exists():\n",
    "                print(f\"SKIP (exists): {out_path}\")\n",
    "                continue\n",
    "\n",
    "        # if raw dir missing / empty, skip\n",
    "        if not raw_dir.exists():\n",
    "            print(f\"SKIP (no dir): {raw_dir}\")\n",
    "            continue\n",
    "\n",
    "        excel_files = list_xlsx_files(raw_dir, recursive=recursive)\n",
    "        if not excel_files:\n",
    "            print(f\"SKIP (no files): {raw_dir}\")\n",
    "            continue\n",
    "\n",
    "        base_metadata = compare_complete_to_metadata(metadata_base_loc, data_type, corpus, model, excel_files)\n",
    "        \n",
    "        combined_metadata = []\n",
    "\n",
    "        for ef in excel_files:\n",
    "            f_name = ef.name\n",
    "            try:\n",
    "                data = read_excel_sheets(ef, [sheet_name])\n",
    "                combined_metadata.append(data[sheet_name])\n",
    "                \n",
    "                # âœ… mark as scored if read succeeded\n",
    "                base_metadata.loc[base_metadata[\"filename\"] == f_name, \"scored\"] = True\n",
    "            except Exception as e:\n",
    "                print(f\"  WARN: failed reading {sheet_name} from {ef}: {e}\")\n",
    "\n",
    "        if not combined_metadata:\n",
    "            print(f\"SKIP (no readable sheets): {raw_dir}\")\n",
    "            continue\n",
    "\n",
    "        results = (\n",
    "            pd.concat(combined_metadata, ignore_index=True)\n",
    "            .sort_values([\"sample_id\", \"min_token_size\"], ascending=[True, True], kind=\"mergesort\")\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        # insert data_type before corpus, scoring_model after corpus\n",
    "        if \"corpus\" in results.columns:\n",
    "            corpus_idx = results.columns.get_loc(\"corpus\")\n",
    "\n",
    "            if \"data_type\" in results.columns:\n",
    "                results.drop(columns=[\"data_type\"], inplace=True)\n",
    "            results.insert(corpus_idx, \"data_type\", data_type)\n",
    "\n",
    "            corpus_idx = results.columns.get_loc(\"corpus\")  # re-fetch\n",
    "            if \"scoring_model\" in results.columns:\n",
    "                results.drop(columns=[\"scoring_model\"], inplace=True)\n",
    "            results.insert(corpus_idx + 1, \"scoring_model\", model)\n",
    "            \n",
    "        # move problem before known_author (always move; adjust index if problem was before)\n",
    "        if \"problem\" in results.columns and \"known_author\" in results.columns:\n",
    "            problem_idx = results.columns.get_loc(\"problem\")\n",
    "            known_author_idx = results.columns.get_loc(\"known_author\")\n",
    "\n",
    "            problem_col = results.pop(\"problem\")\n",
    "\n",
    "            # if problem was before known_author, known_author shifted left by 1 after pop\n",
    "            if problem_idx < known_author_idx:\n",
    "                known_author_idx -= 1\n",
    "\n",
    "            results.insert(known_author_idx, \"problem\", problem_col)\n",
    "        \n",
    "        # ensure parent exists, then save\n",
    "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        results.to_excel(out_path, index=False)\n",
    "        print(f\"SAVED: {out_path}  (rows={len(results)})\")\n",
    "        \n",
    "        # Also want to save the metadata\n",
    "        base_metadata.to_excel(metadata_out_path, index=False)\n",
    "        \n",
    "        summary_metadata = create_problem_complete_metadata(base_metadata)\n",
    "        summary_metadata.to_excel(summary_metadata_out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "e9579f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/Qwen2.5-0.5B-Instruct/token_level_raw_scores.xlsx  (rows=1721)\n",
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/Qwen2.5-1.5B-Instruct/token_level_raw_scores.xlsx  (rows=1721)\n",
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gemma-3-270m/token_level_raw_scores.xlsx  (rows=1864)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-277>:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/Qwen2.5-0.5B-Instruct/token_level_raw_scores.xlsx  (rows=1606)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-277>:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/Qwen2.5-1.5B-Instruct/token_level_raw_scores.xlsx  (rows=1606)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-277>:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gemma-3-270m/token_level_raw_scores.xlsx  (rows=2086)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-277>:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/token_level_raw_scores.xlsx  (rows=1973)\n"
     ]
    }
   ],
   "source": [
    "build_and_save_token_level_raw_scores(\n",
    "    completed_data,\n",
    "    base_loc,\n",
    "    metadata_base_loc,\n",
    "    sheet_name = \"metadata\",\n",
    "    output_name = \"token_level_raw_scores.xlsx\",\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7f02c112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_type</th>\n",
       "      <th>corpus</th>\n",
       "      <th>model</th>\n",
       "      <th>expected_num_files</th>\n",
       "      <th>actual_num_files</th>\n",
       "      <th>delta</th>\n",
       "      <th>missing</th>\n",
       "      <th>extra</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>Perverted Justice</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>574</td>\n",
       "      <td>491</td>\n",
       "      <td>-83</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>MISSING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_type             corpus model  expected_num_files  actual_num_files  delta  missing  extra   status\n",
       "3      test  Perverted Justice  gpt2                 574               491    -83       83      0  MISSING"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_df = actual_df[\n",
    "    (actual_df['data_type'] == 'test')\n",
    "    & (actual_df['corpus'] == 'Perverted Justice')\n",
    "    & (actual_df['model'] == 'gpt2')\n",
    "]\n",
    "\n",
    "manual_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "53d0767d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-275>:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/token_level_raw_scores.xlsx  (rows=1513)\n"
     ]
    }
   ],
   "source": [
    "build_and_save_token_level_raw_scores(\n",
    "    manual_df,\n",
    "    base_loc,\n",
    "    metadata_base_loc,\n",
    "    sheet_name = \"metadata\",\n",
    "    output_name = \"token_level_raw_scores.xlsx\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
