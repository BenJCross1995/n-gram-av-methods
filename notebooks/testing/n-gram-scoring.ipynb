{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51f61474",
   "metadata": {},
   "source": [
    "# N-gram Tracing\n",
    "\n",
    "This notebook will be used to test out n-gram tracing for use with author verification methods. The end goal is to ensure the code works to find common n-grams between two texts and that we can return the text prior to those n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "372d175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from from_root import from_root\n",
    "\n",
    "sys.path.insert(0, str(from_root(\"src\")))\n",
    "\n",
    "from model_loading import load_model\n",
    "from read_and_write_docs import read_txt\n",
    "from n_gram_tracing import (\n",
    "    common_ngrams,\n",
    "    tokens_to_text,\n",
    "    texts_around_each_ngram,\n",
    "    get_trimmed_context_before_span\n",
    ")\n",
    "from n_gram_scoring import score_ngrams, score_ngrams_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd60f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = load_model(\"/Volumes/BCross/models/Llama-3.2-3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271baf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32768\n"
     ]
    }
   ],
   "source": [
    "max_len = getattr(model.config, \"max_position_embeddings\", None) or getattr(model.config, \"n_positions\", None)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7af33593",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_text = read_txt(\"../../data/kevin_hyatt_mail_1.txt\")\n",
    "unknown_text = read_txt(\"../../data/kevin_hyatt_mail_2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff4d14",
   "metadata": {},
   "source": [
    "## Get Common N-Grams\n",
    "\n",
    "Here we get the n-grams in common between the two texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7d8fe864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "common = common_ngrams(\n",
    "    text1=known_text,\n",
    "    text2=unknown_text,\n",
    "    n=2,\n",
    "    tokenizer=tokenizer,\n",
    "    include_subgrams=False,\n",
    "    lowercase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4b0aa35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[',', 'Ġas'],\n",
       " [',', 'Ġbut'],\n",
       " ['.', 'Ġif'],\n",
       " ['.', 'Ġthe'],\n",
       " ['ie', ','],\n",
       " ['Ġa', 'Ġdraft'],\n",
       " ['Ġa', 'Ġfax'],\n",
       " ['Ġand', 'Ġhe'],\n",
       " ['Ġand', 'Ġi'],\n",
       " ['Ġarea', '.'],\n",
       " ['Ġcall', 'Ġme'],\n",
       " ['Ġdid', 'Ġnot'],\n",
       " ['Ġdo', 'Ġnot'],\n",
       " ['Ġfor', 'Ġthe'],\n",
       " ['Ġhave', 'Ġa'],\n",
       " ['Ġhelp', 'Ġin'],\n",
       " ['Ġhim', 'Ġto'],\n",
       " ['Ġi', 'Ġam'],\n",
       " ['Ġi', 'Ġcan'],\n",
       " ['Ġi', 'Ġneed'],\n",
       " ['Ġi', 'Ġsent'],\n",
       " ['Ġif', 'Ġwe'],\n",
       " ['Ġin', 'Ġ2002'],\n",
       " ['Ġin', 'Ġthe'],\n",
       " ['Ġit', 'Ġis'],\n",
       " ['Ġj', 'une'],\n",
       " ['Ġme', '.'],\n",
       " ['Ġme', 'Ġthat'],\n",
       " ['Ġme', 'Ġto'],\n",
       " ['Ġmeeting', '.'],\n",
       " ['Ġneed', 'Ġto'],\n",
       " ['Ġnot', 'Ġget'],\n",
       " ['Ġof', 'Ġyou'],\n",
       " ['Ġon', 'Ġthe'],\n",
       " ['Ġon', 'Ġthis'],\n",
       " ['Ġon', 'Ġto'],\n",
       " ['Ġone', 'Ġof'],\n",
       " ['Ġred', 'Ġrock'],\n",
       " ['Ġste', 've'],\n",
       " ['Ġt', 'uesday'],\n",
       " ['Ġthat', 'Ġi'],\n",
       " ['Ġthe', 'Ġbullets'],\n",
       " ['Ġthis', 'Ġweek'],\n",
       " ['Ġto', 'Ġbe'],\n",
       " ['Ġto', 'Ġensure'],\n",
       " ['Ġto', 'Ġget'],\n",
       " ['Ġto', 'Ġsend'],\n",
       " ['Ġto', 'Ġthe'],\n",
       " ['Ġwanted', 'Ġto'],\n",
       " ['Ġweek', '.'],\n",
       " ['Ġwhen', 'Ġi'],\n",
       " ['Ġwill', 'Ġhave'],\n",
       " ['Ġwould', 'Ġbe'],\n",
       " ['Ġyou', '.'],\n",
       " ['Ġyou', 'Ġneed'],\n",
       " ['Ġyou', 'Ġto'],\n",
       " [\"'d\", 'Ġlike', 'Ġto'],\n",
       " [',', 'Ġi', 'Ġhave'],\n",
       " [',', 'Ġi', 'Ġjust'],\n",
       " [',', 'Ġi', 'Ġnoticed'],\n",
       " [',', 'Ġso', 'Ġi'],\n",
       " ['.', 'Ġi', 'Ġhave'],\n",
       " ['.', 'Ġi', 'Ġjust'],\n",
       " ['Ġcost', 'Ġof', 'Ġthe'],\n",
       " ['Ġi', 'Ġhave', 'Ġreceived'],\n",
       " ['Ġin', 'Ġh', 'ouston'],\n",
       " ['Ġin', 'Ġr', 'ome'],\n",
       " ['Ġour', 'Ġgroup', '.'],\n",
       " ['Ġsome', 'Ġof', 'Ġthe'],\n",
       " ['Ġthat', 'Ġyou', 'Ġhave'],\n",
       " ['Ġto', 'Ġmeet', 'Ġwith'],\n",
       " ['Ġto', 'Ġsee', 'Ġif'],\n",
       " ['Ġwith', 'Ġyou', 'Ġand'],\n",
       " [',', 'Ġhere', 'Ġis', 'Ġthe'],\n",
       " ['.', 'Ġalso', ',', 'Ġi'],\n",
       " ['.', 'Ġplease', 'Ġreview', 'Ġand'],\n",
       " ['Ġat', 'Ġthe', 'Ġend', 'Ġof'],\n",
       " ['Ġhotel', 'Ġin', 'Ġposit', 'ano'],\n",
       " ['Ġhotel', 'Ġmar', 'inc', 'anto'],\n",
       " ['Ġse', 'pt', '.', 'Ġi'],\n",
       " ['Ġto', 'Ġconnect', 'Ġup', 'Ġwith'],\n",
       " ['Ġto', 'Ġvisit', 'Ġwith', 'Ġyou'],\n",
       " [',', 'Ġattached', ',', 'Ġplease', 'Ġfind'],\n",
       " ['.', 'Ġi', 'Ġwould', 'Ġlike', 'Ġto'],\n",
       " ['.', 'Ġplease', 'Ġlet', 'Ġme', 'Ġknow'],\n",
       " ['Ġif', 'Ġyou', 'Ġare', 'Ġavailable', '.'],\n",
       " ['.', 'Ġlet', 'Ġme', 'Ġknow', 'Ġif', 'Ġyou'],\n",
       " ['Ġif', 'Ġyou', 'Ġhave', 'Ġany', 'Ġquestions', 'Ġor'],\n",
       " [',', 'Ġi', 'Ġwould', 'Ġlike', 'Ġto', 'Ġvisit', 'Ġwith'],\n",
       " ['Ġlet', 'Ġme', 'Ġknow', 'Ġif', 'Ġyou', 'Ġwould', 'Ġlike']]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ca323798",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tokens = common[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e3016b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "113b0775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. i would like to'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = tokens_to_text(['.', 'Ġi', 'Ġwould', 'Ġlike', 'Ġto'], tokenizer)\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b3225c",
   "metadata": {},
   "source": [
    "## Find Starting Positions\n",
    "\n",
    "Two options here, to find the starting positions of n-grams and return the text before that or to include the n-gram in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "886536f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1081, 1086)]\n"
     ]
    }
   ],
   "source": [
    "example_texts = texts_around_each_ngram(\n",
    "    unknown_text,\n",
    "    sample_text,\n",
    "    return_spans=True,\n",
    "    return_token_spans=True,\n",
    "    tokenizer=tokenizer,\n",
    "    return_tokenized_text=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "175ad595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"they also have private parking at the cheap price of euro 18 per day and only a thousand uphill each way steps to it. i do not know if they have two standard room and two superior rooms or just one of each type available. please let me know what your preference is. if both our preferences are for the same type room and they only have one of each, shall we draw straws or have a pizza eating contest? also, there was one other hotel in positano that i looked into before finding hotel marincanto for our sept. i may look them up tonight and fax them tomorrow just to compare. we also have a fax from hotel firenze in rome that we are confirmed for june 7 8! if you have no bullets to report, please reply to me that you have none. the 131 is 100 of the cost of the project. lorraine will be attending for our group. will you be able to attend and give us your advise? earl, as i understand it, you have a copy also. please confirm that you have what you need. i will send my copy to mansoor unless otherwise directed. also, i have received an invoice from agave for 245,904. i believe mark mcconnell faxed you a copy a few weeks ago. i need you both to approve the invoice so i can pay. do either of you have any comments regarding this invoice? rich is retiring after 35 years of service. tiny, i just received a message that rich is going to retire at the end of the month. i understand that there is a surprise lunch for him in houston on march 29. let us know, we'd like to meet with you if you are going to be in town. did you receive the 50 check i sent you for rich's gift? when i was reconciling my checking account a couple of weeks ago, i noticed it had not cleared yet. i just want to make sure it did not get lost in the mail. dear gary and fran, attached, please find a resignation letter from both me and lorraine lindberg. if you would like a signed hard copy, just let me know, i would be happy to provide it to you. lorraine has also indicated that she would provide you a signed hard copy, too. at your convience, i would like to visit with each of you. amy, here is the open season document on our sun devil expansion. please call me if you have any questions. i would love to visit with you and share with you some of the things we have been working on to ensure a smooth transition. tuesday is possible, i would need to move another appointment. here is a start to the bullets. thank you for handling this for the team today! steve, while i am checking on this items we discussed, here is a draft copy of both proposals. please note that i have given them 60 days to respond. that may be too long for the red rock proposal. let me know if you would like one or both timeframes changed. i'll visit with you by voice mail as i get an answer from dennis tu. dave, may i ask you to take a look at this spreadsheet, please? steve and i are hoping to connect up with danny tomorrow afternoon and discuss both our fuel strategy and our index to index deal strategy. i have put together some numbers on the i to i deals, but i would like to discuss them with you to make sure i am not missing anything. although larry pavlou is on vacation tomorrow, he will be conferenced into our meeting. you are also welcome to join our meeting if you are available. it is that time of year please complete your list of accomplishments by the end of november. also, please complete your 2002 objectives by december 14. your objectives will need to outline your specific marketing plan for each customer, project and idea you may have for adding/increasing value to transwestern in 2002. as discussed earlier, we will get together in mid-december to review account loads to see if we need to do any shifting. your 2002 objectives will be helpful in determining whether your load is heavy, light or just right. i will be happy to visit with each of you individually if you have any questions or would like to discuss these items. i will have my cell phone if anyone needs me. and sue had a conversation regarding help in the risk mgmt area. i saw dave in the hallway earlier and he indicated that he wanted to rally with you and me to discuss. i hope to get him to send in a request this week. also, james has been running numbers today, so i should have a term sheet for you tomorrow. the agave christmas party is on tuesday, december 11. is it possible to take a company plane out with reps from mgmt, mktg, gas logistics and operations? we are also running a few more scenarios for transpecos. stephanie, here is the sun devil expansion package. please review and forward on to those in your group who may have an interest. we would be happy to discuss this expansion opportunity with you at your convenience. take a look and i'll give you a call late this afternoon to discuss. i would like to\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d63204f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"they also have private parking at the cheap price of euro 18 per day and only a thousand uphill each way steps to it. i do not know if they have two standard room and two superior rooms or just one of each type available. please let me know what your preference is. if both our preferences are for the same type room and they only have one of each, shall we draw straws or have a pizza eating contest? also, there was one other hotel in positano that i looked into before finding hotel marincanto for our sept. i may look them up tonight and fax them tomorrow just to compare. we also have a fax from hotel firenze in rome that we are confirmed for june 7 8! if you have no bullets to report, please reply to me that you have none. the 131 is 100 of the cost of the project. lorraine will be attending for our group. will you be able to attend and give us your advise? earl, as i understand it, you have a copy also. please confirm that you have what you need. i will send my copy to mansoor unless otherwise directed. also, i have received an invoice from agave for 245,904. i believe mark mcconnell faxed you a copy a few weeks ago. i need you both to approve the invoice so i can pay. do either of you have any comments regarding this invoice? rich is retiring after 35 years of service. tiny, i just received a message that rich is going to retire at the end of the month. i understand that there is a surprise lunch for him in houston on march 29. let us know, we'd like to meet with you if you are going to be in town. did you receive the 50 check i sent you for rich's gift? when i was reconciling my checking account a couple of weeks ago, i noticed it had not cleared yet. i just want to make sure it did not get lost in the mail. dear gary and fran, attached, please find a resignation letter from both me and lorraine lindberg. if you would like a signed hard copy, just let me know, i would be happy to provide it to you. lorraine has also indicated that she would provide you a signed hard copy, too. at your convience, i would like to visit with each of you. amy, here is the open season document on our sun devil expansion. please call me if you have any questions. i would love to visit with you and share with you some of the things we have been working on to ensure a smooth transition. tuesday is possible, i would need to move another appointment. here is a start to the bullets. thank you for handling this for the team today! steve, while i am checking on this items we discussed, here is a draft copy of both proposals. please note that i have given them 60 days to respond. that may be too long for the red rock proposal. let me know if you would like one or both timeframes changed. i'll visit with you by voice mail as i get an answer from dennis tu. dave, may i ask you to take a look at this spreadsheet, please? steve and i are hoping to connect up with danny tomorrow afternoon and discuss both our fuel strategy and our index to index deal strategy. i have put together some numbers on the i to i deals, but i would like to discuss them with you to make sure i am not missing anything. although larry pavlou is on vacation tomorrow, he will be conferenced into our meeting. you are also welcome to join our meeting if you are available. it is that time of year please complete your list of accomplishments by the end of november. also, please complete your 2002 objectives by december 14. your objectives will need to outline your specific marketing plan for each customer, project and idea you may have for adding/increasing value to transwestern in 2002. as discussed earlier, we will get together in mid-december to review account loads to see if we need to do any shifting. your 2002 objectives will be helpful in determining whether your load is heavy, light or just right. i will be happy to visit with each of you individually if you have any questions or would like to discuss these items. i will have my cell phone if anyone needs me. and sue had a conversation regarding help in the risk mgmt area. i saw dave in the hallway earlier and he indicated that he wanted to rally with you and me to discuss. i hope to get him to send in a request this week. also, james has been running numbers today, so i should have a term sheet for you tomorrow. the agave christmas party is on tuesday, december 11. is it possible to take a company plane out with reps from mgmt, mktg, gas logistics and operations? we are also running a few more scenarios for transpecos. stephanie, here is the sun devil expansion package. please review and forward on to those in your group who may have an interest. we would be happy to discuss this expansion opportunity with you at your convenience. take a look and i'll give you a call late this afternoon to discuss. i would like to\"],\n",
       " [(4779, 4796)],\n",
       " [(1081, 1086)],\n",
       " ['they',\n",
       "  'Ġalso',\n",
       "  'Ġhave',\n",
       "  'Ġprivate',\n",
       "  'Ġparking',\n",
       "  'Ġat',\n",
       "  'Ġthe',\n",
       "  'Ġcheap',\n",
       "  'Ġprice',\n",
       "  'Ġof',\n",
       "  'Ġeuro',\n",
       "  'Ġ18',\n",
       "  'Ġper',\n",
       "  'Ġday',\n",
       "  'Ġand',\n",
       "  'Ġonly',\n",
       "  'Ġa',\n",
       "  'Ġthousand',\n",
       "  'Ġuphill',\n",
       "  'Ġeach',\n",
       "  'Ġway',\n",
       "  'Ġsteps',\n",
       "  'Ġto',\n",
       "  'Ġit',\n",
       "  '.',\n",
       "  'Ġi',\n",
       "  'Ġdo',\n",
       "  'Ġnot',\n",
       "  'Ġknow',\n",
       "  'Ġif',\n",
       "  'Ġthey',\n",
       "  'Ġhave',\n",
       "  'Ġtwo',\n",
       "  'Ġstandard',\n",
       "  'Ġroom',\n",
       "  'Ġand',\n",
       "  'Ġtwo',\n",
       "  'Ġsuperior',\n",
       "  'Ġrooms',\n",
       "  'Ġor',\n",
       "  'Ġjust',\n",
       "  'Ġone',\n",
       "  'Ġof',\n",
       "  'Ġeach',\n",
       "  'Ġtype',\n",
       "  'Ġavailable',\n",
       "  '.',\n",
       "  'Ġplease',\n",
       "  'Ġlet',\n",
       "  'Ġme',\n",
       "  'Ġknow',\n",
       "  'Ġwhat',\n",
       "  'Ġyour',\n",
       "  'Ġpreference',\n",
       "  'Ġis',\n",
       "  '.',\n",
       "  'Ġif',\n",
       "  'Ġboth',\n",
       "  'Ġour',\n",
       "  'Ġpreferences',\n",
       "  'Ġare',\n",
       "  'Ġfor',\n",
       "  'Ġthe',\n",
       "  'Ġsame',\n",
       "  'Ġtype',\n",
       "  'Ġroom',\n",
       "  'Ġand',\n",
       "  'Ġthey',\n",
       "  'Ġonly',\n",
       "  'Ġhave',\n",
       "  'Ġone',\n",
       "  'Ġof',\n",
       "  'Ġeach',\n",
       "  ',',\n",
       "  'Ġshall',\n",
       "  'Ġwe',\n",
       "  'Ġdraw',\n",
       "  'Ġstraw',\n",
       "  's',\n",
       "  'Ġor',\n",
       "  'Ġhave',\n",
       "  'Ġa',\n",
       "  'Ġpizza',\n",
       "  'Ġeating',\n",
       "  'Ġcontest',\n",
       "  '?',\n",
       "  'Ġalso',\n",
       "  ',',\n",
       "  'Ġthere',\n",
       "  'Ġwas',\n",
       "  'Ġone',\n",
       "  'Ġother',\n",
       "  'Ġhotel',\n",
       "  'Ġin',\n",
       "  'Ġposit',\n",
       "  'ano',\n",
       "  'Ġthat',\n",
       "  'Ġi',\n",
       "  'Ġlooked',\n",
       "  'Ġinto',\n",
       "  'Ġbefore',\n",
       "  'Ġfinding',\n",
       "  'Ġhotel',\n",
       "  'Ġmar',\n",
       "  'inc',\n",
       "  'anto',\n",
       "  'Ġfor',\n",
       "  'Ġour',\n",
       "  'Ġse',\n",
       "  'pt',\n",
       "  '.',\n",
       "  'Ġi',\n",
       "  'Ġmay',\n",
       "  'Ġlook',\n",
       "  'Ġthem',\n",
       "  'Ġup',\n",
       "  'Ġtonight',\n",
       "  'Ġand',\n",
       "  'Ġfax',\n",
       "  'Ġthem',\n",
       "  'Ġtomorrow',\n",
       "  'Ġjust',\n",
       "  'Ġto',\n",
       "  'Ġcompare',\n",
       "  '.',\n",
       "  'Ġwe',\n",
       "  'Ġalso',\n",
       "  'Ġhave',\n",
       "  'Ġa',\n",
       "  'Ġfax',\n",
       "  'Ġfrom',\n",
       "  'Ġhotel',\n",
       "  'Ġfire',\n",
       "  'n',\n",
       "  'ze',\n",
       "  'Ġin',\n",
       "  'Ġr',\n",
       "  'ome',\n",
       "  'Ġthat',\n",
       "  'Ġwe',\n",
       "  'Ġare',\n",
       "  'Ġconfirmed',\n",
       "  'Ġfor',\n",
       "  'Ġj',\n",
       "  'une',\n",
       "  'Ġ7',\n",
       "  'Ġ8',\n",
       "  '!',\n",
       "  'Ġif',\n",
       "  'Ġyou',\n",
       "  'Ġhave',\n",
       "  'Ġno',\n",
       "  'Ġbullets',\n",
       "  'Ġto',\n",
       "  'Ġreport',\n",
       "  ',',\n",
       "  'Ġplease',\n",
       "  'Ġreply',\n",
       "  'Ġto',\n",
       "  'Ġme',\n",
       "  'Ġthat',\n",
       "  'Ġyou',\n",
       "  'Ġhave',\n",
       "  'Ġnone',\n",
       "  '.',\n",
       "  'Ġthe',\n",
       "  'Ġ131',\n",
       "  'Ġis',\n",
       "  'Ġ100',\n",
       "  'Ġof',\n",
       "  'Ġthe',\n",
       "  'Ġcost',\n",
       "  'Ġof',\n",
       "  'Ġthe',\n",
       "  'Ġproject',\n",
       "  '.',\n",
       "  'Ġl',\n",
       "  'or',\n",
       "  'raine',\n",
       "  'Ġwill',\n",
       "  'Ġbe',\n",
       "  'Ġattending',\n",
       "  'Ġfor',\n",
       "  'Ġour',\n",
       "  'Ġgroup',\n",
       "  '.',\n",
       "  'Ġwill',\n",
       "  'Ġyou',\n",
       "  'Ġbe',\n",
       "  'Ġable',\n",
       "  'Ġto',\n",
       "  'Ġattend',\n",
       "  'Ġand',\n",
       "  'Ġgive',\n",
       "  'Ġus',\n",
       "  'Ġyour',\n",
       "  'Ġadvise',\n",
       "  '?',\n",
       "  'Ġear',\n",
       "  'l',\n",
       "  ',',\n",
       "  'Ġas',\n",
       "  'Ġi',\n",
       "  'Ġunderstand',\n",
       "  'Ġit',\n",
       "  ',',\n",
       "  'Ġyou',\n",
       "  'Ġhave',\n",
       "  'Ġa',\n",
       "  'Ġcopy',\n",
       "  'Ġalso',\n",
       "  '.',\n",
       "  'Ġplease',\n",
       "  'Ġconfirm',\n",
       "  'Ġthat',\n",
       "  'Ġyou',\n",
       "  'Ġhave',\n",
       "  'Ġwhat',\n",
       "  'Ġyou',\n",
       "  'Ġneed',\n",
       "  '.',\n",
       "  'Ġi',\n",
       "  'Ġwill',\n",
       "  'Ġsend',\n",
       "  'Ġmy',\n",
       "  'Ġcopy',\n",
       "  'Ġto',\n",
       "  'Ġmans',\n",
       "  'oor',\n",
       "  'Ġunless',\n",
       "  'Ġotherwise',\n",
       "  'Ġdirected',\n",
       "  '.',\n",
       "  'Ġalso',\n",
       "  ',',\n",
       "  'Ġi',\n",
       "  'Ġhave',\n",
       "  'Ġreceived',\n",
       "  'Ġan',\n",
       "  'Ġinvoice',\n",
       "  'Ġfrom',\n",
       "  'Ġag',\n",
       "  'ave',\n",
       "  'Ġfor',\n",
       "  'Ġ245',\n",
       "  ',',\n",
       "  '9',\n",
       "  '04',\n",
       "  '.',\n",
       "  'Ġi',\n",
       "  'Ġbelieve',\n",
       "  'Ġmark',\n",
       "  'Ġm',\n",
       "  'cc',\n",
       "  'on',\n",
       "  'nell',\n",
       "  'Ġfax',\n",
       "  'ed',\n",
       "  'Ġyou',\n",
       "  'Ġa',\n",
       "  'Ġcopy',\n",
       "  'Ġa',\n",
       "  'Ġfew',\n",
       "  'Ġweeks',\n",
       "  'Ġago',\n",
       "  '.',\n",
       "  'Ġi',\n",
       "  'Ġneed',\n",
       "  'Ġyou',\n",
       "  'Ġboth',\n",
       "  'Ġto',\n",
       "  'Ġapprove',\n",
       "  'Ġthe',\n",
       "  'Ġinvoice',\n",
       "  'Ġso',\n",
       "  'Ġi',\n",
       "  'Ġcan',\n",
       "  'Ġpay',\n",
       "  '.',\n",
       "  'Ġdo',\n",
       "  'Ġeither',\n",
       "  'Ġof',\n",
       "  'Ġyou',\n",
       "  'Ġhave',\n",
       "  'Ġany',\n",
       "  'Ġcomments',\n",
       "  'Ġregarding',\n",
       "  'Ġthis',\n",
       "  'Ġinvoice',\n",
       "  '?',\n",
       "  'Ġrich',\n",
       "  'Ġis',\n",
       "  'Ġretiring',\n",
       "  'Ġafter',\n",
       "  'Ġ35',\n",
       "  'Ġyears',\n",
       "  'Ġof',\n",
       "  'Ġservice',\n",
       "  '.',\n",
       "  'Ġtiny',\n",
       "  ',',\n",
       "  'Ġi',\n",
       "  'Ġjust',\n",
       "  'Ġreceived',\n",
       "  'Ġa',\n",
       "  'Ġmessage',\n",
       "  'Ġthat',\n",
       "  'Ġrich',\n",
       "  'Ġis',\n",
       "  'Ġgoing',\n",
       "  'Ġto',\n",
       "  'Ġretire',\n",
       "  'Ġat',\n",
       "  'Ġthe',\n",
       "  'Ġend',\n",
       "  'Ġof',\n",
       "  'Ġthe',\n",
       "  'Ġmonth',\n",
       "  '.',\n",
       "  'Ġi',\n",
       "  'Ġunderstand',\n",
       "  'Ġthat',\n",
       "  'Ġthere',\n",
       "  'Ġis',\n",
       "  'Ġa',\n",
       "  'Ġsurprise',\n",
       "  'Ġlunch',\n",
       "  'Ġfor',\n",
       "  'Ġhim',\n",
       "  'Ġin',\n",
       "  'Ġh',\n",
       "  'ouston',\n",
       "  'Ġon',\n",
       "  'Ġmarch',\n",
       "  'Ġ29',\n",
       "  '.',\n",
       "  'Ġlet',\n",
       "  'Ġus',\n",
       "  'Ġknow',\n",
       "  ',',\n",
       "  'Ġwe',\n",
       "  \"'d\",\n",
       "  'Ġlike',\n",
       "  'Ġto',\n",
       "  'Ġmeet',\n",
       "  'Ġwith',\n",
       "  'Ġyou',\n",
       "  'Ġif',\n",
       "  'Ġyou',\n",
       "  'Ġare',\n",
       "  'Ġgoing',\n",
       "  'Ġto',\n",
       "  'Ġbe',\n",
       "  'Ġin',\n",
       "  'Ġtown',\n",
       "  '.',\n",
       "  'Ġdid',\n",
       "  'Ġyou',\n",
       "  'Ġreceive',\n",
       "  'Ġthe',\n",
       "  'Ġ50',\n",
       "  'Ġcheck',\n",
       "  'Ġi',\n",
       "  'Ġsent',\n",
       "  'Ġyou',\n",
       "  'Ġfor',\n",
       "  'Ġrich',\n",
       "  \"'s\",\n",
       "  'Ġgift',\n",
       "  '?',\n",
       "  'Ġwhen',\n",
       "  'Ġi',\n",
       "  'Ġwas',\n",
       "  'Ġreconcil',\n",
       "  'ing',\n",
       "  'Ġmy',\n",
       "  'Ġchecking',\n",
       "  'Ġaccount',\n",
       "  'Ġa',\n",
       "  'Ġcouple',\n",
       "  'Ġof',\n",
       "  'Ġweeks',\n",
       "  'Ġago',\n",
       "  ',',\n",
       "  'Ġi',\n",
       "  'Ġnoticed',\n",
       "  'Ġit',\n",
       "  'Ġhad',\n",
       "  'Ġnot',\n",
       "  'Ġcleared',\n",
       "  'Ġyet',\n",
       "  '.',\n",
       "  'Ġi',\n",
       "  'Ġjust',\n",
       "  'Ġwant',\n",
       "  'Ġto',\n",
       "  'Ġmake',\n",
       "  'Ġsure',\n",
       "  'Ġit',\n",
       "  'Ġdid',\n",
       "  'Ġnot',\n",
       "  'Ġget',\n",
       "  'Ġlost',\n",
       "  'Ġin',\n",
       "  'Ġthe',\n",
       "  'Ġmail',\n",
       "  '.',\n",
       "  'Ġdear',\n",
       "  'Ġg',\n",
       "  'ary',\n",
       "  'Ġand',\n",
       "  'Ġfr',\n",
       "  'an',\n",
       "  ',',\n",
       "  'Ġattached',\n",
       "  ',',\n",
       "  'Ġplease',\n",
       "  'Ġfind',\n",
       "  'Ġa',\n",
       "  'Ġresignation',\n",
       "  'Ġletter',\n",
       "  'Ġfrom',\n",
       "  'Ġboth',\n",
       "  'Ġme',\n",
       "  'Ġand',\n",
       "  'Ġl',\n",
       "  'or',\n",
       "  'raine',\n",
       "  'Ġl',\n",
       "  'ind',\n",
       "  'berg',\n",
       "  '.',\n",
       "  'Ġif',\n",
       "  'Ġyou',\n",
       "  'Ġwould',\n",
       "  'Ġlike',\n",
       "  'Ġa',\n",
       "  'Ġsigned',\n",
       "  'Ġhard',\n",
       "  'Ġcopy',\n",
       "  ',',\n",
       "  'Ġjust',\n",
       "  'Ġlet',\n",
       "  'Ġme',\n",
       "  'Ġknow',\n",
       "  ',',\n",
       "  'Ġi',\n",
       "  'Ġwould',\n",
       "  'Ġbe',\n",
       "  'Ġhappy',\n",
       "  'Ġto',\n",
       "  'Ġprovide',\n",
       "  'Ġit',\n",
       "  'Ġto',\n",
       "  'Ġyou',\n",
       "  '.',\n",
       "  'Ġl',\n",
       "  'or',\n",
       "  'raine',\n",
       "  'Ġhas',\n",
       "  'Ġalso',\n",
       "  'Ġindicated',\n",
       "  'Ġthat',\n",
       "  'Ġshe',\n",
       "  'Ġwould',\n",
       "  'Ġprovide',\n",
       "  'Ġyou',\n",
       "  'Ġa',\n",
       "  'Ġsigned',\n",
       "  'Ġhard',\n",
       "  'Ġcopy',\n",
       "  ',',\n",
       "  'Ġtoo',\n",
       "  '.',\n",
       "  'Ġat',\n",
       "  'Ġyour',\n",
       "  'Ġconv',\n",
       "  'ience',\n",
       "  ',',\n",
       "  'Ġi',\n",
       "  'Ġwould',\n",
       "  'Ġlike',\n",
       "  'Ġto',\n",
       "  'Ġvisit',\n",
       "  'Ġwith',\n",
       "  'Ġeach',\n",
       "  'Ġof',\n",
       "  'Ġyou',\n",
       "  '.',\n",
       "  'Ġamy',\n",
       "  ',',\n",
       "  'Ġhere',\n",
       "  'Ġis',\n",
       "  'Ġthe',\n",
       "  'Ġopen',\n",
       "  'Ġseason',\n",
       "  'Ġdocument',\n",
       "  'Ġon',\n",
       "  'Ġour',\n",
       "  'Ġsun',\n",
       "  'Ġdevil',\n",
       "  'Ġexpansion',\n",
       "  '.',\n",
       "  'Ġplease',\n",
       "  'Ġcall',\n",
       "  'Ġme',\n",
       "  'Ġif',\n",
       "  'Ġyou',\n",
       "  'Ġhave',\n",
       "  'Ġany',\n",
       "  'Ġquestions',\n",
       "  '.',\n",
       "  'Ġi',\n",
       "  'Ġwould',\n",
       "  'Ġlove',\n",
       "  'Ġto',\n",
       "  'Ġvisit',\n",
       "  'Ġwith',\n",
       "  'Ġyou',\n",
       "  'Ġand',\n",
       "  'Ġshare',\n",
       "  'Ġwith',\n",
       "  'Ġyou',\n",
       "  'Ġsome',\n",
       "  'Ġof',\n",
       "  'Ġthe',\n",
       "  'Ġthings',\n",
       "  'Ġwe',\n",
       "  'Ġhave',\n",
       "  'Ġbeen',\n",
       "  'Ġworking',\n",
       "  'Ġon',\n",
       "  'Ġto',\n",
       "  'Ġensure',\n",
       "  'Ġa',\n",
       "  'Ġsmooth',\n",
       "  'Ġtransition',\n",
       "  '.',\n",
       "  'Ġt',\n",
       "  'uesday',\n",
       "  'Ġis',\n",
       "  'Ġpossible',\n",
       "  ',',\n",
       "  'Ġi',\n",
       "  'Ġwould',\n",
       "  'Ġneed',\n",
       "  'Ġto',\n",
       "  'Ġmove',\n",
       "  'Ġanother',\n",
       "  'Ġappointment',\n",
       "  '.',\n",
       "  'Ġhere',\n",
       "  'Ġis',\n",
       "  'Ġa',\n",
       "  'Ġstart',\n",
       "  'Ġto',\n",
       "  'Ġthe',\n",
       "  'Ġbullets',\n",
       "  '.',\n",
       "  'Ġthank',\n",
       "  'Ġyou',\n",
       "  'Ġfor',\n",
       "  'Ġhandling',\n",
       "  'Ġthis',\n",
       "  'Ġfor',\n",
       "  'Ġthe',\n",
       "  'Ġteam',\n",
       "  'Ġtoday',\n",
       "  '!',\n",
       "  'Ġste',\n",
       "  've',\n",
       "  ',',\n",
       "  'Ġwhile',\n",
       "  'Ġi',\n",
       "  'Ġam',\n",
       "  'Ġchecking',\n",
       "  'Ġon',\n",
       "  'Ġthis',\n",
       "  'Ġitems',\n",
       "  'Ġwe',\n",
       "  'Ġdiscussed',\n",
       "  ',',\n",
       "  'Ġhere',\n",
       "  'Ġis',\n",
       "  'Ġa',\n",
       "  'Ġdraft',\n",
       "  'Ġcopy',\n",
       "  'Ġof',\n",
       "  'Ġboth',\n",
       "  'Ġproposals',\n",
       "  '.',\n",
       "  'Ġplease',\n",
       "  'Ġnote',\n",
       "  'Ġthat',\n",
       "  'Ġi',\n",
       "  'Ġhave',\n",
       "  'Ġgiven',\n",
       "  'Ġthem',\n",
       "  'Ġ60',\n",
       "  'Ġdays',\n",
       "  'Ġto',\n",
       "  'Ġrespond',\n",
       "  '.',\n",
       "  'Ġthat',\n",
       "  'Ġmay',\n",
       "  'Ġbe',\n",
       "  'Ġtoo',\n",
       "  'Ġlong',\n",
       "  'Ġfor',\n",
       "  'Ġthe',\n",
       "  'Ġred',\n",
       "  'Ġrock',\n",
       "  'Ġproposal',\n",
       "  '.',\n",
       "  'Ġlet',\n",
       "  'Ġme',\n",
       "  'Ġknow',\n",
       "  'Ġif',\n",
       "  'Ġyou',\n",
       "  'Ġwould',\n",
       "  'Ġlike',\n",
       "  'Ġone',\n",
       "  'Ġor',\n",
       "  'Ġboth',\n",
       "  'Ġtime',\n",
       "  'frames',\n",
       "  'Ġchanged',\n",
       "  '.',\n",
       "  'Ġi',\n",
       "  \"'ll\",\n",
       "  'Ġvisit',\n",
       "  'Ġwith',\n",
       "  'Ġyou',\n",
       "  'Ġby',\n",
       "  'Ġvoice',\n",
       "  'Ġmail',\n",
       "  'Ġas',\n",
       "  'Ġi',\n",
       "  'Ġget',\n",
       "  'Ġan',\n",
       "  'Ġanswer',\n",
       "  'Ġfrom',\n",
       "  'Ġd',\n",
       "  'ennis',\n",
       "  'Ġtu',\n",
       "  '.',\n",
       "  'Ġd',\n",
       "  'ave',\n",
       "  ',',\n",
       "  'Ġmay',\n",
       "  'Ġi',\n",
       "  'Ġask',\n",
       "  'Ġyou',\n",
       "  'Ġto',\n",
       "  'Ġtake',\n",
       "  'Ġa',\n",
       "  'Ġlook',\n",
       "  'Ġat',\n",
       "  'Ġthis',\n",
       "  'Ġspreadsheet',\n",
       "  ',',\n",
       "  'Ġplease',\n",
       "  '?',\n",
       "  'Ġste',\n",
       "  've',\n",
       "  'Ġand',\n",
       "  'Ġi',\n",
       "  'Ġare',\n",
       "  'Ġhoping',\n",
       "  'Ġto',\n",
       "  'Ġconnect',\n",
       "  'Ġup',\n",
       "  'Ġwith',\n",
       "  'Ġd',\n",
       "  'anny',\n",
       "  'Ġtomorrow',\n",
       "  'Ġafternoon',\n",
       "  'Ġand',\n",
       "  'Ġdiscuss',\n",
       "  'Ġboth',\n",
       "  'Ġour',\n",
       "  'Ġfuel',\n",
       "  'Ġstrategy',\n",
       "  'Ġand',\n",
       "  'Ġour',\n",
       "  'Ġindex',\n",
       "  'Ġto',\n",
       "  'Ġindex',\n",
       "  'Ġdeal',\n",
       "  'Ġstrategy',\n",
       "  '.',\n",
       "  'Ġi',\n",
       "  'Ġhave',\n",
       "  'Ġput',\n",
       "  'Ġtogether',\n",
       "  'Ġsome',\n",
       "  'Ġnumbers',\n",
       "  'Ġon',\n",
       "  'Ġthe',\n",
       "  'Ġi',\n",
       "  'Ġto',\n",
       "  'Ġi',\n",
       "  'Ġdeals',\n",
       "  ',',\n",
       "  'Ġbut',\n",
       "  'Ġi',\n",
       "  'Ġwould',\n",
       "  'Ġlike',\n",
       "  'Ġto',\n",
       "  'Ġdiscuss',\n",
       "  'Ġthem',\n",
       "  'Ġwith',\n",
       "  'Ġyou',\n",
       "  'Ġto',\n",
       "  'Ġmake',\n",
       "  'Ġsure',\n",
       "  'Ġi',\n",
       "  'Ġam',\n",
       "  'Ġnot',\n",
       "  'Ġmissing',\n",
       "  'Ġanything',\n",
       "  '.',\n",
       "  'Ġalthough',\n",
       "  'Ġl',\n",
       "  'arry',\n",
       "  'Ġpav',\n",
       "  'l',\n",
       "  'ou',\n",
       "  'Ġis',\n",
       "  'Ġon',\n",
       "  'Ġvacation',\n",
       "  'Ġtomorrow',\n",
       "  ',',\n",
       "  'Ġhe',\n",
       "  'Ġwill',\n",
       "  'Ġbe',\n",
       "  'Ġconf',\n",
       "  'eren',\n",
       "  'ced',\n",
       "  'Ġinto',\n",
       "  'Ġour',\n",
       "  'Ġmeeting',\n",
       "  '.',\n",
       "  'Ġyou',\n",
       "  'Ġare',\n",
       "  'Ġalso',\n",
       "  'Ġwelcome',\n",
       "  'Ġto',\n",
       "  'Ġjoin',\n",
       "  'Ġour',\n",
       "  'Ġmeeting',\n",
       "  'Ġif',\n",
       "  'Ġyou',\n",
       "  'Ġare',\n",
       "  'Ġavailable',\n",
       "  '.',\n",
       "  'Ġit',\n",
       "  'Ġis',\n",
       "  'Ġthat',\n",
       "  'Ġtime',\n",
       "  'Ġof',\n",
       "  'Ġyear',\n",
       "  'Ġplease',\n",
       "  'Ġcomplete',\n",
       "  'Ġyour',\n",
       "  'Ġlist',\n",
       "  'Ġof',\n",
       "  'Ġaccomplishments',\n",
       "  'Ġby',\n",
       "  'Ġthe',\n",
       "  'Ġend',\n",
       "  'Ġof',\n",
       "  'Ġno',\n",
       "  've',\n",
       "  'mber',\n",
       "  '.',\n",
       "  'Ġalso',\n",
       "  ',',\n",
       "  'Ġplease',\n",
       "  'Ġcomplete',\n",
       "  'Ġyour',\n",
       "  'Ġ2002',\n",
       "  'Ġobjectives',\n",
       "  'Ġby',\n",
       "  'Ġde',\n",
       "  'cember',\n",
       "  'Ġ14',\n",
       "  '.',\n",
       "  'Ġyour',\n",
       "  'Ġobjectives',\n",
       "  'Ġwill',\n",
       "  'Ġneed',\n",
       "  'Ġto',\n",
       "  'Ġoutline',\n",
       "  'Ġyour',\n",
       "  'Ġspecific',\n",
       "  'Ġmarketing',\n",
       "  'Ġplan',\n",
       "  'Ġfor',\n",
       "  'Ġeach',\n",
       "  'Ġcustomer',\n",
       "  ',',\n",
       "  'Ġproject',\n",
       "  'Ġand',\n",
       "  'Ġidea',\n",
       "  'Ġyou',\n",
       "  'Ġmay',\n",
       "  'Ġhave',\n",
       "  'Ġfor',\n",
       "  'Ġadding',\n",
       "  '/',\n",
       "  'increasing',\n",
       "  'Ġvalue',\n",
       "  'Ġto',\n",
       "  'Ġtrans',\n",
       "  'western',\n",
       "  'Ġin',\n",
       "  'Ġ2002',\n",
       "  '.',\n",
       "  'Ġas',\n",
       "  'Ġdiscussed',\n",
       "  'Ġearlier',\n",
       "  ',',\n",
       "  'Ġwe',\n",
       "  'Ġwill',\n",
       "  'Ġget',\n",
       "  'Ġtogether',\n",
       "  'Ġin',\n",
       "  'Ġmid',\n",
       "  '-',\n",
       "  'de',\n",
       "  'cember',\n",
       "  'Ġto',\n",
       "  'Ġreview',\n",
       "  'Ġaccount',\n",
       "  'Ġloads',\n",
       "  'Ġto',\n",
       "  'Ġsee',\n",
       "  'Ġif',\n",
       "  'Ġwe',\n",
       "  'Ġneed',\n",
       "  'Ġto',\n",
       "  'Ġdo',\n",
       "  'Ġany',\n",
       "  'Ġshifting',\n",
       "  '.',\n",
       "  'Ġyour',\n",
       "  'Ġ2002',\n",
       "  'Ġobjectives',\n",
       "  'Ġwill',\n",
       "  'Ġbe',\n",
       "  'Ġhelpful',\n",
       "  'Ġin',\n",
       "  'Ġdetermining',\n",
       "  'Ġwhether',\n",
       "  'Ġyour',\n",
       "  'Ġload',\n",
       "  'Ġis',\n",
       "  'Ġheavy',\n",
       "  ',',\n",
       "  'Ġlight',\n",
       "  'Ġor',\n",
       "  'Ġjust',\n",
       "  'Ġright',\n",
       "  '.',\n",
       "  'Ġi',\n",
       "  'Ġwill',\n",
       "  'Ġbe',\n",
       "  'Ġhappy',\n",
       "  'Ġto',\n",
       "  'Ġvisit',\n",
       "  'Ġwith',\n",
       "  'Ġeach',\n",
       "  'Ġof',\n",
       "  'Ġyou',\n",
       "  'Ġindividually',\n",
       "  'Ġif',\n",
       "  'Ġyou',\n",
       "  'Ġhave',\n",
       "  'Ġany',\n",
       "  'Ġquestions',\n",
       "  'Ġor',\n",
       "  'Ġwould',\n",
       "  'Ġlike',\n",
       "  'Ġto',\n",
       "  'Ġdiscuss',\n",
       "  'Ġthese',\n",
       "  'Ġitems',\n",
       "  '.',\n",
       "  'Ġi',\n",
       "  'Ġwill',\n",
       "  'Ġhave',\n",
       "  'Ġmy',\n",
       "  'Ġcell',\n",
       "  'Ġphone',\n",
       "  'Ġif',\n",
       "  'Ġanyone',\n",
       "  'Ġneeds',\n",
       "  'Ġme',\n",
       "  '.',\n",
       "  'Ġand',\n",
       "  'Ġsue',\n",
       "  'Ġhad',\n",
       "  'Ġa',\n",
       "  'Ġconversation',\n",
       "  'Ġregarding',\n",
       "  'Ġhelp',\n",
       "  'Ġin',\n",
       "  'Ġthe',\n",
       "  'Ġrisk',\n",
       "  'Ġmg',\n",
       "  'mt',\n",
       "  'Ġarea',\n",
       "  '.',\n",
       "  'Ġi',\n",
       "  'Ġsaw',\n",
       "  'Ġd',\n",
       "  'ave',\n",
       "  'Ġin',\n",
       "  'Ġthe',\n",
       "  'Ġhallway',\n",
       "  'Ġearlier',\n",
       "  'Ġand',\n",
       "  'Ġhe',\n",
       "  'Ġindicated',\n",
       "  'Ġthat',\n",
       "  'Ġhe',\n",
       "  'Ġwanted',\n",
       "  'Ġto',\n",
       "  'Ġrally',\n",
       "  'Ġwith',\n",
       "  'Ġyou',\n",
       "  'Ġand',\n",
       "  'Ġme',\n",
       "  'Ġto',\n",
       "  'Ġdiscuss',\n",
       "  '.',\n",
       "  'Ġi',\n",
       "  'Ġhope',\n",
       "  'Ġto',\n",
       "  'Ġget',\n",
       "  'Ġhim',\n",
       "  'Ġto',\n",
       "  'Ġsend',\n",
       "  'Ġin',\n",
       "  'Ġa',\n",
       "  'Ġrequest',\n",
       "  'Ġthis',\n",
       "  'Ġweek',\n",
       "  '.',\n",
       "  'Ġalso',\n",
       "  ',',\n",
       "  'Ġj',\n",
       "  'ames',\n",
       "  'Ġhas',\n",
       "  'Ġbeen',\n",
       "  'Ġrunning',\n",
       "  'Ġnumbers',\n",
       "  'Ġtoday',\n",
       "  ',',\n",
       "  'Ġso',\n",
       "  'Ġi',\n",
       "  'Ġshould',\n",
       "  'Ġhave',\n",
       "  'Ġa',\n",
       "  'Ġterm',\n",
       "  'Ġsheet',\n",
       "  'Ġfor',\n",
       "  'Ġyou',\n",
       "  'Ġtomorrow',\n",
       "  '.',\n",
       "  'Ġthe',\n",
       "  'Ġag',\n",
       "  'ave',\n",
       "  'Ġchrist',\n",
       "  'mas',\n",
       "  'Ġparty',\n",
       "  'Ġis',\n",
       "  'Ġon',\n",
       "  'Ġt',\n",
       "  'uesday',\n",
       "  ',',\n",
       "  'Ġde',\n",
       "  'cember',\n",
       "  'Ġ11',\n",
       "  '.',\n",
       "  'Ġis',\n",
       "  'Ġit',\n",
       "  'Ġpossible',\n",
       "  'Ġto',\n",
       "  'Ġtake',\n",
       "  'Ġa',\n",
       "  'Ġcompany',\n",
       "  'Ġplane',\n",
       "  'Ġout',\n",
       "  'Ġwith',\n",
       "  'Ġreps',\n",
       "  'Ġfrom',\n",
       "  'Ġmg',\n",
       "  'mt',\n",
       "  ...])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "81baeeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = example_texts[3]\n",
    "token_span = example_texts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6a9f0d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1081, 1086)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d0c308db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġon', 'Ġaug', 'ust', 'Ġ22', '.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9d33f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_trimmed_context_before_span(\n",
    "    tokens = tokens,\n",
    "    token_span = token_span[0],\n",
    "    max_tokens = 1000,\n",
    "    return_text = False,\n",
    "    tokenizer = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e825ae79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġa',\n",
       " 'Ġpizza',\n",
       " 'Ġeating',\n",
       " 'Ġcontest',\n",
       " '?',\n",
       " 'Ġalso',\n",
       " ',',\n",
       " 'Ġthere',\n",
       " 'Ġwas',\n",
       " 'Ġone',\n",
       " 'Ġother',\n",
       " 'Ġhotel',\n",
       " 'Ġin',\n",
       " 'Ġposit',\n",
       " 'ano',\n",
       " 'Ġthat',\n",
       " 'Ġi',\n",
       " 'Ġlooked',\n",
       " 'Ġinto',\n",
       " 'Ġbefore',\n",
       " 'Ġfinding',\n",
       " 'Ġhotel',\n",
       " 'Ġmar',\n",
       " 'inc',\n",
       " 'anto',\n",
       " 'Ġfor',\n",
       " 'Ġour',\n",
       " 'Ġse',\n",
       " 'pt',\n",
       " '.',\n",
       " 'Ġi',\n",
       " 'Ġmay',\n",
       " 'Ġlook',\n",
       " 'Ġthem',\n",
       " 'Ġup',\n",
       " 'Ġtonight',\n",
       " 'Ġand',\n",
       " 'Ġfax',\n",
       " 'Ġthem',\n",
       " 'Ġtomorrow',\n",
       " 'Ġjust',\n",
       " 'Ġto',\n",
       " 'Ġcompare',\n",
       " '.',\n",
       " 'Ġwe',\n",
       " 'Ġalso',\n",
       " 'Ġhave',\n",
       " 'Ġa',\n",
       " 'Ġfax',\n",
       " 'Ġfrom',\n",
       " 'Ġhotel',\n",
       " 'Ġfire',\n",
       " 'n',\n",
       " 'ze',\n",
       " 'Ġin',\n",
       " 'Ġr',\n",
       " 'ome',\n",
       " 'Ġthat',\n",
       " 'Ġwe',\n",
       " 'Ġare',\n",
       " 'Ġconfirmed',\n",
       " 'Ġfor',\n",
       " 'Ġj',\n",
       " 'une',\n",
       " 'Ġ7',\n",
       " 'Ġ8',\n",
       " '!',\n",
       " 'Ġif',\n",
       " 'Ġyou',\n",
       " 'Ġhave',\n",
       " 'Ġno',\n",
       " 'Ġbullets',\n",
       " 'Ġto',\n",
       " 'Ġreport',\n",
       " ',',\n",
       " 'Ġplease',\n",
       " 'Ġreply',\n",
       " 'Ġto',\n",
       " 'Ġme',\n",
       " 'Ġthat',\n",
       " 'Ġyou',\n",
       " 'Ġhave',\n",
       " 'Ġnone',\n",
       " '.',\n",
       " 'Ġthe',\n",
       " 'Ġ131',\n",
       " 'Ġis',\n",
       " 'Ġ100',\n",
       " 'Ġof',\n",
       " 'Ġthe',\n",
       " 'Ġcost',\n",
       " 'Ġof',\n",
       " 'Ġthe',\n",
       " 'Ġproject',\n",
       " '.',\n",
       " 'Ġl',\n",
       " 'or',\n",
       " 'raine',\n",
       " 'Ġwill',\n",
       " 'Ġbe',\n",
       " 'Ġattending',\n",
       " 'Ġfor',\n",
       " 'Ġour',\n",
       " 'Ġgroup',\n",
       " '.',\n",
       " 'Ġwill',\n",
       " 'Ġyou',\n",
       " 'Ġbe',\n",
       " 'Ġable',\n",
       " 'Ġto',\n",
       " 'Ġattend',\n",
       " 'Ġand',\n",
       " 'Ġgive',\n",
       " 'Ġus',\n",
       " 'Ġyour',\n",
       " 'Ġadvise',\n",
       " '?',\n",
       " 'Ġear',\n",
       " 'l',\n",
       " ',',\n",
       " 'Ġas',\n",
       " 'Ġi',\n",
       " 'Ġunderstand',\n",
       " 'Ġit',\n",
       " ',',\n",
       " 'Ġyou',\n",
       " 'Ġhave',\n",
       " 'Ġa',\n",
       " 'Ġcopy',\n",
       " 'Ġalso',\n",
       " '.',\n",
       " 'Ġplease',\n",
       " 'Ġconfirm',\n",
       " 'Ġthat',\n",
       " 'Ġyou',\n",
       " 'Ġhave',\n",
       " 'Ġwhat',\n",
       " 'Ġyou',\n",
       " 'Ġneed',\n",
       " '.',\n",
       " 'Ġi',\n",
       " 'Ġwill',\n",
       " 'Ġsend',\n",
       " 'Ġmy',\n",
       " 'Ġcopy',\n",
       " 'Ġto',\n",
       " 'Ġmans',\n",
       " 'oor',\n",
       " 'Ġunless',\n",
       " 'Ġotherwise',\n",
       " 'Ġdirected',\n",
       " '.',\n",
       " 'Ġalso',\n",
       " ',',\n",
       " 'Ġi',\n",
       " 'Ġhave',\n",
       " 'Ġreceived',\n",
       " 'Ġan',\n",
       " 'Ġinvoice',\n",
       " 'Ġfrom',\n",
       " 'Ġag',\n",
       " 'ave',\n",
       " 'Ġfor',\n",
       " 'Ġ245',\n",
       " ',',\n",
       " '9',\n",
       " '04',\n",
       " '.',\n",
       " 'Ġi',\n",
       " 'Ġbelieve',\n",
       " 'Ġmark',\n",
       " 'Ġm',\n",
       " 'cc',\n",
       " 'on',\n",
       " 'nell',\n",
       " 'Ġfax',\n",
       " 'ed',\n",
       " 'Ġyou',\n",
       " 'Ġa',\n",
       " 'Ġcopy',\n",
       " 'Ġa',\n",
       " 'Ġfew',\n",
       " 'Ġweeks',\n",
       " 'Ġago',\n",
       " '.',\n",
       " 'Ġi',\n",
       " 'Ġneed',\n",
       " 'Ġyou',\n",
       " 'Ġboth',\n",
       " 'Ġto',\n",
       " 'Ġapprove',\n",
       " 'Ġthe',\n",
       " 'Ġinvoice',\n",
       " 'Ġso',\n",
       " 'Ġi',\n",
       " 'Ġcan',\n",
       " 'Ġpay',\n",
       " '.',\n",
       " 'Ġdo',\n",
       " 'Ġeither',\n",
       " 'Ġof',\n",
       " 'Ġyou',\n",
       " 'Ġhave',\n",
       " 'Ġany',\n",
       " 'Ġcomments',\n",
       " 'Ġregarding',\n",
       " 'Ġthis',\n",
       " 'Ġinvoice',\n",
       " '?',\n",
       " 'Ġrich',\n",
       " 'Ġis',\n",
       " 'Ġretiring',\n",
       " 'Ġafter',\n",
       " 'Ġ35',\n",
       " 'Ġyears',\n",
       " 'Ġof',\n",
       " 'Ġservice',\n",
       " '.',\n",
       " 'Ġtiny',\n",
       " ',',\n",
       " 'Ġi',\n",
       " 'Ġjust',\n",
       " 'Ġreceived',\n",
       " 'Ġa',\n",
       " 'Ġmessage',\n",
       " 'Ġthat',\n",
       " 'Ġrich',\n",
       " 'Ġis',\n",
       " 'Ġgoing',\n",
       " 'Ġto',\n",
       " 'Ġretire',\n",
       " 'Ġat',\n",
       " 'Ġthe',\n",
       " 'Ġend',\n",
       " 'Ġof',\n",
       " 'Ġthe',\n",
       " 'Ġmonth',\n",
       " '.',\n",
       " 'Ġi',\n",
       " 'Ġunderstand',\n",
       " 'Ġthat',\n",
       " 'Ġthere',\n",
       " 'Ġis',\n",
       " 'Ġa',\n",
       " 'Ġsurprise',\n",
       " 'Ġlunch',\n",
       " 'Ġfor',\n",
       " 'Ġhim',\n",
       " 'Ġin',\n",
       " 'Ġh',\n",
       " 'ouston',\n",
       " 'Ġon',\n",
       " 'Ġmarch',\n",
       " 'Ġ29',\n",
       " '.',\n",
       " 'Ġlet',\n",
       " 'Ġus',\n",
       " 'Ġknow',\n",
       " ',',\n",
       " 'Ġwe',\n",
       " \"'d\",\n",
       " 'Ġlike',\n",
       " 'Ġto',\n",
       " 'Ġmeet',\n",
       " 'Ġwith',\n",
       " 'Ġyou',\n",
       " 'Ġif',\n",
       " 'Ġyou',\n",
       " 'Ġare',\n",
       " 'Ġgoing',\n",
       " 'Ġto',\n",
       " 'Ġbe',\n",
       " 'Ġin',\n",
       " 'Ġtown',\n",
       " '.',\n",
       " 'Ġdid',\n",
       " 'Ġyou',\n",
       " 'Ġreceive',\n",
       " 'Ġthe',\n",
       " 'Ġ50',\n",
       " 'Ġcheck',\n",
       " 'Ġi',\n",
       " 'Ġsent',\n",
       " 'Ġyou',\n",
       " 'Ġfor',\n",
       " 'Ġrich',\n",
       " \"'s\",\n",
       " 'Ġgift',\n",
       " '?',\n",
       " 'Ġwhen',\n",
       " 'Ġi',\n",
       " 'Ġwas',\n",
       " 'Ġreconcil',\n",
       " 'ing',\n",
       " 'Ġmy',\n",
       " 'Ġchecking',\n",
       " 'Ġaccount',\n",
       " 'Ġa',\n",
       " 'Ġcouple',\n",
       " 'Ġof',\n",
       " 'Ġweeks',\n",
       " 'Ġago',\n",
       " ',',\n",
       " 'Ġi',\n",
       " 'Ġnoticed',\n",
       " 'Ġit',\n",
       " 'Ġhad',\n",
       " 'Ġnot',\n",
       " 'Ġcleared',\n",
       " 'Ġyet',\n",
       " '.',\n",
       " 'Ġi',\n",
       " 'Ġjust',\n",
       " 'Ġwant',\n",
       " 'Ġto',\n",
       " 'Ġmake',\n",
       " 'Ġsure',\n",
       " 'Ġit',\n",
       " 'Ġdid',\n",
       " 'Ġnot',\n",
       " 'Ġget',\n",
       " 'Ġlost',\n",
       " 'Ġin',\n",
       " 'Ġthe',\n",
       " 'Ġmail',\n",
       " '.',\n",
       " 'Ġdear',\n",
       " 'Ġg',\n",
       " 'ary',\n",
       " 'Ġand',\n",
       " 'Ġfr',\n",
       " 'an',\n",
       " ',',\n",
       " 'Ġattached',\n",
       " ',',\n",
       " 'Ġplease',\n",
       " 'Ġfind',\n",
       " 'Ġa',\n",
       " 'Ġresignation',\n",
       " 'Ġletter',\n",
       " 'Ġfrom',\n",
       " 'Ġboth',\n",
       " 'Ġme',\n",
       " 'Ġand',\n",
       " 'Ġl',\n",
       " 'or',\n",
       " 'raine',\n",
       " 'Ġl',\n",
       " 'ind',\n",
       " 'berg',\n",
       " '.',\n",
       " 'Ġif',\n",
       " 'Ġyou',\n",
       " 'Ġwould',\n",
       " 'Ġlike',\n",
       " 'Ġa',\n",
       " 'Ġsigned',\n",
       " 'Ġhard',\n",
       " 'Ġcopy',\n",
       " ',',\n",
       " 'Ġjust',\n",
       " 'Ġlet',\n",
       " 'Ġme',\n",
       " 'Ġknow',\n",
       " ',',\n",
       " 'Ġi',\n",
       " 'Ġwould',\n",
       " 'Ġbe',\n",
       " 'Ġhappy',\n",
       " 'Ġto',\n",
       " 'Ġprovide',\n",
       " 'Ġit',\n",
       " 'Ġto',\n",
       " 'Ġyou',\n",
       " '.',\n",
       " 'Ġl',\n",
       " 'or',\n",
       " 'raine',\n",
       " 'Ġhas',\n",
       " 'Ġalso',\n",
       " 'Ġindicated',\n",
       " 'Ġthat',\n",
       " 'Ġshe',\n",
       " 'Ġwould',\n",
       " 'Ġprovide',\n",
       " 'Ġyou',\n",
       " 'Ġa',\n",
       " 'Ġsigned',\n",
       " 'Ġhard',\n",
       " 'Ġcopy',\n",
       " ',',\n",
       " 'Ġtoo',\n",
       " '.',\n",
       " 'Ġat',\n",
       " 'Ġyour',\n",
       " 'Ġconv',\n",
       " 'ience',\n",
       " ',',\n",
       " 'Ġi',\n",
       " 'Ġwould',\n",
       " 'Ġlike',\n",
       " 'Ġto',\n",
       " 'Ġvisit',\n",
       " 'Ġwith',\n",
       " 'Ġeach',\n",
       " 'Ġof',\n",
       " 'Ġyou',\n",
       " '.',\n",
       " 'Ġamy',\n",
       " ',',\n",
       " 'Ġhere',\n",
       " 'Ġis',\n",
       " 'Ġthe',\n",
       " 'Ġopen',\n",
       " 'Ġseason',\n",
       " 'Ġdocument',\n",
       " 'Ġon',\n",
       " 'Ġour',\n",
       " 'Ġsun',\n",
       " 'Ġdevil',\n",
       " 'Ġexpansion',\n",
       " '.',\n",
       " 'Ġplease',\n",
       " 'Ġcall',\n",
       " 'Ġme',\n",
       " 'Ġif',\n",
       " 'Ġyou',\n",
       " 'Ġhave',\n",
       " 'Ġany',\n",
       " 'Ġquestions',\n",
       " '.',\n",
       " 'Ġi',\n",
       " 'Ġwould',\n",
       " 'Ġlove',\n",
       " 'Ġto',\n",
       " 'Ġvisit',\n",
       " 'Ġwith',\n",
       " 'Ġyou',\n",
       " 'Ġand',\n",
       " 'Ġshare',\n",
       " 'Ġwith',\n",
       " 'Ġyou',\n",
       " 'Ġsome',\n",
       " 'Ġof',\n",
       " 'Ġthe',\n",
       " 'Ġthings',\n",
       " 'Ġwe',\n",
       " 'Ġhave',\n",
       " 'Ġbeen',\n",
       " 'Ġworking',\n",
       " 'Ġon',\n",
       " 'Ġto',\n",
       " 'Ġensure',\n",
       " 'Ġa',\n",
       " 'Ġsmooth',\n",
       " 'Ġtransition',\n",
       " '.',\n",
       " 'Ġt',\n",
       " 'uesday',\n",
       " 'Ġis',\n",
       " 'Ġpossible',\n",
       " ',',\n",
       " 'Ġi',\n",
       " 'Ġwould',\n",
       " 'Ġneed',\n",
       " 'Ġto',\n",
       " 'Ġmove',\n",
       " 'Ġanother',\n",
       " 'Ġappointment',\n",
       " '.',\n",
       " 'Ġhere',\n",
       " 'Ġis',\n",
       " 'Ġa',\n",
       " 'Ġstart',\n",
       " 'Ġto',\n",
       " 'Ġthe',\n",
       " 'Ġbullets',\n",
       " '.',\n",
       " 'Ġthank',\n",
       " 'Ġyou',\n",
       " 'Ġfor',\n",
       " 'Ġhandling',\n",
       " 'Ġthis',\n",
       " 'Ġfor',\n",
       " 'Ġthe',\n",
       " 'Ġteam',\n",
       " 'Ġtoday',\n",
       " '!',\n",
       " 'Ġste',\n",
       " 've',\n",
       " ',',\n",
       " 'Ġwhile',\n",
       " 'Ġi',\n",
       " 'Ġam',\n",
       " 'Ġchecking',\n",
       " 'Ġon',\n",
       " 'Ġthis',\n",
       " 'Ġitems',\n",
       " 'Ġwe',\n",
       " 'Ġdiscussed',\n",
       " ',',\n",
       " 'Ġhere',\n",
       " 'Ġis',\n",
       " 'Ġa',\n",
       " 'Ġdraft',\n",
       " 'Ġcopy',\n",
       " 'Ġof',\n",
       " 'Ġboth',\n",
       " 'Ġproposals',\n",
       " '.',\n",
       " 'Ġplease',\n",
       " 'Ġnote',\n",
       " 'Ġthat',\n",
       " 'Ġi',\n",
       " 'Ġhave',\n",
       " 'Ġgiven',\n",
       " 'Ġthem',\n",
       " 'Ġ60',\n",
       " 'Ġdays',\n",
       " 'Ġto',\n",
       " 'Ġrespond',\n",
       " '.',\n",
       " 'Ġthat',\n",
       " 'Ġmay',\n",
       " 'Ġbe',\n",
       " 'Ġtoo',\n",
       " 'Ġlong',\n",
       " 'Ġfor',\n",
       " 'Ġthe',\n",
       " 'Ġred',\n",
       " 'Ġrock',\n",
       " 'Ġproposal',\n",
       " '.',\n",
       " 'Ġlet',\n",
       " 'Ġme',\n",
       " 'Ġknow',\n",
       " 'Ġif',\n",
       " 'Ġyou',\n",
       " 'Ġwould',\n",
       " 'Ġlike',\n",
       " 'Ġone',\n",
       " 'Ġor',\n",
       " 'Ġboth',\n",
       " 'Ġtime',\n",
       " 'frames',\n",
       " 'Ġchanged',\n",
       " '.',\n",
       " 'Ġi',\n",
       " \"'ll\",\n",
       " 'Ġvisit',\n",
       " 'Ġwith',\n",
       " 'Ġyou',\n",
       " 'Ġby',\n",
       " 'Ġvoice',\n",
       " 'Ġmail',\n",
       " 'Ġas',\n",
       " 'Ġi',\n",
       " 'Ġget',\n",
       " 'Ġan',\n",
       " 'Ġanswer',\n",
       " 'Ġfrom',\n",
       " 'Ġd',\n",
       " 'ennis',\n",
       " 'Ġtu',\n",
       " '.',\n",
       " 'Ġd',\n",
       " 'ave',\n",
       " ',',\n",
       " 'Ġmay',\n",
       " 'Ġi',\n",
       " 'Ġask',\n",
       " 'Ġyou',\n",
       " 'Ġto',\n",
       " 'Ġtake',\n",
       " 'Ġa',\n",
       " 'Ġlook',\n",
       " 'Ġat',\n",
       " 'Ġthis',\n",
       " 'Ġspreadsheet',\n",
       " ',',\n",
       " 'Ġplease',\n",
       " '?',\n",
       " 'Ġste',\n",
       " 've',\n",
       " 'Ġand',\n",
       " 'Ġi',\n",
       " 'Ġare',\n",
       " 'Ġhoping',\n",
       " 'Ġto',\n",
       " 'Ġconnect',\n",
       " 'Ġup',\n",
       " 'Ġwith',\n",
       " 'Ġd',\n",
       " 'anny',\n",
       " 'Ġtomorrow',\n",
       " 'Ġafternoon',\n",
       " 'Ġand',\n",
       " 'Ġdiscuss',\n",
       " 'Ġboth',\n",
       " 'Ġour',\n",
       " 'Ġfuel',\n",
       " 'Ġstrategy',\n",
       " 'Ġand',\n",
       " 'Ġour',\n",
       " 'Ġindex',\n",
       " 'Ġto',\n",
       " 'Ġindex',\n",
       " 'Ġdeal',\n",
       " 'Ġstrategy',\n",
       " '.',\n",
       " 'Ġi',\n",
       " 'Ġhave',\n",
       " 'Ġput',\n",
       " 'Ġtogether',\n",
       " 'Ġsome',\n",
       " 'Ġnumbers',\n",
       " 'Ġon',\n",
       " 'Ġthe',\n",
       " 'Ġi',\n",
       " 'Ġto',\n",
       " 'Ġi',\n",
       " 'Ġdeals',\n",
       " ',',\n",
       " 'Ġbut',\n",
       " 'Ġi',\n",
       " 'Ġwould',\n",
       " 'Ġlike',\n",
       " 'Ġto',\n",
       " 'Ġdiscuss',\n",
       " 'Ġthem',\n",
       " 'Ġwith',\n",
       " 'Ġyou',\n",
       " 'Ġto',\n",
       " 'Ġmake',\n",
       " 'Ġsure',\n",
       " 'Ġi',\n",
       " 'Ġam',\n",
       " 'Ġnot',\n",
       " 'Ġmissing',\n",
       " 'Ġanything',\n",
       " '.',\n",
       " 'Ġalthough',\n",
       " 'Ġl',\n",
       " 'arry',\n",
       " 'Ġpav',\n",
       " 'l',\n",
       " 'ou',\n",
       " 'Ġis',\n",
       " 'Ġon',\n",
       " 'Ġvacation',\n",
       " 'Ġtomorrow',\n",
       " ',',\n",
       " 'Ġhe',\n",
       " 'Ġwill',\n",
       " 'Ġbe',\n",
       " 'Ġconf',\n",
       " 'eren',\n",
       " 'ced',\n",
       " 'Ġinto',\n",
       " 'Ġour',\n",
       " 'Ġmeeting',\n",
       " '.',\n",
       " 'Ġyou',\n",
       " 'Ġare',\n",
       " 'Ġalso',\n",
       " 'Ġwelcome',\n",
       " 'Ġto',\n",
       " 'Ġjoin',\n",
       " 'Ġour',\n",
       " 'Ġmeeting',\n",
       " 'Ġif',\n",
       " 'Ġyou',\n",
       " 'Ġare',\n",
       " 'Ġavailable',\n",
       " '.',\n",
       " 'Ġit',\n",
       " 'Ġis',\n",
       " 'Ġthat',\n",
       " 'Ġtime',\n",
       " 'Ġof',\n",
       " 'Ġyear',\n",
       " 'Ġplease',\n",
       " 'Ġcomplete',\n",
       " 'Ġyour',\n",
       " 'Ġlist',\n",
       " 'Ġof',\n",
       " 'Ġaccomplishments',\n",
       " 'Ġby',\n",
       " 'Ġthe',\n",
       " 'Ġend',\n",
       " 'Ġof',\n",
       " 'Ġno',\n",
       " 've',\n",
       " 'mber',\n",
       " '.',\n",
       " 'Ġalso',\n",
       " ',',\n",
       " 'Ġplease',\n",
       " 'Ġcomplete',\n",
       " 'Ġyour',\n",
       " 'Ġ2002',\n",
       " 'Ġobjectives',\n",
       " 'Ġby',\n",
       " 'Ġde',\n",
       " 'cember',\n",
       " 'Ġ14',\n",
       " '.',\n",
       " 'Ġyour',\n",
       " 'Ġobjectives',\n",
       " 'Ġwill',\n",
       " 'Ġneed',\n",
       " 'Ġto',\n",
       " 'Ġoutline',\n",
       " 'Ġyour',\n",
       " 'Ġspecific',\n",
       " 'Ġmarketing',\n",
       " 'Ġplan',\n",
       " 'Ġfor',\n",
       " 'Ġeach',\n",
       " 'Ġcustomer',\n",
       " ',',\n",
       " 'Ġproject',\n",
       " 'Ġand',\n",
       " 'Ġidea',\n",
       " 'Ġyou',\n",
       " 'Ġmay',\n",
       " 'Ġhave',\n",
       " 'Ġfor',\n",
       " 'Ġadding',\n",
       " '/',\n",
       " 'increasing',\n",
       " 'Ġvalue',\n",
       " 'Ġto',\n",
       " 'Ġtrans',\n",
       " 'western',\n",
       " 'Ġin',\n",
       " 'Ġ2002',\n",
       " '.',\n",
       " 'Ġas',\n",
       " 'Ġdiscussed',\n",
       " 'Ġearlier',\n",
       " ',',\n",
       " 'Ġwe',\n",
       " 'Ġwill',\n",
       " 'Ġget',\n",
       " 'Ġtogether',\n",
       " 'Ġin',\n",
       " 'Ġmid',\n",
       " '-',\n",
       " 'de',\n",
       " 'cember',\n",
       " 'Ġto',\n",
       " 'Ġreview',\n",
       " 'Ġaccount',\n",
       " 'Ġloads',\n",
       " 'Ġto',\n",
       " 'Ġsee',\n",
       " 'Ġif',\n",
       " 'Ġwe',\n",
       " 'Ġneed',\n",
       " 'Ġto',\n",
       " 'Ġdo',\n",
       " 'Ġany',\n",
       " 'Ġshifting',\n",
       " '.',\n",
       " 'Ġyour',\n",
       " 'Ġ2002',\n",
       " 'Ġobjectives',\n",
       " 'Ġwill',\n",
       " 'Ġbe',\n",
       " 'Ġhelpful',\n",
       " 'Ġin',\n",
       " 'Ġdetermining',\n",
       " 'Ġwhether',\n",
       " 'Ġyour',\n",
       " 'Ġload',\n",
       " 'Ġis',\n",
       " 'Ġheavy',\n",
       " ',',\n",
       " 'Ġlight',\n",
       " 'Ġor',\n",
       " 'Ġjust',\n",
       " 'Ġright',\n",
       " '.',\n",
       " 'Ġi',\n",
       " 'Ġwill',\n",
       " 'Ġbe',\n",
       " 'Ġhappy',\n",
       " 'Ġto',\n",
       " 'Ġvisit',\n",
       " 'Ġwith',\n",
       " 'Ġeach',\n",
       " 'Ġof',\n",
       " 'Ġyou',\n",
       " 'Ġindividually',\n",
       " 'Ġif',\n",
       " 'Ġyou',\n",
       " 'Ġhave',\n",
       " 'Ġany',\n",
       " 'Ġquestions',\n",
       " 'Ġor',\n",
       " 'Ġwould',\n",
       " 'Ġlike',\n",
       " 'Ġto',\n",
       " 'Ġdiscuss',\n",
       " 'Ġthese',\n",
       " 'Ġitems',\n",
       " '.',\n",
       " 'Ġi',\n",
       " 'Ġwill',\n",
       " 'Ġhave',\n",
       " 'Ġmy',\n",
       " 'Ġcell',\n",
       " 'Ġphone',\n",
       " 'Ġif',\n",
       " 'Ġanyone',\n",
       " 'Ġneeds',\n",
       " 'Ġme',\n",
       " '.',\n",
       " 'Ġand',\n",
       " 'Ġsue',\n",
       " 'Ġhad',\n",
       " 'Ġa',\n",
       " 'Ġconversation',\n",
       " 'Ġregarding',\n",
       " 'Ġhelp',\n",
       " 'Ġin',\n",
       " 'Ġthe',\n",
       " 'Ġrisk',\n",
       " 'Ġmg',\n",
       " 'mt',\n",
       " 'Ġarea',\n",
       " '.',\n",
       " 'Ġi',\n",
       " 'Ġsaw',\n",
       " 'Ġd',\n",
       " 'ave',\n",
       " 'Ġin',\n",
       " 'Ġthe',\n",
       " 'Ġhallway',\n",
       " 'Ġearlier',\n",
       " 'Ġand',\n",
       " 'Ġhe',\n",
       " 'Ġindicated',\n",
       " 'Ġthat',\n",
       " 'Ġhe',\n",
       " 'Ġwanted',\n",
       " 'Ġto',\n",
       " 'Ġrally',\n",
       " 'Ġwith',\n",
       " 'Ġyou',\n",
       " 'Ġand',\n",
       " 'Ġme',\n",
       " 'Ġto',\n",
       " 'Ġdiscuss',\n",
       " '.',\n",
       " 'Ġi',\n",
       " 'Ġhope',\n",
       " 'Ġto',\n",
       " 'Ġget',\n",
       " 'Ġhim',\n",
       " 'Ġto',\n",
       " 'Ġsend',\n",
       " 'Ġin',\n",
       " 'Ġa',\n",
       " 'Ġrequest',\n",
       " 'Ġthis',\n",
       " 'Ġweek',\n",
       " '.',\n",
       " 'Ġalso',\n",
       " ',',\n",
       " 'Ġj',\n",
       " 'ames',\n",
       " 'Ġhas',\n",
       " 'Ġbeen',\n",
       " 'Ġrunning',\n",
       " 'Ġnumbers',\n",
       " 'Ġtoday',\n",
       " ',',\n",
       " 'Ġso',\n",
       " 'Ġi',\n",
       " 'Ġshould',\n",
       " 'Ġhave',\n",
       " 'Ġa',\n",
       " 'Ġterm',\n",
       " 'Ġsheet',\n",
       " 'Ġfor',\n",
       " 'Ġyou',\n",
       " 'Ġtomorrow',\n",
       " '.',\n",
       " 'Ġthe',\n",
       " 'Ġag',\n",
       " 'ave',\n",
       " 'Ġchrist',\n",
       " 'mas',\n",
       " 'Ġparty',\n",
       " 'Ġis',\n",
       " 'Ġon',\n",
       " 'Ġt',\n",
       " 'uesday',\n",
       " ',',\n",
       " 'Ġde',\n",
       " 'cember',\n",
       " 'Ġ11',\n",
       " '.',\n",
       " 'Ġis',\n",
       " 'Ġit',\n",
       " 'Ġpossible',\n",
       " 'Ġto',\n",
       " 'Ġtake',\n",
       " 'Ġa',\n",
       " 'Ġcompany',\n",
       " 'Ġplane',\n",
       " 'Ġout',\n",
       " 'Ġwith',\n",
       " 'Ġreps',\n",
       " 'Ġfrom',\n",
       " 'Ġmg',\n",
       " 'mt',\n",
       " ',',\n",
       " 'Ġm',\n",
       " 'kt',\n",
       " 'g',\n",
       " ',',\n",
       " 'Ġgas',\n",
       " 'Ġlogistics',\n",
       " 'Ġand',\n",
       " 'Ġoperations',\n",
       " '?',\n",
       " 'Ġwe',\n",
       " 'Ġare',\n",
       " 'Ġalso',\n",
       " 'Ġrunning',\n",
       " 'Ġa',\n",
       " 'Ġfew',\n",
       " 'Ġmore',\n",
       " 'Ġscenarios',\n",
       " 'Ġfor',\n",
       " 'Ġtrans',\n",
       " 'pe',\n",
       " 'cos',\n",
       " '.',\n",
       " 'Ġstep',\n",
       " 'han',\n",
       " 'ie',\n",
       " ',',\n",
       " 'Ġhere',\n",
       " 'Ġis',\n",
       " 'Ġthe',\n",
       " 'Ġsun',\n",
       " 'Ġdevil',\n",
       " 'Ġexpansion',\n",
       " 'Ġpackage',\n",
       " '.',\n",
       " 'Ġplease',\n",
       " 'Ġreview',\n",
       " 'Ġand',\n",
       " 'Ġforward',\n",
       " 'Ġon',\n",
       " 'Ġto',\n",
       " 'Ġthose',\n",
       " 'Ġin',\n",
       " 'Ġyour',\n",
       " 'Ġgroup',\n",
       " 'Ġwho',\n",
       " 'Ġmay',\n",
       " 'Ġhave',\n",
       " 'Ġan',\n",
       " 'Ġinterest',\n",
       " '.',\n",
       " 'Ġwe',\n",
       " 'Ġwould',\n",
       " 'Ġbe',\n",
       " 'Ġhappy',\n",
       " 'Ġto',\n",
       " 'Ġdiscuss',\n",
       " 'Ġthis',\n",
       " 'Ġexpansion',\n",
       " 'Ġopportunity',\n",
       " 'Ġwith',\n",
       " 'Ġyou',\n",
       " 'Ġat',\n",
       " 'Ġyour',\n",
       " 'Ġconvenience',\n",
       " '.',\n",
       " 'Ġtake',\n",
       " 'Ġa',\n",
       " 'Ġlook',\n",
       " 'Ġand',\n",
       " 'Ġi',\n",
       " \"'ll\",\n",
       " 'Ġgive',\n",
       " 'Ġyou',\n",
       " 'Ġa',\n",
       " 'Ġcall',\n",
       " 'Ġlate',\n",
       " 'Ġthis',\n",
       " 'Ġafternoon',\n",
       " 'Ġto',\n",
       " 'Ġdiscuss',\n",
       " ...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b0c419c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1005"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "caaad655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.', 'Ġi', 'Ġwould', 'Ġlike', 'Ġto']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fbf261ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġlate', 'Ġthis', 'Ġafternoon', 'Ġto', 'Ġdiscuss']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0][-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f41716",
   "metadata": {},
   "source": [
    "## Find Positions all Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f641e35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(571, 573)]\n",
      "Phrase: , as - Span: [(571, 573)]\n",
      "[(390, 392)]\n",
      "Phrase: , but - Span: [(390, 392)]\n",
      "[(144, 146), (621, 623)]\n",
      "Phrase: . if - Span: [(144, 146), (621, 623)]\n",
      "[(443, 445)]\n",
      "Phrase: . the - Span: [(443, 445)]\n",
      "[(671, 673)]\n",
      "Phrase: ie, - Span: [(671, 673)]\n",
      "[(257, 259)]\n",
      "Phrase:  a draft - Span: [(257, 259)]\n",
      "[(29, 31)]\n",
      "Phrase:  a fax - Span: [(29, 31)]\n",
      "[(72, 74)]\n",
      "Phrase:  and he - Span: [(72, 74)]\n",
      "[(183, 185), (614, 616)]\n",
      "Phrase:  and i - Span: [(183, 185), (614, 616)]\n",
      "[(442, 444)]\n",
      "Phrase:  area. - Span: [(442, 444)]\n",
      "[(556, 558), (806, 808)]\n",
      "Phrase:  call me - Span: [(556, 558), (806, 808)]\n",
      "[(47, 49)]\n",
      "Phrase:  did not - Span: [(47, 49)]\n",
      "[(97, 99)]\n",
      "Phrase:  do not - Span: [(97, 99)]\n",
      "[(101, 103), (278, 280), (785, 787)]\n",
      "Phrase:  for the - Span: [(101, 103), (278, 280), (785, 787)]\n",
      "[(256, 258), (464, 466), (654, 656), (797, 799)]\n",
      "Phrase:  have a - Span: [(256, 258), (464, 466), (654, 656), (797, 799)]\n",
      "[(484, 486)]\n",
      "Phrase:  help in - Span: [(484, 486)]\n",
      "[(193, 195)]\n",
      "Phrase:  him to - Span: [(193, 195)]\n",
      "[(529, 531)]\n",
      "Phrase:  i am - Span: [(529, 531)]\n",
      "[(246, 248), (540, 542), (615, 617), (754, 756)]\n",
      "Phrase:  i can - Span: [(246, 248), (540, 542), (615, 617), (754, 756)]\n",
      "[(345, 347)]\n",
      "Phrase:  i need - Span: [(345, 347)]\n",
      "[(27, 29)]\n",
      "Phrase:  i sent - Span: [(27, 29)]\n",
      "[(622, 624)]\n",
      "Phrase:  if we - Span: [(622, 624)]\n",
      "[(137, 139)]\n",
      "Phrase:  in 2002 - Span: [(137, 139)]\n",
      "[(300, 302), (437, 439)]\n",
      "Phrase:  in the - Span: [(300, 302), (437, 439)]\n",
      "[(749, 751)]\n",
      "Phrase:  it is - Span: [(749, 751)]\n",
      "[(167, 169)]\n",
      "Phrase:  june - Span: [(167, 169)]\n",
      "[(807, 809)]\n",
      "Phrase:  me. - Span: [(807, 809)]\n",
      "[(76, 78)]\n",
      "Phrase:  me that - Span: [(76, 78)]\n",
      "[(223, 225)]\n",
      "Phrase:  me to - Span: [(223, 225)]\n",
      "[(283, 285)]\n",
      "Phrase:  meeting. - Span: [(283, 285)]\n",
      "[(346, 348)]\n",
      "Phrase:  need to - Span: [(346, 348)]\n",
      "[(98, 100)]\n",
      "Phrase:  not get - Span: [(98, 100)]\n",
      "[(6, 8), (147, 149), (704, 706), (730, 732)]\n",
      "Phrase:  of you - Span: [(6, 8), (147, 149), (704, 706), (730, 732)]\n",
      "[(386, 388)]\n",
      "Phrase:  on the - Span: [(386, 388)]\n",
      "[(11, 13), (322, 324)]\n",
      "Phrase:  on this - Span: [(11, 13), (322, 324)]\n",
      "[(205, 207)]\n",
      "Phrase:  on to - Span: [(205, 207)]\n",
      "[(146, 148)]\n",
      "Phrase:  one of - Span: [(146, 148)]\n",
      "[(330, 332)]\n",
      "Phrase:  red rock - Span: [(330, 332)]\n",
      "[(218, 220)]\n",
      "Phrase:  steve - Span: [(218, 220)]\n",
      "[(603, 605)]\n",
      "Phrase:  tuesday - Span: [(603, 605)]\n",
      "[(26, 28)]\n",
      "Phrase:  that i - Span: [(26, 28)]\n",
      "[(260, 262), (268, 270)]\n",
      "Phrase:  the bullets - Span: [(260, 262), (268, 270)]\n",
      "[(32, 34), (174, 176), (522, 524), (709, 711), (723, 725)]\n",
      "Phrase:  this week - Span: [(32, 34), (174, 176), (522, 524), (709, 711), (723, 725)]\n",
      "[(176, 178)]\n",
      "Phrase:  to be - Span: [(176, 178)]\n",
      "[(93, 95)]\n",
      "Phrase:  to ensure - Span: [(93, 95)]\n",
      "[(224, 226)]\n",
      "Phrase:  to get - Span: [(224, 226)]\n",
      "[(774, 776)]\n",
      "Phrase:  to send - Span: [(774, 776)]\n",
      "[(206, 208), (297, 299)]\n",
      "Phrase:  to the - Span: [(206, 208), (297, 299)]\n",
      "[(773, 775)]\n",
      "Phrase:  wanted to - Span: [(773, 775)]\n",
      "[(213, 215)]\n",
      "Phrase:  week. - Span: [(213, 215)]\n",
      "[(673, 675)]\n",
      "Phrase:  when i - Span: [(673, 675)]\n",
      "[(595, 597)]\n",
      "Phrase:  will have - Span: [(595, 597)]\n",
      "[(161, 163)]\n",
      "Phrase:  would be - Span: [(161, 163)]\n",
      "[(620, 622)]\n",
      "Phrase:  you. - Span: [(620, 622)]\n",
      "[(235, 237), (482, 484)]\n",
      "Phrase:  you need - Span: [(235, 237), (482, 484)]\n",
      "[(23, 25), (731, 733)]\n",
      "Phrase:  you to - Span: [(23, 25), (731, 733)]\n",
      "[(563, 566)]\n",
      "Phrase: 'd like to - Span: [(563, 566)]\n",
      "[(254, 257)]\n",
      "Phrase: , i have - Span: [(254, 257)]\n",
      "[(19, 22)]\n",
      "Phrase: , i just - Span: [(19, 22)]\n",
      "[(373, 376)]\n",
      "Phrase: , i noticed - Span: [(373, 376)]\n",
      "[(55, 58)]\n",
      "Phrase: , so i - Span: [(55, 58)]\n",
      "[(104, 107)]\n",
      "Phrase: . i have - Span: [(104, 107)]\n",
      "[(740, 743)]\n",
      "Phrase: . i just - Span: [(740, 743)]\n",
      "[(446, 449)]\n",
      "Phrase:  cost of the - Span: [(446, 449)]\n",
      "[(105, 108)]\n",
      "Phrase:  i have received - Span: [(105, 108)]\n",
      "[(608, 611)]\n",
      "Phrase:  in houston - Span: [(608, 611)]\n",
      "[(113, 116)]\n",
      "Phrase:  in rome - Span: [(113, 116)]\n",
      "[(238, 241)]\n",
      "Phrase:  our group. - Span: [(238, 241)]\n",
      "[(379, 382)]\n",
      "Phrase:  some of the - Span: [(379, 382)]\n",
      "[(745, 748)]\n",
      "Phrase:  that you have - Span: [(745, 748)]\n",
      "[(347, 350)]\n",
      "Phrase:  to meet with - Span: [(347, 350)]\n",
      "[(156, 159)]\n",
      "Phrase:  to see if - Span: [(156, 159)]\n",
      "[(226, 229)]\n",
      "Phrase:  with you and - Span: [(226, 229)]\n",
      "[(577, 581)]\n",
      "Phrase: , here is the - Span: [(577, 581)]\n",
      "[(371, 375)]\n",
      "Phrase: . also, i - Span: [(371, 375)]\n",
      "[(455, 459)]\n",
      "Phrase: . please review and - Span: [(455, 459)]\n",
      "[(701, 705)]\n",
      "Phrase:  at the end of - Span: [(701, 705)]\n",
      "[(37, 41)]\n",
      "Phrase:  hotel in positano - Span: [(37, 41)]\n",
      "[(41, 45)]\n",
      "Phrase:  hotel marincanto - Span: [(41, 45)]\n",
      "[(537, 541)]\n",
      "Phrase:  sept. i - Span: [(537, 541)]\n",
      "[(517, 521)]\n",
      "Phrase:  to connect up with - Span: [(517, 521)]\n",
      "[(364, 368)]\n",
      "Phrase:  to visit with you - Span: [(364, 368)]\n",
      "[(419, 424)]\n",
      "Phrase: , attached, please find - Span: [(419, 424)]\n",
      "[(513, 518)]\n",
      "Phrase: . i would like to - Span: [(513, 518)]\n",
      "[(240, 245), (588, 593)]\n",
      "Phrase: . please let me know - Span: [(240, 245), (588, 593)]\n",
      "[(524, 529)]\n",
      "Phrase:  if you are available. - Span: [(524, 529)]\n",
      "[(477, 483)]\n",
      "Phrase: . let me know if you - Span: [(477, 483)]\n",
      "[(462, 468)]\n",
      "Phrase:  if you have any questions or - Span: [(462, 468)]\n",
      "[(360, 367)]\n",
      "Phrase: , i would like to visit with - Span: [(360, 367)]\n",
      "[(632, 639)]\n",
      "Phrase:  let me know if you would like - Span: [(632, 639)]\n"
     ]
    }
   ],
   "source": [
    "for com in common:\n",
    "    test_text = tokens_to_text(com, tokenizer)\n",
    "    \n",
    "    prefixes, tok_spans = texts_around_each_ngram(known_text, test_text, return_token_spans=True, tokenizer=tokenizer)\n",
    "    \n",
    "    print(f\"Phrase: {test_text} - Span: {tok_spans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7fe37391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(200, 202)]\n",
      "Phrase: , as - Best span: (200, 202) (highest=202)\n",
      "[(703, 705)]\n",
      "Phrase: , but - Best span: (703, 705) (highest=705)\n",
      "[(55, 57), (431, 433)]\n",
      "Phrase: . if - Best span: (431, 433) (highest=433)\n",
      "[(164, 166), (970, 972)]\n",
      "Phrase: . the - Best span: (970, 972) (highest=972)\n",
      "[(1025, 1027)]\n",
      "Phrase: ie, - Best span: (1025, 1027) (highest=1027)\n",
      "[(584, 586)]\n",
      "Phrase:  a draft - Best span: (584, 586) (highest=586)\n",
      "[(128, 130)]\n",
      "Phrase:  a fax - Best span: (128, 130) (highest=130)\n",
      "[(922, 924)]\n",
      "Phrase:  and he - Best span: (922, 924) (highest=924)\n",
      "[(665, 667), (803, 805), (1069, 1071)]\n",
      "Phrase:  and i - Best span: (1069, 1071) (highest=1071)\n",
      "[(912, 914)]\n",
      "Phrase:  area. - Best span: (912, 914) (highest=914)\n",
      "[(504, 506)]\n",
      "Phrase:  call me - Best span: (504, 506) (highest=506)\n",
      "[(399, 401)]\n",
      "Phrase:  did not - Best span: (399, 401) (highest=401)\n",
      "[(26, 28)]\n",
      "Phrase:  do not - Best span: (26, 28) (highest=28)\n",
      "[(61, 63), (564, 566), (608, 610)]\n",
      "Phrase:  for the - Best span: (608, 610) (highest=610)\n",
      "[(80, 82), (127, 129), (207, 209), (283, 285), (508, 510), (878, 880), (963, 965), (1047, 1049)]\n",
      "Phrase:  have a - Best span: (1047, 1049) (highest=1049)\n",
      "[(906, 908)]\n",
      "Phrase:  help in - Best span: (906, 908) (highest=908)\n",
      "[(941, 943)]\n",
      "Phrase:  him to - Best span: (941, 943) (highest=943)\n",
      "[(573, 575), (716, 718)]\n",
      "Phrase:  i am - Best span: (716, 718) (highest=718)\n",
      "[(275, 277)]\n",
      "Phrase:  i can - Best span: (275, 277) (highest=277)\n",
      "[(266, 268)]\n",
      "Phrase:  i need - Best span: (266, 268) (highest=268)\n",
      "[(362, 364)]\n",
      "Phrase:  i sent - Best span: (362, 364) (highest=364)\n",
      "[(838, 840)]\n",
      "Phrase:  if we - Best span: (838, 840) (highest=840)\n",
      "[(816, 818)]\n",
      "Phrase:  in 2002 - Best span: (816, 818) (highest=818)\n",
      "[(403, 405), (907, 909), (918, 920)]\n",
      "Phrase:  in the - Best span: (918, 920) (highest=920)\n",
      "[(756, 758)]\n",
      "Phrase:  it is - Best span: (756, 758) (highest=758)\n",
      "[(143, 145)]\n",
      "Phrase:  june - Best span: (143, 145) (highest=145)\n",
      "[(898, 900)]\n",
      "Phrase:  me. - Best span: (898, 900) (highest=900)\n",
      "[(159, 161)]\n",
      "Phrase:  me that - Best span: (159, 161) (highest=161)\n",
      "[(933, 935)]\n",
      "Phrase:  me to - Best span: (933, 935) (highest=935)\n",
      "[(741, 743)]\n",
      "Phrase:  meeting. - Best span: (741, 743) (highest=743)\n",
      "[(545, 547), (791, 793), (840, 842)]\n",
      "Phrase:  need to - Best span: (840, 842) (highest=842)\n",
      "[(400, 402)]\n",
      "Phrase:  not get - Best span: (400, 402) (highest=402)\n",
      "[(281, 283), (486, 488), (873, 875)]\n",
      "Phrase:  of you - Best span: (873, 875) (highest=875)\n",
      "[(697, 699)]\n",
      "Phrase:  on the - Best span: (697, 699) (highest=699)\n",
      "[(576, 578)]\n",
      "Phrase:  on this - Best span: (576, 578) (highest=578)\n",
      "[(531, 533), (1039, 1041)]\n",
      "Phrase:  on to - Best span: (1039, 1041) (highest=1041)\n",
      "[(41, 43), (70, 72)]\n",
      "Phrase:  one of - Best span: (70, 72) (highest=72)\n",
      "[(610, 612)]\n",
      "Phrase:  red rock - Best span: (610, 612) (highest=612)\n",
      "[(569, 571), (663, 665)]\n",
      "Phrase:  steve - Best span: (663, 665) (highest=665)\n",
      "[(538, 540), (979, 981)]\n",
      "Phrase:  tuesday - Best span: (979, 981) (highest=981)\n",
      "[(96, 98), (593, 595)]\n",
      "Phrase:  that i - Best span: (593, 595) (highest=595)\n",
      "[(556, 558)]\n",
      "Phrase:  the bullets - Best span: (556, 558) (highest=558)\n",
      "[(947, 949)]\n",
      "Phrase:  this week - Best span: (947, 949) (highest=949)\n",
      "[(351, 353)]\n",
      "Phrase:  to be - Best span: (351, 353) (highest=353)\n",
      "[(532, 534)]\n",
      "Phrase:  to ensure - Best span: (532, 534) (highest=534)\n",
      "[(939, 941)]\n",
      "Phrase:  to get - Best span: (939, 941) (highest=941)\n",
      "[(942, 944)]\n",
      "Phrase:  to send - Best span: (942, 944) (highest=944)\n",
      "[(555, 557)]\n",
      "Phrase:  to the - Best span: (555, 557) (highest=557)\n",
      "[(927, 929)]\n",
      "Phrase:  wanted to - Best span: (927, 929) (highest=929)\n",
      "[(948, 950)]\n",
      "Phrase:  week. - Best span: (948, 950) (highest=950)\n",
      "[(370, 372)]\n",
      "Phrase:  when i - Best span: (370, 372) (highest=372)\n",
      "[(890, 892)]\n",
      "Phrase:  will have - Best span: (890, 892) (highest=892)\n",
      "[(447, 449), (1052, 1054)]\n",
      "Phrase:  would be - Best span: (1052, 1054) (highest=1054)\n",
      "[(454, 456), (487, 489)]\n",
      "Phrase:  you. - Best span: (487, 489) (highest=489)\n",
      "[(218, 220)]\n",
      "Phrase:  you need - Best span: (218, 220) (highest=220)\n",
      "[(652, 654), (712, 714), (968, 970)]\n",
      "Phrase:  you to - Best span: (968, 970) (highest=970)\n",
      "[(341, 344)]\n",
      "Phrase: 'd like to - Best span: (341, 344) (highest=344)\n",
      "[(234, 237)]\n",
      "Phrase: , i have - Best span: (234, 237) (highest=237)\n",
      "[(300, 303)]\n",
      "Phrase: , i just - Best span: (300, 303) (highest=303)\n",
      "[(383, 386)]\n",
      "Phrase: , i noticed - Best span: (383, 386) (highest=386)\n",
      "[(959, 962)]\n",
      "Phrase: , so i - Best span: (959, 962) (highest=962)\n",
      "[(690, 693)]\n",
      "Phrase: . i have - Best span: (690, 693) (highest=693)\n",
      "[(391, 394)]\n",
      "Phrase: . i just - Best span: (391, 394) (highest=394)\n",
      "[(171, 174)]\n",
      "Phrase:  cost of the - Best span: (171, 174) (highest=174)\n",
      "[(235, 238)]\n",
      "Phrase:  i have received - Best span: (235, 238) (highest=238)\n",
      "[(329, 332)]\n",
      "Phrase:  in houston - Best span: (329, 332) (highest=332)\n",
      "[(135, 138)]\n",
      "Phrase:  in rome - Best span: (135, 138) (highest=138)\n",
      "[(183, 186)]\n",
      "Phrase:  our group. - Best span: (183, 186) (highest=186)\n",
      "[(523, 526)]\n",
      "Phrase:  some of the - Best span: (523, 526) (highest=526)\n",
      "[(160, 163), (214, 217)]\n",
      "Phrase:  that you have - Best span: (214, 217) (highest=217)\n",
      "[(343, 346)]\n",
      "Phrase:  to meet with - Best span: (343, 346) (highest=346)\n",
      "[(836, 839)]\n",
      "Phrase:  to see if - Best span: (836, 839) (highest=839)\n",
      "[(517, 520), (930, 933)]\n",
      "Phrase:  with you and - Best span: (930, 933) (highest=933)\n",
      "[(490, 494), (1026, 1030)]\n",
      "Phrase: , here is the - Best span: (1026, 1030) (highest=1030)\n",
      "[(232, 236)]\n",
      "Phrase: . also, i - Best span: (232, 236) (highest=236)\n",
      "[(1034, 1038)]\n",
      "Phrase: . please review and - Best span: (1034, 1038) (highest=1038)\n",
      "[(312, 316)]\n",
      "Phrase:  at the end of - Best span: (312, 316) (highest=316)\n",
      "[(92, 96)]\n",
      "Phrase:  hotel in positano - Best span: (92, 96) (highest=96)\n",
      "[(102, 106)]\n",
      "Phrase:  hotel marincanto - Best span: (102, 106) (highest=106)\n",
      "[(108, 112)]\n",
      "Phrase:  sept. i - Best span: (108, 112) (highest=112)\n",
      "[(669, 673)]\n",
      "Phrase:  to connect up with - Best span: (669, 673) (highest=673)\n",
      "[(515, 519)]\n",
      "Phrase:  to visit with you - Best span: (515, 519) (highest=519)\n",
      "[(413, 418)]\n",
      "Phrase: , attached, please find - Best span: (413, 418) (highest=418)\n",
      "[(1081, 1086)]\n",
      "Phrase: . i would like to - Best span: (1081, 1086) (highest=1086)\n",
      "[(46, 51)]\n",
      "Phrase: . please let me know - Best span: (46, 51) (highest=51)\n",
      "[(751, 756)]\n",
      "Phrase:  if you are available. - Best span: (751, 756) (highest=756)\n",
      "[(613, 619)]\n",
      "Phrase: . let me know if you - Best span: (613, 619) (highest=619)\n",
      "[(876, 882)]\n",
      "Phrase:  if you have any questions or - Best span: (876, 882) (highest=882)\n",
      "[(478, 485)]\n",
      "Phrase: , i would like to visit with - Best span: (478, 485) (highest=485)\n",
      "[(614, 621)]\n",
      "Phrase:  let me know if you would like - Best span: (614, 621) (highest=621)\n",
      "\n",
      "--- GLOBAL BEST ---\n",
      "Phrase:  . i would like to\n",
      "Span:    (1081, 1086)\n",
      "Highest: 1086\n",
      "Tokens:  ['.', 'Ġi', 'Ġwould', 'Ġlike', 'Ġto']\n",
      "Text:    . i would like to\n"
     ]
    }
   ],
   "source": [
    "best = None  # global best across all phrases\n",
    "\n",
    "# tokenize the full unknown text once so we can slice tokens later\n",
    "enc = tokenizer(unknown_text, add_special_tokens=False)\n",
    "input_ids = enc.get(\"input_ids\")\n",
    "if input_ids is None:\n",
    "    input_ids = tokenizer.encode(unknown_text, add_special_tokens=False)\n",
    "elif input_ids and isinstance(input_ids[0], (list, tuple)):\n",
    "    input_ids = input_ids[0]\n",
    "\n",
    "unk_tokens = (\n",
    "    tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    if hasattr(tokenizer, \"convert_ids_to_tokens\")\n",
    "    else input_ids\n",
    ")\n",
    "\n",
    "for com in common:\n",
    "    test_text = tokens_to_text(com, tokenizer)\n",
    "\n",
    "    prefixes, tok_spans = texts_around_each_ngram(\n",
    "        unknown_text,\n",
    "        test_text,\n",
    "        return_token_spans=True,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    if not tok_spans:\n",
    "        continue\n",
    "\n",
    "    # pick the span whose tuple contains the highest number (usually the biggest tok_end)\n",
    "    best_span = max(tok_spans, key=lambda sp: max(sp))\n",
    "    best_val = max(best_span)\n",
    "\n",
    "    print(f\"Phrase: {test_text} - Best span: {best_span} (highest={best_val})\")\n",
    "\n",
    "    # keep global best across all phrases\n",
    "    if best is None or best_val > best[\"highest\"]:\n",
    "        best_idx = tok_spans.index(best_span)\n",
    "        best = {\n",
    "            \"phrase\": test_text,\n",
    "            \"span\": best_span,\n",
    "            \"highest\": best_val,\n",
    "            \"prefix\": prefixes[best_idx],  # optional\n",
    "        }\n",
    "\n",
    "print(\"\\n--- GLOBAL BEST ---\")\n",
    "if best is None:\n",
    "    print(\"No spans found.\")\n",
    "else:\n",
    "    s_tok, e_tok = best[\"span\"]\n",
    "\n",
    "    best_tokens = unk_tokens[s_tok:e_tok]\n",
    "    best_tokens_text = (\n",
    "        tokenizer.decode(input_ids[s_tok:e_tok], skip_special_tokens=True)\n",
    "        if hasattr(tokenizer, \"decode\")\n",
    "        else str(best_tokens)\n",
    "    )\n",
    "\n",
    "    print(f\"Phrase:  {best['phrase']}\")\n",
    "    print(f\"Span:    {best['span']}\")\n",
    "    print(f\"Highest: {best['highest']}\")\n",
    "    print(f\"Tokens:  {best_tokens}\")\n",
    "    print(f\"Text:    {best_tokens_text}\")\n",
    "    # optional:\n",
    "    # print(f\"Prefix:  {best['prefix']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "33345277",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[103], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[43mscore_ngrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mĠi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mĠwould\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mĠlike\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mĠto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munknown_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_bos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/src/n_gram_scoring.py:80\u001b[0m, in \u001b[0;36mscore_ngrams\u001b[0;34m(ngram, model, tokenizer, text, lowercase, use_bos)\u001b[0m\n",
      "\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;32m---> 80\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids_for_model\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits  \u001b[38;5;66;03m# (1, T' , V)\u001b[39;00m\n",
      "\u001b[1;32m     81\u001b[0m         lp_vocab \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(logits[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (1, T'-1, V)\u001b[39;00m\n",
      "\u001b[1;32m     82\u001b[0m         next_ids \u001b[38;5;241m=\u001b[39m ids_for_model[:, \u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# (1, T'-1)\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:1189\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, logits_to_keep, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m   1170\u001b[0m \u001b[38;5;124;03minput_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\u001b[39;00m\n",
      "\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03m    `input_ids_length` = `sequence_length` if `past_key_values` is `None` else\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1185\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n",
      "\u001b[1;32m   1186\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m   1187\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n",
      "\u001b[0;32m-> 1189\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1204\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1205\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;32m   1207\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:860\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    858\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m cache_position\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;32m--> 860\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwpe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    861\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;32m    863\u001b[0m \u001b[38;5;66;03m# Attention mask.\u001b[39;00m\n",
      "\u001b[1;32m    864\u001b[0m \u001b[38;5;66;03m# ._update_causal_mask() and ._prepare_4d_causal_attention_mask_with_cache_position() copied from LlamaModel\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n",
      "\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n",
      "\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n",
      "\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n",
      "\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n",
      "\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n",
      "\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n",
      "\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n",
      "\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "score_ngrams(['.', 'Ġi', 'Ġwould', 'Ġlike', 'Ġto'], model, tokenizer, unknown_text, use_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "588147e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phrase': ' let me know if',\n",
       " 'tokens': ['Ġlet', 'Ġme', 'Ġknow', 'Ġif'],\n",
       " 'num_tokens': 4,\n",
       " 'log_probs': [-11.52054500579834,\n",
       "  -3.1591553688049316,\n",
       "  -2.4348859786987305,\n",
       "  -1.0943843126296997],\n",
       " 'sum_log_probs': -18.2089706659317,\n",
       " 'text_tokens': ['Ġlet', 'Ġme', 'Ġknow', 'Ġif'],\n",
       " 'text_len': 4,\n",
       " 'text_log_probs': [-11.52054500579834,\n",
       "  -3.1591553688049316,\n",
       "  -2.4348859786987305,\n",
       "  -1.0943843126296997]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(sample_tokens, model, tokenizer, use_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b87041c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phrase': ' let me know if',\n",
       " 'tokens': ['Ġlet', 'Ġme', 'Ġknow', 'Ġif'],\n",
       " 'num_tokens': 4,\n",
       " 'log_probs': [-11.52054500579834,\n",
       "  -3.1591553688049316,\n",
       "  -2.4348859786987305,\n",
       "  -1.0943843126296997],\n",
       " 'sum_log_probs': -18.2089706659317,\n",
       " 'text_tokens': ['Ġlet', 'Ġme', 'Ġknow', 'Ġif'],\n",
       " 'text_len': 4,\n",
       " 'text_log_probs': [-11.52054500579834,\n",
       "  -3.1591553688049316,\n",
       "  -2.4348859786987305,\n",
       "  -1.0943843126296997]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ngrams(sample_text, model, tokenizer, use_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ad40138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no = score_ngrams_to_df(common, model, tokenizer, full_text=None, use_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1dafc5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_num</th>\n",
       "      <th>phrase_occurrence</th>\n",
       "      <th>phrase</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>log_probs</th>\n",
       "      <th>sum_log_probs</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text_log_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>, as</td>\n",
       "      <td>[,, Ġas]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-5.659754753112793, -5.123129367828369]</td>\n",
       "      <td>-10.782884</td>\n",
       "      <td>[,, Ġas]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-5.659754753112793, -5.123129367828369]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>, but</td>\n",
       "      <td>[,, Ġbut]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-5.659754753112793, -4.751577854156494]</td>\n",
       "      <td>-10.411333</td>\n",
       "      <td>[,, Ġbut]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-5.659754753112793, -4.751577854156494]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>. if</td>\n",
       "      <td>[., Ġif]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-4.482760429382324, -9.537545204162598]</td>\n",
       "      <td>-14.020306</td>\n",
       "      <td>[., Ġif]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-4.482760429382324, -9.537545204162598]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>. the</td>\n",
       "      <td>[., Ġthe]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-4.482760429382324, -7.372399806976318]</td>\n",
       "      <td>-11.855160</td>\n",
       "      <td>[., Ġthe]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-4.482760429382324, -7.372399806976318]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ie,</td>\n",
       "      <td>[ie, ,]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-8.445429801940918, -4.862000465393066]</td>\n",
       "      <td>-13.307430</td>\n",
       "      <td>[ie, ,]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-8.445429801940918, -4.862000465393066]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>if you are available.</td>\n",
       "      <td>[Ġif, Ġyou, Ġare, Ġavailable, .]</td>\n",
       "      <td>5</td>\n",
       "      <td>[-9.735991477966309, -1.6311017274856567, -2.1...</td>\n",
       "      <td>-24.022795</td>\n",
       "      <td>[Ġif, Ġyou, Ġare, Ġavailable, .]</td>\n",
       "      <td>5</td>\n",
       "      <td>[-9.735991477966309, -1.6311017274856567, -2.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>. let me know if you</td>\n",
       "      <td>[., Ġlet, Ġme, Ġknow, Ġif, Ġyou]</td>\n",
       "      <td>6</td>\n",
       "      <td>[-4.482760429382324, -10.545089721679688, -3.8...</td>\n",
       "      <td>-21.918498</td>\n",
       "      <td>[., Ġlet, Ġme, Ġknow, Ġif, Ġyou]</td>\n",
       "      <td>6</td>\n",
       "      <td>[-4.482760429382324, -10.545089721679688, -3.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>if you have any questions or</td>\n",
       "      <td>[Ġif, Ġyou, Ġhave, Ġany, Ġquestions, Ġor]</td>\n",
       "      <td>6</td>\n",
       "      <td>[-9.735991477966309, -1.6311017274856567, -2.7...</td>\n",
       "      <td>-18.474388</td>\n",
       "      <td>[Ġif, Ġyou, Ġhave, Ġany, Ġquestions, Ġor]</td>\n",
       "      <td>6</td>\n",
       "      <td>[-9.735991477966309, -1.6311017274856567, -2.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>, i would like to visit with</td>\n",
       "      <td>[,, Ġi, Ġwould, Ġlike, Ġto, Ġvisit, Ġwith]</td>\n",
       "      <td>7</td>\n",
       "      <td>[-5.659754753112793, -6.466437339782715, -6.28...</td>\n",
       "      <td>-32.375830</td>\n",
       "      <td>[,, Ġi, Ġwould, Ġlike, Ġto, Ġvisit, Ġwith]</td>\n",
       "      <td>7</td>\n",
       "      <td>[-5.659754753112793, -6.466437339782715, -6.28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>let me know if you would like</td>\n",
       "      <td>[Ġlet, Ġme, Ġknow, Ġif, Ġyou, Ġwould, Ġlike]</td>\n",
       "      <td>7</td>\n",
       "      <td>[-11.52054500579834, -3.159168243408203, -2.43...</td>\n",
       "      <td>-22.310898</td>\n",
       "      <td>[Ġlet, Ġme, Ġknow, Ġif, Ġyou, Ġwould, Ġlike]</td>\n",
       "      <td>7</td>\n",
       "      <td>[-11.52054500579834, -3.159168243408203, -2.43...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    phrase_num  phrase_occurrence                          phrase  \\\n",
       "0            1                  1                            , as   \n",
       "1            2                  1                           , but   \n",
       "2            3                  1                            . if   \n",
       "3            4                  1                           . the   \n",
       "4            5                  1                             ie,   \n",
       "..         ...                ...                             ...   \n",
       "85          86                  1           if you are available.   \n",
       "86          87                  1            . let me know if you   \n",
       "87          88                  1    if you have any questions or   \n",
       "88          89                  1    , i would like to visit with   \n",
       "89          90                  1   let me know if you would like   \n",
       "\n",
       "                                          tokens  num_tokens  \\\n",
       "0                                       [,, Ġas]           2   \n",
       "1                                      [,, Ġbut]           2   \n",
       "2                                       [., Ġif]           2   \n",
       "3                                      [., Ġthe]           2   \n",
       "4                                        [ie, ,]           2   \n",
       "..                                           ...         ...   \n",
       "85              [Ġif, Ġyou, Ġare, Ġavailable, .]           5   \n",
       "86              [., Ġlet, Ġme, Ġknow, Ġif, Ġyou]           6   \n",
       "87     [Ġif, Ġyou, Ġhave, Ġany, Ġquestions, Ġor]           6   \n",
       "88    [,, Ġi, Ġwould, Ġlike, Ġto, Ġvisit, Ġwith]           7   \n",
       "89  [Ġlet, Ġme, Ġknow, Ġif, Ġyou, Ġwould, Ġlike]           7   \n",
       "\n",
       "                                            log_probs  sum_log_probs  \\\n",
       "0            [-5.659754753112793, -5.123129367828369]     -10.782884   \n",
       "1            [-5.659754753112793, -4.751577854156494]     -10.411333   \n",
       "2            [-4.482760429382324, -9.537545204162598]     -14.020306   \n",
       "3            [-4.482760429382324, -7.372399806976318]     -11.855160   \n",
       "4            [-8.445429801940918, -4.862000465393066]     -13.307430   \n",
       "..                                                ...            ...   \n",
       "85  [-9.735991477966309, -1.6311017274856567, -2.1...     -24.022795   \n",
       "86  [-4.482760429382324, -10.545089721679688, -3.8...     -21.918498   \n",
       "87  [-9.735991477966309, -1.6311017274856567, -2.7...     -18.474388   \n",
       "88  [-5.659754753112793, -6.466437339782715, -6.28...     -32.375830   \n",
       "89  [-11.52054500579834, -3.159168243408203, -2.43...     -22.310898   \n",
       "\n",
       "                                     text_tokens  text_len  \\\n",
       "0                                       [,, Ġas]         2   \n",
       "1                                      [,, Ġbut]         2   \n",
       "2                                       [., Ġif]         2   \n",
       "3                                      [., Ġthe]         2   \n",
       "4                                        [ie, ,]         2   \n",
       "..                                           ...       ...   \n",
       "85              [Ġif, Ġyou, Ġare, Ġavailable, .]         5   \n",
       "86              [., Ġlet, Ġme, Ġknow, Ġif, Ġyou]         6   \n",
       "87     [Ġif, Ġyou, Ġhave, Ġany, Ġquestions, Ġor]         6   \n",
       "88    [,, Ġi, Ġwould, Ġlike, Ġto, Ġvisit, Ġwith]         7   \n",
       "89  [Ġlet, Ġme, Ġknow, Ġif, Ġyou, Ġwould, Ġlike]         7   \n",
       "\n",
       "                                       text_log_probs  \n",
       "0            [-5.659754753112793, -5.123129367828369]  \n",
       "1            [-5.659754753112793, -4.751577854156494]  \n",
       "2            [-4.482760429382324, -9.537545204162598]  \n",
       "3            [-4.482760429382324, -7.372399806976318]  \n",
       "4            [-8.445429801940918, -4.862000465393066]  \n",
       "..                                                ...  \n",
       "85  [-9.735991477966309, -1.6311017274856567, -2.1...  \n",
       "86  [-4.482760429382324, -10.545089721679688, -3.8...  \n",
       "87  [-9.735991477966309, -1.6311017274856567, -2.7...  \n",
       "88  [-5.659754753112793, -6.466437339782715, -6.28...  \n",
       "89  [-11.52054500579834, -3.159168243408203, -2.43...  \n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ace76b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(571, 573)]\n",
      "[(390, 392)]\n",
      "[(144, 146), (621, 623)]\n",
      "[(443, 445)]\n",
      "[(671, 673)]\n",
      "[(257, 259)]\n",
      "[(29, 31)]\n",
      "[(72, 74)]\n",
      "[(183, 185), (614, 616)]\n",
      "[(442, 444)]\n",
      "[(556, 558), (806, 808)]\n",
      "[(47, 49)]\n",
      "[(97, 99)]\n",
      "[(101, 103), (278, 280), (785, 787)]\n",
      "[(256, 258), (464, 466), (654, 656), (797, 799)]\n",
      "[(484, 486)]\n",
      "[(193, 195)]\n",
      "[(529, 531)]\n",
      "[(246, 248), (540, 542), (615, 617), (754, 756)]\n",
      "[(345, 347)]\n",
      "[(27, 29)]\n",
      "[(622, 624)]\n",
      "[(137, 139)]\n",
      "[(300, 302), (437, 439)]\n",
      "[(749, 751)]\n",
      "[(167, 169)]\n",
      "[(807, 809)]\n",
      "[(76, 78)]\n",
      "[(223, 225)]\n",
      "[(283, 285)]\n",
      "[(346, 348)]\n",
      "[(98, 100)]\n",
      "[(6, 8), (147, 149), (704, 706), (730, 732)]\n",
      "[(386, 388)]\n",
      "[(11, 13), (322, 324)]\n",
      "[(205, 207)]\n",
      "[(146, 148)]\n",
      "[(330, 332)]\n",
      "[(218, 220)]\n",
      "[(603, 605)]\n",
      "[(26, 28)]\n",
      "[(260, 262), (268, 270)]\n",
      "[(32, 34), (174, 176), (522, 524), (709, 711), (723, 725)]\n",
      "[(176, 178)]\n",
      "[(93, 95)]\n",
      "[(224, 226)]\n",
      "[(774, 776)]\n",
      "[(206, 208), (297, 299)]\n",
      "[(773, 775)]\n",
      "[(213, 215)]\n",
      "[(673, 675)]\n",
      "[(595, 597)]\n",
      "[(161, 163)]\n",
      "[(620, 622)]\n",
      "[(235, 237), (482, 484)]\n",
      "[(23, 25), (731, 733)]\n",
      "[(563, 566)]\n",
      "[(254, 257)]\n",
      "[(19, 22)]\n",
      "[(373, 376)]\n",
      "[(55, 58)]\n",
      "[(104, 107)]\n",
      "[(740, 743)]\n",
      "[(446, 449)]\n",
      "[(105, 108)]\n",
      "[(608, 611)]\n",
      "[(113, 116)]\n",
      "[(238, 241)]\n",
      "[(379, 382)]\n",
      "[(745, 748)]\n",
      "[(347, 350)]\n",
      "[(156, 159)]\n",
      "[(226, 229)]\n",
      "[(577, 581)]\n",
      "[(371, 375)]\n",
      "[(455, 459)]\n",
      "[(701, 705)]\n",
      "[(37, 41)]\n",
      "[(41, 45)]\n",
      "[(537, 541)]\n",
      "[(517, 521)]\n",
      "[(364, 368)]\n",
      "[(419, 424)]\n",
      "[(513, 518)]\n",
      "[(240, 245), (588, 593)]\n",
      "[(524, 529)]\n",
      "[(477, 483)]\n",
      "[(462, 468)]\n",
      "[(360, 367)]\n",
      "[(632, 639)]\n"
     ]
    }
   ],
   "source": [
    "df_known = score_ngrams_to_df(common, model, tokenizer, full_text=known_text, use_bos=True, num_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "024a1f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_num</th>\n",
       "      <th>phrase_occurrence</th>\n",
       "      <th>phrase</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>log_probs</th>\n",
       "      <th>sum_log_probs</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text_log_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>, as</td>\n",
       "      <td>[,, Ġas]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-1.019666314125061, -5.439155578613281]</td>\n",
       "      <td>-6.458822</td>\n",
       "      <td>[many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...</td>\n",
       "      <td>573</td>\n",
       "      <td>[-11.021262168884277, -3.822641372680664, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>, but</td>\n",
       "      <td>[,, Ġbut]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-2.6605143547058105, -2.4401988983154297]</td>\n",
       "      <td>-5.100713</td>\n",
       "      <td>[many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...</td>\n",
       "      <td>392</td>\n",
       "      <td>[-11.021262168884277, -3.822641372680664, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>. if</td>\n",
       "      <td>[., Ġif]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.9009577035903931, -4.4446234703063965]</td>\n",
       "      <td>-5.345581</td>\n",
       "      <td>[many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...</td>\n",
       "      <td>146</td>\n",
       "      <td>[-11.021262168884277, -3.822641372680664, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>. if</td>\n",
       "      <td>[., Ġif]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.48230841755867004, -3.4513957500457764]</td>\n",
       "      <td>-3.933704</td>\n",
       "      <td>[many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...</td>\n",
       "      <td>623</td>\n",
       "      <td>[-11.021262168884277, -3.822641372680664, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>. the</td>\n",
       "      <td>[., Ġthe]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.8463349342346191, -4.308838844299316]</td>\n",
       "      <td>-5.155174</td>\n",
       "      <td>[many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...</td>\n",
       "      <td>445</td>\n",
       "      <td>[-11.021262168884277, -3.822641372680664, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>if you are available.</td>\n",
       "      <td>[Ġif, Ġyou, Ġare, Ġavailable, .]</td>\n",
       "      <td>5</td>\n",
       "      <td>[-3.888493061065674, -1.3347547054290771, -2.0...</td>\n",
       "      <td>-10.362843</td>\n",
       "      <td>[many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...</td>\n",
       "      <td>529</td>\n",
       "      <td>[-11.021262168884277, -3.822641372680664, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>. let me know if you</td>\n",
       "      <td>[., Ġlet, Ġme, Ġknow, Ġif, Ġyou]</td>\n",
       "      <td>6</td>\n",
       "      <td>[-1.82478928565979, -5.64450740814209, -0.2195...</td>\n",
       "      <td>-8.822046</td>\n",
       "      <td>[many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...</td>\n",
       "      <td>483</td>\n",
       "      <td>[-11.021262168884277, -3.822641372680664, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>if you have any questions or</td>\n",
       "      <td>[Ġif, Ġyou, Ġhave, Ġany, Ġquestions, Ġor]</td>\n",
       "      <td>6</td>\n",
       "      <td>[-1.1867774724960327, -1.0457713603973389, -1....</td>\n",
       "      <td>-7.948379</td>\n",
       "      <td>[many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...</td>\n",
       "      <td>468</td>\n",
       "      <td>[-11.021262168884277, -3.822641372680664, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>, i would like to visit with</td>\n",
       "      <td>[,, Ġi, Ġwould, Ġlike, Ġto, Ġvisit, Ġwith]</td>\n",
       "      <td>7</td>\n",
       "      <td>[-1.1141384840011597, -1.9723618030548096, -4....</td>\n",
       "      <td>-16.292405</td>\n",
       "      <td>[many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...</td>\n",
       "      <td>367</td>\n",
       "      <td>[-11.021262168884277, -3.822641372680664, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>let me know if you would like</td>\n",
       "      <td>[Ġlet, Ġme, Ġknow, Ġif, Ġyou, Ġwould, Ġlike]</td>\n",
       "      <td>7</td>\n",
       "      <td>[-4.549959182739258, -0.2981421649456024, -0.0...</td>\n",
       "      <td>-10.906216</td>\n",
       "      <td>[many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...</td>\n",
       "      <td>639</td>\n",
       "      <td>[-11.021262168884277, -3.822641372680664, -0.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     phrase_num  phrase_occurrence                          phrase  \\\n",
       "0             1                  1                            , as   \n",
       "1             2                  1                           , but   \n",
       "2             3                  1                            . if   \n",
       "3             3                  2                            . if   \n",
       "4             4                  1                           . the   \n",
       "..          ...                ...                             ...   \n",
       "110          86                  1           if you are available.   \n",
       "111          87                  1            . let me know if you   \n",
       "112          88                  1    if you have any questions or   \n",
       "113          89                  1    , i would like to visit with   \n",
       "114          90                  1   let me know if you would like   \n",
       "\n",
       "                                           tokens  num_tokens  \\\n",
       "0                                        [,, Ġas]           2   \n",
       "1                                       [,, Ġbut]           2   \n",
       "2                                        [., Ġif]           2   \n",
       "3                                        [., Ġif]           2   \n",
       "4                                       [., Ġthe]           2   \n",
       "..                                            ...         ...   \n",
       "110              [Ġif, Ġyou, Ġare, Ġavailable, .]           5   \n",
       "111              [., Ġlet, Ġme, Ġknow, Ġif, Ġyou]           6   \n",
       "112     [Ġif, Ġyou, Ġhave, Ġany, Ġquestions, Ġor]           6   \n",
       "113    [,, Ġi, Ġwould, Ġlike, Ġto, Ġvisit, Ġwith]           7   \n",
       "114  [Ġlet, Ġme, Ġknow, Ġif, Ġyou, Ġwould, Ġlike]           7   \n",
       "\n",
       "                                             log_probs  sum_log_probs  \\\n",
       "0             [-1.019666314125061, -5.439155578613281]      -6.458822   \n",
       "1           [-2.6605143547058105, -2.4401988983154297]      -5.100713   \n",
       "2           [-0.9009577035903931, -4.4446234703063965]      -5.345581   \n",
       "3          [-0.48230841755867004, -3.4513957500457764]      -3.933704   \n",
       "4            [-0.8463349342346191, -4.308838844299316]      -5.155174   \n",
       "..                                                 ...            ...   \n",
       "110  [-3.888493061065674, -1.3347547054290771, -2.0...     -10.362843   \n",
       "111  [-1.82478928565979, -5.64450740814209, -0.2195...      -8.822046   \n",
       "112  [-1.1867774724960327, -1.0457713603973389, -1....      -7.948379   \n",
       "113  [-1.1141384840011597, -1.9723618030548096, -4....     -16.292405   \n",
       "114  [-4.549959182739258, -0.2981421649456024, -0.0...     -10.906216   \n",
       "\n",
       "                                           text_tokens  text_len  \\\n",
       "0    [many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...       573   \n",
       "1    [many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...       392   \n",
       "2    [many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...       146   \n",
       "3    [many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...       623   \n",
       "4    [many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...       445   \n",
       "..                                                 ...       ...   \n",
       "110  [many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...       529   \n",
       "111  [many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...       483   \n",
       "112  [many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...       468   \n",
       "113  [many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...       367   \n",
       "114  [many, ,, Ġmany, Ġthanks, Ġfor, Ġall, Ġof, Ġyo...       639   \n",
       "\n",
       "                                        text_log_probs  \n",
       "0    [-11.021262168884277, -3.822641372680664, -0.2...  \n",
       "1    [-11.021262168884277, -3.822641372680664, -0.2...  \n",
       "2    [-11.021262168884277, -3.822641372680664, -0.2...  \n",
       "3    [-11.021262168884277, -3.822641372680664, -0.2...  \n",
       "4    [-11.021262168884277, -3.822641372680664, -0.2...  \n",
       "..                                                 ...  \n",
       "110  [-11.021262168884277, -3.822641372680664, -0.2...  \n",
       "111  [-11.021262168884277, -3.822641372680664, -0.2...  \n",
       "112  [-11.021262168884277, -3.822641372680664, -0.2...  \n",
       "113  [-11.021262168884277, -3.822641372680664, -0.2...  \n",
       "114  [-11.021262168884277, -3.822641372680664, -0.2...  \n",
       "\n",
       "[115 rows x 10 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6b67d13d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[218], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m df_unknown \u001b[38;5;241m=\u001b[39m \u001b[43mscore_ngrams_to_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munknown_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/src/n_gram_scoring.py:170\u001b[0m, in \u001b[0;36mscore_ngrams_to_df\u001b[0;34m(ngrams, model, tokenizer, full_text, lowercase, use_bos, num_tokens)\u001b[0m\n",
      "\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    168\u001b[0m             occ_text \u001b[38;5;241m=\u001b[39m prefix\n",
      "\u001b[0;32m--> 170\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mscore_ngrams\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mngram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mng\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocc_text\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlowercase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlowercase\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_bos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_bos\u001b[49m\n",
      "\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    179\u001b[0m         rows\u001b[38;5;241m.\u001b[39mappend({\n",
      "\u001b[1;32m    180\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphrase_num\u001b[39m\u001b[38;5;124m\"\u001b[39m: phrase_num,\n",
      "\u001b[1;32m    181\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphrase_occurrence\u001b[39m\u001b[38;5;124m\"\u001b[39m: i,\n",
      "\u001b[1;32m    182\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mres\n",
      "\u001b[1;32m    183\u001b[0m         })\n",
      "\u001b[1;32m    185\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/src/n_gram_scoring.py:80\u001b[0m, in \u001b[0;36mscore_ngrams\u001b[0;34m(ngram, model, tokenizer, text, lowercase, use_bos)\u001b[0m\n",
      "\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;32m---> 80\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids_for_model\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits  \u001b[38;5;66;03m# (1, T' , V)\u001b[39;00m\n",
      "\u001b[1;32m     81\u001b[0m         lp_vocab \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(logits[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (1, T'-1, V)\u001b[39;00m\n",
      "\u001b[1;32m     82\u001b[0m         next_ids \u001b[38;5;241m=\u001b[39m ids_for_model[:, \u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# (1, T'-1)\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:1189\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, logits_to_keep, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m   1170\u001b[0m \u001b[38;5;124;03minput_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\u001b[39;00m\n",
      "\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03m    `input_ids_length` = `sequence_length` if `past_key_values` is `None` else\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1185\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n",
      "\u001b[1;32m   1186\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m   1187\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n",
      "\u001b[0;32m-> 1189\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1204\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1205\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;32m   1207\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:860\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m    858\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m cache_position\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;32m--> 860\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwpe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    861\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;32m    863\u001b[0m \u001b[38;5;66;03m# Attention mask.\u001b[39;00m\n",
      "\u001b[1;32m    864\u001b[0m \u001b[38;5;66;03m# ._update_causal_mask() and ._prepare_4d_causal_attention_mask_with_cache_position() copied from LlamaModel\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n",
      "\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Documents/GitHub/n-gram-av-methods/my_venv/lib/python3.11/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n",
      "\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n",
      "\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n",
      "\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n",
      "\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n",
      "\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n",
      "\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n",
      "\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "df_unknown = score_ngrams_to_df(common, model, tokenizer, full_text=unknown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1bb33139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unknown = score_ngrams_to_df(common, model, tokenizer, full_text=unknown_text, use_bos=True, num_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c84dd41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_num</th>\n",
       "      <th>phrase_occurrence</th>\n",
       "      <th>phrase</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>log_probs</th>\n",
       "      <th>sum_log_probs</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>text_len</th>\n",
       "      <th>text_log_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>, as</td>\n",
       "      <td>[,, Ġas]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-3.0795679092407227, -5.415594100952148]</td>\n",
       "      <td>-8.495162</td>\n",
       "      <td>[they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...</td>\n",
       "      <td>202</td>\n",
       "      <td>[-9.514735221862793, -5.6802144050598145, -2.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>, but</td>\n",
       "      <td>[,, Ġbut]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-1.9199104309082031, -2.626206874847412]</td>\n",
       "      <td>-4.546117</td>\n",
       "      <td>[they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...</td>\n",
       "      <td>705</td>\n",
       "      <td>[-9.514735221862793, -5.6802144050598145, -2.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>. if</td>\n",
       "      <td>[., Ġif]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-1.1455343961715698, -3.911022186279297]</td>\n",
       "      <td>-5.056557</td>\n",
       "      <td>[they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...</td>\n",
       "      <td>57</td>\n",
       "      <td>[-9.514735221862793, -5.6802144050598145, -2.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>. if</td>\n",
       "      <td>[., Ġif]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-1.3444461822509766, -3.487243413925171]</td>\n",
       "      <td>-4.831690</td>\n",
       "      <td>[they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...</td>\n",
       "      <td>433</td>\n",
       "      <td>[-9.514735221862793, -5.6802144050598145, -2.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>. the</td>\n",
       "      <td>[., Ġthe]</td>\n",
       "      <td>2</td>\n",
       "      <td>[-1.065126657485962, -4.100943565368652]</td>\n",
       "      <td>-5.166070</td>\n",
       "      <td>[they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...</td>\n",
       "      <td>166</td>\n",
       "      <td>[-9.514735221862793, -5.6802144050598145, -2.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>if you are available.</td>\n",
       "      <td>[Ġif, Ġyou, Ġare, Ġavailable, .]</td>\n",
       "      <td>5</td>\n",
       "      <td>[-3.424461841583252, -0.23520515859127045, -1....</td>\n",
       "      <td>-10.285177</td>\n",
       "      <td>[they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...</td>\n",
       "      <td>756</td>\n",
       "      <td>[-9.514735221862793, -5.6802144050598145, -2.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>. let me know if you</td>\n",
       "      <td>[., Ġlet, Ġme, Ġknow, Ġif, Ġyou]</td>\n",
       "      <td>6</td>\n",
       "      <td>[-1.1237517595291138, -5.131729602813721, -0.6...</td>\n",
       "      <td>-8.408055</td>\n",
       "      <td>[they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...</td>\n",
       "      <td>619</td>\n",
       "      <td>[-9.514735221862793, -5.6802144050598145, -2.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>if you have any questions or</td>\n",
       "      <td>[Ġif, Ġyou, Ġhave, Ġany, Ġquestions, Ġor]</td>\n",
       "      <td>6</td>\n",
       "      <td>[-2.703808069229126, -0.8416548371315002, -1.6...</td>\n",
       "      <td>-7.866544</td>\n",
       "      <td>[they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...</td>\n",
       "      <td>882</td>\n",
       "      <td>[-9.514735221862793, -5.6802144050598145, -2.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>, i would like to visit with</td>\n",
       "      <td>[,, Ġi, Ġwould, Ġlike, Ġto, Ġvisit, Ġwith]</td>\n",
       "      <td>7</td>\n",
       "      <td>[-0.9718462824821472, -1.1969939470291138, -1....</td>\n",
       "      <td>-15.629446</td>\n",
       "      <td>[they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...</td>\n",
       "      <td>485</td>\n",
       "      <td>[-9.514735221862793, -5.6802144050598145, -2.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>let me know if you would like</td>\n",
       "      <td>[Ġlet, Ġme, Ġknow, Ġif, Ġyou, Ġwould, Ġlike]</td>\n",
       "      <td>7</td>\n",
       "      <td>[-5.131729602813721, -0.664366602897644, -0.29...</td>\n",
       "      <td>-9.897178</td>\n",
       "      <td>[they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...</td>\n",
       "      <td>621</td>\n",
       "      <td>[-9.514735221862793, -5.6802144050598145, -2.7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     phrase_num  phrase_occurrence                          phrase  \\\n",
       "0             1                  1                            , as   \n",
       "1             2                  1                           , but   \n",
       "2             3                  1                            . if   \n",
       "3             3                  2                            . if   \n",
       "4             4                  1                           . the   \n",
       "..          ...                ...                             ...   \n",
       "117          86                  1           if you are available.   \n",
       "118          87                  1            . let me know if you   \n",
       "119          88                  1    if you have any questions or   \n",
       "120          89                  1    , i would like to visit with   \n",
       "121          90                  1   let me know if you would like   \n",
       "\n",
       "                                           tokens  num_tokens  \\\n",
       "0                                        [,, Ġas]           2   \n",
       "1                                       [,, Ġbut]           2   \n",
       "2                                        [., Ġif]           2   \n",
       "3                                        [., Ġif]           2   \n",
       "4                                       [., Ġthe]           2   \n",
       "..                                            ...         ...   \n",
       "117              [Ġif, Ġyou, Ġare, Ġavailable, .]           5   \n",
       "118              [., Ġlet, Ġme, Ġknow, Ġif, Ġyou]           6   \n",
       "119     [Ġif, Ġyou, Ġhave, Ġany, Ġquestions, Ġor]           6   \n",
       "120    [,, Ġi, Ġwould, Ġlike, Ġto, Ġvisit, Ġwith]           7   \n",
       "121  [Ġlet, Ġme, Ġknow, Ġif, Ġyou, Ġwould, Ġlike]           7   \n",
       "\n",
       "                                             log_probs  sum_log_probs  \\\n",
       "0            [-3.0795679092407227, -5.415594100952148]      -8.495162   \n",
       "1            [-1.9199104309082031, -2.626206874847412]      -4.546117   \n",
       "2            [-1.1455343961715698, -3.911022186279297]      -5.056557   \n",
       "3            [-1.3444461822509766, -3.487243413925171]      -4.831690   \n",
       "4             [-1.065126657485962, -4.100943565368652]      -5.166070   \n",
       "..                                                 ...            ...   \n",
       "117  [-3.424461841583252, -0.23520515859127045, -1....     -10.285177   \n",
       "118  [-1.1237517595291138, -5.131729602813721, -0.6...      -8.408055   \n",
       "119  [-2.703808069229126, -0.8416548371315002, -1.6...      -7.866544   \n",
       "120  [-0.9718462824821472, -1.1969939470291138, -1....     -15.629446   \n",
       "121  [-5.131729602813721, -0.664366602897644, -0.29...      -9.897178   \n",
       "\n",
       "                                           text_tokens  text_len  \\\n",
       "0    [they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...       202   \n",
       "1    [they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...       705   \n",
       "2    [they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...        57   \n",
       "3    [they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...       433   \n",
       "4    [they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...       166   \n",
       "..                                                 ...       ...   \n",
       "117  [they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...       756   \n",
       "118  [they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...       619   \n",
       "119  [they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...       882   \n",
       "120  [they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...       485   \n",
       "121  [they, Ġalso, Ġhave, Ġprivate, Ġparking, Ġat, ...       621   \n",
       "\n",
       "                                        text_log_probs  \n",
       "0    [-9.514735221862793, -5.6802144050598145, -2.7...  \n",
       "1    [-9.514735221862793, -5.6802144050598145, -2.7...  \n",
       "2    [-9.514735221862793, -5.6802144050598145, -2.7...  \n",
       "3    [-9.514735221862793, -5.6802144050598145, -2.7...  \n",
       "4    [-9.514735221862793, -5.6802144050598145, -2.7...  \n",
       "..                                                 ...  \n",
       "117  [-9.514735221862793, -5.6802144050598145, -2.7...  \n",
       "118  [-9.514735221862793, -5.6802144050598145, -2.7...  \n",
       "119  [-9.514735221862793, -5.6802144050598145, -2.7...  \n",
       "120  [-9.514735221862793, -5.6802144050598145, -2.7...  \n",
       "121  [-9.514735221862793, -5.6802144050598145, -2.7...  \n",
       "\n",
       "[122 rows x 10 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6163295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
