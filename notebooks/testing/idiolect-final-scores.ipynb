{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d896ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressWarnings(\n",
    "  suppressPackageStartupMessages(\n",
    "    {\n",
    "      library(readxl)\n",
    "      library(writexl)\n",
    "      library(dplyr)\n",
    "      library(purrr)\n",
    "      library(tibble)\n",
    "      library(devtools)\n",
    "    }\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "942aad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m──\u001b[39m \u001b[36mR CMD build\u001b[39m \u001b[36m─────────────────────────────────────────────────────────────────\u001b[39m\n",
      "✔  checking for file ‘/Users/user/Documents/GitHub/idiolect/DESCRIPTION’ ...\n",
      "─  preparing ‘idiolect’:\n",
      "✔  checking DESCRIPTION meta-information ...\n",
      "─  checking for LF line-endings in source and make files and shell scripts\n",
      "─  checking for empty or unneeded directories\n",
      "─  building ‘idiolect_1.1.1.9000.tar.gz’\n",
      "   \n",
      "Running /Library/Frameworks/R.framework/Resources/bin/R CMD INSTALL \\\n",
      "  /var/folders/xx/hy496x3x5sn4hy9gy1fk19lw0000gp/T//RtmpYBP5Aw/idiolect_1.1.1.9000.tar.gz \\\n",
      "  --install-tests \n",
      "* installing to library ‘/Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library’\n",
      "* installing *source* package ‘idiolect’ ...\n",
      "** using staged installation\n",
      "** R\n",
      "** data\n",
      "*** moving datasets to lazyload DB\n",
      "** inst\n",
      "** tests\n",
      "** byte-compile and prepare package for lazy loading\n",
      "Warning messages:\n",
      "1: package ‘quanteda’ was built under R version 4.2.3 \n",
      "2: In .recacheSubclasses(def@className, def, env) :\n",
      "  undefined subclass \"ndiMatrix\" of class \"replValueSp\"; definition not updated\n",
      "3: In .recacheSubclasses(def@className, def, env) :\n",
      "  undefined subclass \"pcorMatrix\" of class \"replValueSp\"; definition not updated\n",
      "** help\n",
      "*** installing help indices\n",
      "*** copying figures\n",
      "** building package indices\n",
      "** installing vignettes\n",
      "** testing if installed package can be loaded from temporary location\n",
      "Warning: package ‘quanteda’ was built under R version 4.2.3\n",
      "Warning in .recacheSubclasses(def@className, def, env) :\n",
      "  undefined subclass \"ndiMatrix\" of class \"replValueSp\"; definition not updated\n",
      "Warning in .recacheSubclasses(def@className, def, env) :\n",
      "  undefined subclass \"pcorMatrix\" of class \"replValueSp\"; definition not updated\n",
      "** testing if installed package can be loaded from final location\n",
      "Warning: package ‘quanteda’ was built under R version 4.2.3\n",
      "Warning in .recacheSubclasses(def@className, def, env) :\n",
      "  undefined subclass \"ndiMatrix\" of class \"replValueSp\"; definition not updated\n",
      "Warning in .recacheSubclasses(def@className, def, env) :\n",
      "  undefined subclass \"pcorMatrix\" of class \"replValueSp\"; definition not updated\n",
      "** testing if installed package keeps a record of temporary installation path\n",
      "* DONE (idiolect)\n"
     ]
    }
   ],
   "source": [
    "# installs from the local folder (your modified clone)\n",
    "devtools::install(\"/Users/user/Documents/GitHub/idiolect\", upgrade = \"never\")\n",
    "\n",
    "library(idiolect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d68971",
   "metadata": {},
   "source": [
    "## Get Number of Files in Each Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e0d4412",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loc <- \"/Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs\"\n",
    "problem_metadata <- read_excel(paste0(base_loc, \"/raw_problem_completed_metadata.xlsx\")) %>%\n",
    "  select(data_type, corpus, scoring_model, problem, num_files, files_completed, files_scored, problem_completed)\n",
    "\n",
    "problem_scores <- read_excel(paste0(base_loc, \"/raw_aggregated_scores.xlsx\"))\n",
    "\n",
    "save_loc <- paste0(base_loc, \"/raw_idiolect_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d52e537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;246m# A tibble: 2,144 × 8\u001b[39m\n",
       "   data_type corpus scoring_model problem num_files files_completed files_scored\n",
       "   \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m       \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m           \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m        \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[38;5;250m 1\u001b[39m test      Perve… Qwen2.5-0.5B… Josh M…         2               2            2\n",
       "\u001b[38;5;250m 2\u001b[39m test      Perve… Qwen2.5-0.5B… Josh M…         2               2            2\n",
       "\u001b[38;5;250m 3\u001b[39m test      Perve… Qwen2.5-0.5B… OSU_Co…         2               2            2\n",
       "\u001b[38;5;250m 4\u001b[39m test      Perve… Qwen2.5-0.5B… OSU_Co…         2               2            2\n",
       "\u001b[38;5;250m 5\u001b[39m test      Perve… Qwen2.5-0.5B… Proteg…         2               2            2\n",
       "\u001b[38;5;250m 6\u001b[39m test      Perve… Qwen2.5-0.5B… Proteg…         2               2            2\n",
       "\u001b[38;5;250m 7\u001b[39m test      Perve… Qwen2.5-0.5B… Rudy L…         2               2            2\n",
       "\u001b[38;5;250m 8\u001b[39m test      Perve… Qwen2.5-0.5B… Rudy L…         2               2            2\n",
       "\u001b[38;5;250m 9\u001b[39m test      Perve… Qwen2.5-0.5B… Salsak…         2               2            2\n",
       "\u001b[38;5;250m10\u001b[39m test      Perve… Qwen2.5-0.5B… Salsak…         2               2            2\n",
       "\u001b[38;5;246m# ℹ 2,134 more rows\u001b[39m\n",
       "\u001b[38;5;246m# ℹ 1 more variable: problem_completed <lgl>\u001b[39m\n",
       "\u001b[38;5;246m# ℹ Use `print(n = ...)` to see more rows\u001b[39m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17cec323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;246m# A tibble: 7,266 × 9\u001b[39m\n",
       "   data_type corpus            scoring_model       problem target min_token_size\n",
       "   \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m             \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m               \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m   \u001b[3m\u001b[38;5;246m<lgl>\u001b[39m\u001b[23m           \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[38;5;250m 1\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… Josh M… TRUE                2\n",
       "\u001b[38;5;250m 2\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… Josh M… TRUE                3\n",
       "\u001b[38;5;250m 3\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… Josh M… TRUE                4\n",
       "\u001b[38;5;250m 4\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… Josh M… FALSE               2\n",
       "\u001b[38;5;250m 5\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… Josh M… FALSE               3\n",
       "\u001b[38;5;250m 6\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… Josh M… FALSE               4\n",
       "\u001b[38;5;250m 7\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… OSU_Co… TRUE                2\n",
       "\u001b[38;5;250m 8\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… OSU_Co… TRUE                3\n",
       "\u001b[38;5;250m 9\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… OSU_Co… TRUE                4\n",
       "\u001b[38;5;250m10\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… OSU_Co… TRUE                5\n",
       "\u001b[38;5;246m# ℹ 7,256 more rows\u001b[39m\n",
       "\u001b[38;5;246m# ℹ 3 more variables: no_context_sum_log_probs <dbl>,\u001b[39m\n",
       "\u001b[38;5;246m#   known_sum_log_probs <dbl>, unknown_sum_log_probs <dbl>\u001b[39m\n",
       "\u001b[38;5;246m# ℹ Use `print(n = ...)` to see more rows\u001b[39m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a27440b",
   "metadata": {},
   "source": [
    "## Get Only Completed Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ded18ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;246m# A tibble: 6 × 8\u001b[39m\n",
       "  data_type corpus  scoring_model problem num_files files_completed files_scored\n",
       "  \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m   \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m       \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m           \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m        \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[38;5;250m1\u001b[39m test      Perver… Qwen2.5-0.5B… Josh M…         2               2            2\n",
       "\u001b[38;5;250m2\u001b[39m test      Perver… Qwen2.5-0.5B… Josh M…         2               2            2\n",
       "\u001b[38;5;250m3\u001b[39m test      Perver… Qwen2.5-0.5B… OSU_Co…         2               2            2\n",
       "\u001b[38;5;250m4\u001b[39m test      Perver… Qwen2.5-0.5B… OSU_Co…         2               2            2\n",
       "\u001b[38;5;250m5\u001b[39m test      Perver… Qwen2.5-0.5B… Proteg…         2               2            2\n",
       "\u001b[38;5;250m6\u001b[39m test      Perver… Qwen2.5-0.5B… Proteg…         2               2            2\n",
       "\u001b[38;5;246m# ℹ 1 more variable: problem_completed <lgl>\u001b[39m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_problems <- problem_metadata %>%\n",
    "  filter(problem_completed == TRUE)\n",
    "\n",
    "complete_problems %>% head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6546454",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_problem_scores <- problem_scores %>%\n",
    "  inner_join(complete_problems, by=c(\"data_type\", \"corpus\", \"scoring_model\", \"problem\")) %>%\n",
    "  select(-c(\"num_files\", \"files_completed\", \"files_scored\", \"problem_completed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01dc3e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;246m# A tibble: 7,196 × 9\u001b[39m\n",
       "   data_type corpus            scoring_model       problem target min_token_size\n",
       "   \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m             \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m               \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m   \u001b[3m\u001b[38;5;246m<lgl>\u001b[39m\u001b[23m           \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[38;5;250m 1\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… Josh M… TRUE                2\n",
       "\u001b[38;5;250m 2\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… Josh M… TRUE                3\n",
       "\u001b[38;5;250m 3\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… Josh M… TRUE                4\n",
       "\u001b[38;5;250m 4\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… Josh M… FALSE               2\n",
       "\u001b[38;5;250m 5\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… Josh M… FALSE               3\n",
       "\u001b[38;5;250m 6\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… Josh M… FALSE               4\n",
       "\u001b[38;5;250m 7\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… OSU_Co… TRUE                2\n",
       "\u001b[38;5;250m 8\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… OSU_Co… TRUE                3\n",
       "\u001b[38;5;250m 9\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… OSU_Co… TRUE                4\n",
       "\u001b[38;5;250m10\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instr… OSU_Co… TRUE                5\n",
       "\u001b[38;5;246m# ℹ 7,186 more rows\u001b[39m\n",
       "\u001b[38;5;246m# ℹ 3 more variables: no_context_sum_log_probs <dbl>,\u001b[39m\n",
       "\u001b[38;5;246m#   known_sum_log_probs <dbl>, unknown_sum_log_probs <dbl>\u001b[39m\n",
       "\u001b[38;5;246m# ℹ Use `print(n = ...)` to see more rows\u001b[39m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_problem_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57549b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_data <- complete_problem_scores %>%\n",
    "  rename('score'='unknown_sum_log_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3db17444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for later\n",
    "token_size_problems <- score_data %>%\n",
    "  select(data_type, corpus, problem, min_token_size, target) %>%\n",
    "  distinct() %>%\n",
    "  arrange(data_type, corpus, problem, min_token_size, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70416427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;246m# A tibble: 6 × 4\u001b[39m\n",
       "  data_type corpus            scoring_model         min_token_size\n",
       "  \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m             \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m                          \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[38;5;250m1\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instruct              2\n",
       "\u001b[38;5;250m2\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instruct              3\n",
       "\u001b[38;5;250m3\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instruct              4\n",
       "\u001b[38;5;250m4\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instruct              5\n",
       "\u001b[38;5;250m5\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instruct              6\n",
       "\u001b[38;5;250m6\u001b[39m test      Perverted Justice Qwen2.5-0.5B-Instruct              7"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_model_sizes <- score_data %>%\n",
    "  select(data_type, corpus, scoring_model, min_token_size) %>%\n",
    "  distinct() %>%\n",
    "  arrange(data_type, corpus, scoring_model, min_token_size)\n",
    "\n",
    "distinct_model_sizes %>% head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2132677",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_group_all_files <- function(i, data_type, corpus, scoring_model, min_token_size) {\n",
    "  message(sprintf(\n",
    "    \"[%d] data_type=%s | corpus=%s | scoring_model=%s | min_token_size=%s\",\n",
    "    i, data_type, corpus, scoring_model, min_token_size\n",
    "  ))\n",
    "\n",
    "  filtered <- score_data %>%\n",
    "    filter(\n",
    "      data_type == !!data_type,\n",
    "      scoring_model == !!scoring_model,\n",
    "      corpus == !!corpus,\n",
    "      min_token_size == !!min_token_size\n",
    "    )\n",
    "\n",
    "  perf_eval <- tryCatch(\n",
    "    {\n",
    "      out <- performance(filtered)\n",
    "      out$evaluation\n",
    "    },\n",
    "    error = function(e) {\n",
    "      message(sprintf(\"  -> FAILED (%s)\", conditionMessage(e)))\n",
    "      NULL\n",
    "    }\n",
    "  )\n",
    "\n",
    "  if (is.null(perf_eval)) return(NULL)\n",
    "\n",
    "  bind_cols(\n",
    "    tibble(\n",
    "      data_type = data_type,\n",
    "      corpus = corpus,\n",
    "      scoring_model = scoring_model,\n",
    "      min_token_size = min_token_size\n",
    "    ),\n",
    "    as_tibble(perf_eval)\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93933421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[2] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[3] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[4] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[5] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=6\n",
      "  |======================================================================| 100%\n",
      "[6] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=7\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[7] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=8\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[8] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[9] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[10] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=11\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[11] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=12\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[12] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=14\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[13] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[14] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=19\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[15] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[16] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[17] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[18] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[19] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=6\n",
      "  |======================================================================| 100%\n",
      "[20] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=7\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[21] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=8\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[22] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[23] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[24] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=11\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[25] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=12\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[26] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=14\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[27] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[28] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=19\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[29] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=1\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[30] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[31] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[32] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[33] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[34] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=6\n",
      "  |======================================================================| 100%\n",
      "[35] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=7\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[36] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=8\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[37] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[38] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[39] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=11\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[40] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=12\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[41] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=13\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[42] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=14\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[43] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[44] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=16\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[45] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=17\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[46] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=21\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[47] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[48] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[49] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[50] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[51] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=6\n",
      "  |====================================================================  |  98%  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[52] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=7\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[53] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=8\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[54] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[55] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[56] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=11\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[57] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=12\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[58] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=13\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[59] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=14\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[60] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[61] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=16\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[62] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=21\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[63] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=1\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[64] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[65] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[66] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[67] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[68] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=6\n",
      "  |=========================                                             |  36%  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[69] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=7\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[70] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=8\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[71] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[72] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[73] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=11\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[74] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=13\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[75] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[76] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=18\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[77] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=19\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[78] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=20\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[79] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=22\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[80] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=23\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[81] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=24\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[82] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=25\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[83] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=26\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[84] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=28\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[85] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=31\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[86] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=32\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[87] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=42\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[88] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=59\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[89] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=60\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[90] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=72\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[91] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=88\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[92] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=154\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[93] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=300\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[94] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=320\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[95] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=1\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[96] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[97] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[98] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[99] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[100] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=6\n",
      "  |=========================                                             |  36%  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[101] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=7\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[102] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=8\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[103] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[104] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[105] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=11\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[106] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=13\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[107] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[108] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=18\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[109] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=19\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[110] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=20\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[111] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=22\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[112] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=23\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[113] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=24\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[114] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=25\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[115] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=26\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[116] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=28\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[117] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=31\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[118] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=32\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[119] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=42\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[120] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=59\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[121] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=60\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[122] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=72\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[123] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=88\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[124] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=154\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[125] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=300\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[126] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=320\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[127] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[128] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[129] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[130] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[131] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=6\n",
      "  |======================================================================| 100%\n",
      "[132] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=7\n",
      "  |======================================================                |  76%  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[133] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=8\n",
      "  |=======================                                               |  33%  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[134] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=9\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[135] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[136] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=11\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[137] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=14\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[138] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[139] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=18\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[140] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=19\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[141] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=20\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[142] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=21\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[143] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=22\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[144] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=23\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[145] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=25\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[146] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=26\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[147] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=28\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[148] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=29\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[149] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=30\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[150] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=31\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[151] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=44\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[152] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=63\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[153] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=75\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[154] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=91\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[155] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=162\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[156] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=309\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[157] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=323\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[158] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=1\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[159] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[160] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[161] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[162] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[163] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=6\n",
      "  |======================================================================| 100%\n",
      "[164] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=7\n",
      "  |==========================                                            |  38%  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[165] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=8\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[166] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[167] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[168] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=12\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[169] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=14\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[170] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[171] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=19\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[172] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=20\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[173] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=21\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[174] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=22\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[175] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=24\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[176] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=25\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[177] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=26\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[178] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=27\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[179] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=28\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[180] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=31\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[181] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=33\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[182] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=37\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[183] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=44\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[184] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=62\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[185] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=63\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[186] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=76\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[187] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=94\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[188] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=165\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[189] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=315\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[190] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=331\n",
      "  -> FAILED (must have 'max' > 'min')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;246m# A tibble: 6 × 20\u001b[39m\n",
       "  data_type corpus            scoring_model  min_token_size  Cllr Cllr_min   EER\n",
       "  \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m             \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m                   \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[38;5;250m1\u001b[39m test      Perverted Justice Qwen2.5-0.5B-…              2 0.686    0.576  23.2\n",
       "\u001b[38;5;250m2\u001b[39m test      Perverted Justice Qwen2.5-0.5B-…              3 0.528    0.489  16.8\n",
       "\u001b[38;5;250m3\u001b[39m test      Perverted Justice Qwen2.5-0.5B-…              4 0.481    0.436  14.0\n",
       "\u001b[38;5;250m4\u001b[39m test      Perverted Justice Qwen2.5-0.5B-…              5 0.716    0.659  25.2\n",
       "\u001b[38;5;250m5\u001b[39m test      Perverted Justice Qwen2.5-0.5B-…              6 0.487    0.553  22.4\n",
       "\u001b[38;5;250m6\u001b[39m test      Perverted Justice Qwen2.5-1.5B-…              2 0.695    0.579  23.4\n",
       "\u001b[38;5;246m# ℹ 13 more variables: `Mean TRUE LLR` <dbl>, `Mean FALSE LLR` <dbl>,\u001b[39m\n",
       "\u001b[38;5;246m#   `TRUE trials` <dbl>, `FALSE trials` <dbl>, AUC <dbl>,\u001b[39m\n",
       "\u001b[38;5;246m#   `Balanced Accuracy` <dbl>, Precision <dbl>, Recall <dbl>, F1 <dbl>,\u001b[39m\n",
       "\u001b[38;5;246m#   TP <int>, FN <int>, FP <int>, TN <int>\u001b[39m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results <- distinct_model_sizes %>%\n",
    "  mutate(i = row_number()) %>%\n",
    "  pmap_dfr(process_group_all_files) %>%\n",
    "  arrange(data_type, corpus, scoring_model, min_token_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9723780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;246m# A tibble: 37 × 20\u001b[39m\n",
       "   data_type corpus          scoring_model min_token_size    Cllr Cllr_min   EER\n",
       "   \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m           \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m                  \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[38;5;250m 1\u001b[39m test      Perverted Just… Qwen2.5-0.5B…              2   0.686    0.576  23.2\n",
       "\u001b[38;5;250m 2\u001b[39m test      Perverted Just… Qwen2.5-0.5B…              3   0.528    0.489  16.8\n",
       "\u001b[38;5;250m 3\u001b[39m test      Perverted Just… Qwen2.5-0.5B…              4   0.481    0.436  14.0\n",
       "\u001b[38;5;250m 4\u001b[39m test      Perverted Just… Qwen2.5-0.5B…              5   0.716    0.659  25.2\n",
       "\u001b[38;5;250m 5\u001b[39m test      Perverted Just… Qwen2.5-0.5B…              6   0.487    0.553  22.4\n",
       "\u001b[38;5;250m 6\u001b[39m test      Perverted Just… Qwen2.5-1.5B…              2   0.695    0.579  23.4\n",
       "\u001b[38;5;250m 7\u001b[39m test      Perverted Just… Qwen2.5-1.5B…              3   0.532    0.498  17.1\n",
       "\u001b[38;5;250m 8\u001b[39m test      Perverted Just… Qwen2.5-1.5B…              4   0.478    0.430  13.6\n",
       "\u001b[38;5;250m 9\u001b[39m test      Perverted Just… Qwen2.5-1.5B…              5   0.737    0.668  26.3\n",
       "\u001b[38;5;250m10\u001b[39m test      Perverted Just… Qwen2.5-1.5B…              6 190.       0.754  33.8\n",
       "\u001b[38;5;246m# ℹ 27 more rows\u001b[39m\n",
       "\u001b[38;5;246m# ℹ 13 more variables: `Mean TRUE LLR` <dbl>, `Mean FALSE LLR` <dbl>,\u001b[39m\n",
       "\u001b[38;5;246m#   `TRUE trials` <dbl>, `FALSE trials` <dbl>, AUC <dbl>,\u001b[39m\n",
       "\u001b[38;5;246m#   `Balanced Accuracy` <dbl>, Precision <dbl>, Recall <dbl>, F1 <dbl>,\u001b[39m\n",
       "\u001b[38;5;246m#   TP <int>, FN <int>, FP <int>, TN <int>\u001b[39m\n",
       "\u001b[38;5;246m# ℹ Use `print(n = ...)` to see more rows\u001b[39m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05c4cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results %>% write_xlsx(save_loc)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
