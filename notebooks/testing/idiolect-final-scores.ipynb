{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d896ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressWarnings(\n",
    "  suppressPackageStartupMessages(\n",
    "    {\n",
    "      library(readxl)\n",
    "      library(writexl)\n",
    "      library(dplyr)\n",
    "      library(purrr)\n",
    "      library(tibble)\n",
    "      library(devtools)\n",
    "    }\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "942aad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m──\u001b[39m \u001b[36mR CMD build\u001b[39m \u001b[36m─────────────────────────────────────────────────────────────────\u001b[39m\n",
      "✔  checking for file ‘/Users/user/Documents/GitHub/idiolect/DESCRIPTION’ (336ms)\n",
      "─  preparing ‘idiolect’:\n",
      "✔  checking DESCRIPTION meta-information ...\n",
      "─  checking for LF line-endings in source and make files and shell scripts\n",
      "─  checking for empty or unneeded directories\n",
      "─  building ‘idiolect_1.1.1.9000.tar.gz’\n",
      "   \n",
      "Running /Library/Frameworks/R.framework/Resources/bin/R CMD INSTALL \\\n",
      "  /var/folders/xx/hy496x3x5sn4hy9gy1fk19lw0000gp/T//RtmpYBP5Aw/idiolect_1.1.1.9000.tar.gz \\\n",
      "  --install-tests \n",
      "* installing to library ‘/Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library’\n",
      "* installing *source* package ‘idiolect’ ...\n",
      "** using staged installation\n",
      "** R\n",
      "** data\n",
      "*** moving datasets to lazyload DB\n",
      "** inst\n",
      "** tests\n",
      "** byte-compile and prepare package for lazy loading\n",
      "Warning messages:\n",
      "1: package ‘quanteda’ was built under R version 4.2.3 \n",
      "2: In .recacheSubclasses(def@className, def, env) :\n",
      "  undefined subclass \"ndiMatrix\" of class \"replValueSp\"; definition not updated\n",
      "3: In .recacheSubclasses(def@className, def, env) :\n",
      "  undefined subclass \"pcorMatrix\" of class \"replValueSp\"; definition not updated\n",
      "** help\n",
      "*** installing help indices\n",
      "*** copying figures\n",
      "** building package indices\n",
      "** installing vignettes\n",
      "** testing if installed package can be loaded from temporary location\n",
      "Warning: package ‘quanteda’ was built under R version 4.2.3\n",
      "Warning in .recacheSubclasses(def@className, def, env) :\n",
      "  undefined subclass \"ndiMatrix\" of class \"replValueSp\"; definition not updated\n",
      "Warning in .recacheSubclasses(def@className, def, env) :\n",
      "  undefined subclass \"pcorMatrix\" of class \"replValueSp\"; definition not updated\n",
      "** testing if installed package can be loaded from final location\n",
      "Warning: package ‘quanteda’ was built under R version 4.2.3\n",
      "Warning in .recacheSubclasses(def@className, def, env) :\n",
      "  undefined subclass \"ndiMatrix\" of class \"replValueSp\"; definition not updated\n",
      "Warning in .recacheSubclasses(def@className, def, env) :\n",
      "  undefined subclass \"pcorMatrix\" of class \"replValueSp\"; definition not updated\n",
      "** testing if installed package keeps a record of temporary installation path\n",
      "* DONE (idiolect)\n"
     ]
    }
   ],
   "source": [
    "# installs from the local folder (your modified clone)\n",
    "devtools::install(\"/Users/user/Documents/GitHub/idiolect\", upgrade = \"never\")\n",
    "\n",
    "library(idiolect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d68971",
   "metadata": {},
   "source": [
    "## Get Number of Files in Each Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e0d4412",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loc <- \"/Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs\"\n",
    "problem_metadata <- read_excel(paste0(base_loc, \"/raw_problem_completed_metadata.xlsx\")) %>%\n",
    "  select(data_type, corpus, scoring_model, problem, num_files, files_completed, files_scored, problem_completed)\n",
    "\n",
    "problem_scores <- read_excel(paste0(base_loc, \"/raw_aggregated_scores.xlsx\"))\n",
    "\n",
    "save_loc <- paste0(base_loc, \"/raw_idiolect_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d52e537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;246m# A tibble: 2,336 × 8\u001b[39m\n",
       "   data_type corpus scoring_model problem num_files files_completed files_scored\n",
       "   \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m       \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m           \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m        \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[38;5;250m 1\u001b[39m test      Enron  Qwen2.5-0.5B… Kevin.…         4               4            4\n",
       "\u001b[38;5;250m 2\u001b[39m test      Enron  Qwen2.5-0.5B… Kevin.…         4               4            4\n",
       "\u001b[38;5;250m 3\u001b[39m test      Enron  Qwen2.5-0.5B… Kimber…         4               4            4\n",
       "\u001b[38;5;250m 4\u001b[39m test      Enron  Qwen2.5-0.5B… Kimber…         4               4            4\n",
       "\u001b[38;5;250m 5\u001b[39m test      Enron  Qwen2.5-0.5B… Larry.…         4               4            4\n",
       "\u001b[38;5;250m 6\u001b[39m test      Enron  Qwen2.5-0.5B… Larry.…         4               4            4\n",
       "\u001b[38;5;250m 7\u001b[39m test      Enron  Qwen2.5-0.5B… Lindy.…         4               4            4\n",
       "\u001b[38;5;250m 8\u001b[39m test      Enron  Qwen2.5-0.5B… Lindy.…         4               4            4\n",
       "\u001b[38;5;250m 9\u001b[39m test      Enron  Qwen2.5-0.5B… Liz.ta…         3               3            3\n",
       "\u001b[38;5;250m10\u001b[39m test      Enron  Qwen2.5-0.5B… Liz.ta…         3               3            3\n",
       "\u001b[38;5;246m# ℹ 2,326 more rows\u001b[39m\n",
       "\u001b[38;5;246m# ℹ 1 more variable: problem_completed <lgl>\u001b[39m\n",
       "\u001b[38;5;246m# ℹ Use `print(n = ...)` to see more rows\u001b[39m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17cec323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;246m# A tibble: 8,220 × 9\u001b[39m\n",
       "   data_type corpus scoring_model         problem          target min_token_size\n",
       "   \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m                 \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m            \u001b[3m\u001b[38;5;246m<lgl>\u001b[39m\u001b[23m           \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[38;5;250m 1\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … TRUE                2\n",
       "\u001b[38;5;250m 2\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … TRUE                3\n",
       "\u001b[38;5;250m 3\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … TRUE                4\n",
       "\u001b[38;5;250m 4\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … TRUE                6\n",
       "\u001b[38;5;250m 5\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … TRUE                7\n",
       "\u001b[38;5;250m 6\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … FALSE               2\n",
       "\u001b[38;5;250m 7\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … FALSE               3\n",
       "\u001b[38;5;250m 8\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … FALSE               4\n",
       "\u001b[38;5;250m 9\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … FALSE               5\n",
       "\u001b[38;5;250m10\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kimberly.watson… TRUE                2\n",
       "\u001b[38;5;246m# ℹ 8,210 more rows\u001b[39m\n",
       "\u001b[38;5;246m# ℹ 3 more variables: no_context_sum_log_probs <dbl>,\u001b[39m\n",
       "\u001b[38;5;246m#   known_sum_log_probs <dbl>, unknown_sum_log_probs <dbl>\u001b[39m\n",
       "\u001b[38;5;246m# ℹ Use `print(n = ...)` to see more rows\u001b[39m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a27440b",
   "metadata": {},
   "source": [
    "## Get Only Completed Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ded18ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;246m# A tibble: 6 × 8\u001b[39m\n",
       "  data_type corpus scoring_model  problem num_files files_completed files_scored\n",
       "  \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m          \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m       \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m           \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m        \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[38;5;250m1\u001b[39m test      Enron  Qwen2.5-0.5B-… Kevin.…         4               4            4\n",
       "\u001b[38;5;250m2\u001b[39m test      Enron  Qwen2.5-0.5B-… Kevin.…         4               4            4\n",
       "\u001b[38;5;250m3\u001b[39m test      Enron  Qwen2.5-0.5B-… Kimber…         4               4            4\n",
       "\u001b[38;5;250m4\u001b[39m test      Enron  Qwen2.5-0.5B-… Kimber…         4               4            4\n",
       "\u001b[38;5;250m5\u001b[39m test      Enron  Qwen2.5-0.5B-… Larry.…         4               4            4\n",
       "\u001b[38;5;250m6\u001b[39m test      Enron  Qwen2.5-0.5B-… Larry.…         4               4            4\n",
       "\u001b[38;5;246m# ℹ 1 more variable: problem_completed <lgl>\u001b[39m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_problems <- problem_metadata %>%\n",
    "  filter(problem_completed == TRUE)\n",
    "\n",
    "complete_problems %>% head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6546454",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_problem_scores <- problem_scores %>%\n",
    "  inner_join(complete_problems, by=c(\"data_type\", \"corpus\", \"scoring_model\", \"problem\")) %>%\n",
    "  select(-c(\"num_files\", \"files_completed\", \"files_scored\", \"problem_completed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01dc3e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;246m# A tibble: 8,150 × 9\u001b[39m\n",
       "   data_type corpus scoring_model         problem          target min_token_size\n",
       "   \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m                 \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m            \u001b[3m\u001b[38;5;246m<lgl>\u001b[39m\u001b[23m           \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[38;5;250m 1\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … TRUE                2\n",
       "\u001b[38;5;250m 2\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … TRUE                3\n",
       "\u001b[38;5;250m 3\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … TRUE                4\n",
       "\u001b[38;5;250m 4\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … TRUE                6\n",
       "\u001b[38;5;250m 5\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … TRUE                7\n",
       "\u001b[38;5;250m 6\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … FALSE               2\n",
       "\u001b[38;5;250m 7\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … FALSE               3\n",
       "\u001b[38;5;250m 8\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … FALSE               4\n",
       "\u001b[38;5;250m 9\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kevin.hyatt vs … FALSE               5\n",
       "\u001b[38;5;250m10\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct Kimberly.watson… TRUE                2\n",
       "\u001b[38;5;246m# ℹ 8,140 more rows\u001b[39m\n",
       "\u001b[38;5;246m# ℹ 3 more variables: no_context_sum_log_probs <dbl>,\u001b[39m\n",
       "\u001b[38;5;246m#   known_sum_log_probs <dbl>, unknown_sum_log_probs <dbl>\u001b[39m\n",
       "\u001b[38;5;246m# ℹ Use `print(n = ...)` to see more rows\u001b[39m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_problem_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57549b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_data <- complete_problem_scores %>%\n",
    "  rename('score'='unknown_sum_log_probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3db17444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for later\n",
    "token_size_problems <- score_data %>%\n",
    "  select(data_type, corpus, problem, min_token_size, target) %>%\n",
    "  distinct() %>%\n",
    "  arrange(data_type, corpus, problem, min_token_size, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70416427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;246m# A tibble: 6 × 4\u001b[39m\n",
       "  data_type corpus scoring_model         min_token_size\n",
       "  \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m                          \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[38;5;250m1\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct              2\n",
       "\u001b[38;5;250m2\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct              3\n",
       "\u001b[38;5;250m3\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct              4\n",
       "\u001b[38;5;250m4\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct              5\n",
       "\u001b[38;5;250m5\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct              6\n",
       "\u001b[38;5;250m6\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct              7"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_model_sizes <- score_data %>%\n",
    "  select(data_type, corpus, scoring_model, min_token_size) %>%\n",
    "  distinct() %>%\n",
    "  arrange(data_type, corpus, scoring_model, min_token_size)\n",
    "\n",
    "distinct_model_sizes %>% head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2132677",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_group_all_files <- function(i, data_type, corpus, scoring_model, min_token_size) {\n",
    "  message(sprintf(\n",
    "    \"[%d] data_type=%s | corpus=%s | scoring_model=%s | min_token_size=%s\",\n",
    "    i, data_type, corpus, scoring_model, min_token_size\n",
    "  ))\n",
    "\n",
    "  filtered <- score_data %>%\n",
    "    filter(\n",
    "      data_type == !!data_type,\n",
    "      scoring_model == !!scoring_model,\n",
    "      corpus == !!corpus,\n",
    "      min_token_size == !!min_token_size\n",
    "    )\n",
    "\n",
    "  perf_eval <- tryCatch(\n",
    "    {\n",
    "      out <- performance(filtered)\n",
    "      out$evaluation\n",
    "    },\n",
    "    error = function(e) {\n",
    "      message(sprintf(\"  -> FAILED (%s)\", conditionMessage(e)))\n",
    "      NULL\n",
    "    }\n",
    "  )\n",
    "\n",
    "  if (is.null(perf_eval)) return(NULL)\n",
    "\n",
    "  bind_cols(\n",
    "    tibble(\n",
    "      data_type = data_type,\n",
    "      corpus = corpus,\n",
    "      scoring_model = scoring_model,\n",
    "      min_token_size = min_token_size\n",
    "    ),\n",
    "    as_tibble(perf_eval)\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93933421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[2] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[3] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[4] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[5] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=6\n",
      "  |======================================================================| 100%\n",
      "[6] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=7\n",
      "  |======================================================================| 100%\n",
      "[7] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=8\n",
      "  |======================================================================| 100%\n",
      "[8] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[9] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=10\n",
      "  |===================================                                   |  50%  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[10] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=11\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[11] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=12\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[12] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=13\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[13] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=14\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[14] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[15] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=16\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[16] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=17\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[17] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=19\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[18] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=20\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[19] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=22\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[20] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=23\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[21] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=33\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[22] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=37\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[23] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=39\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[24] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=41\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[25] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=44\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[26] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=47\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[27] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=48\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[28] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=52\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[29] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=53\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[30] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=65\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[31] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=69\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[32] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=74\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[33] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=99\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[34] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=102\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[35] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=123\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[36] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=124\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[37] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=136\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[38] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=145\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[39] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=177\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[40] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=197\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[41] data_type=test | corpus=Enron | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=304\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[42] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[43] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[44] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[45] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[46] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=6\n",
      "  |======================================================================| 100%\n",
      "[47] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=7\n",
      "  |======================================================================| 100%\n",
      "[48] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=8\n",
      "  |======================================================================| 100%\n",
      "[49] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[50] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=10\n",
      "  |===================================                                   |  50%  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[51] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=11\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[52] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=12\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[53] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=13\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[54] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=14\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[55] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[56] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=16\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[57] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=17\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[58] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=19\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[59] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=20\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[60] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=22\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[61] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=23\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[62] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=24\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[63] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=34\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[64] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=38\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[65] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=40\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[66] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=42\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[67] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=43\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[68] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=48\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[69] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=52\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[70] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=54\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[71] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=65\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[72] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=69\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[73] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=77\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[74] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=95\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[75] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=101\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[76] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=102\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[77] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=124\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[78] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=127\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[79] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=136\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[80] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=146\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[81] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=175\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[82] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=206\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[83] data_type=test | corpus=Enron | scoring_model=gemma-3-270m | min_token_size=317\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[84] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[85] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[86] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[87] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[88] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=6\n",
      "  |======================================================================| 100%\n",
      "[89] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=7\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[90] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=8\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[91] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[92] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[93] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=11\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[94] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=12\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[95] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=14\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[96] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[97] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=19\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[98] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[99] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[100] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[101] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[102] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=6\n",
      "  |======================================================================| 100%\n",
      "[103] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=7\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[104] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=8\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[105] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[106] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[107] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=11\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[108] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=12\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[109] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=14\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[110] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[111] data_type=test | corpus=Perverted Justice | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=19\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[112] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=1\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[113] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[114] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[115] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[116] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[117] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=6\n",
      "  |======================================================================| 100%\n",
      "[118] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=7\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[119] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=8\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[120] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[121] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[122] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=11\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[123] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=12\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[124] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=13\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[125] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=14\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[126] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[127] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=16\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[128] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=17\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[129] data_type=test | corpus=Perverted Justice | scoring_model=gemma-3-270m | min_token_size=21\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[130] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[131] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[132] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[133] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[134] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=6\n",
      "  |====================================================================  |  98%  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[135] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=7\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[136] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=8\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[137] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[138] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[139] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=11\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[140] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=12\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[141] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=13\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[142] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=14\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[143] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[144] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=16\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[145] data_type=test | corpus=Perverted Justice | scoring_model=gpt2 | min_token_size=21\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[146] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=1\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[147] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[148] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[149] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[150] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[151] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=6\n",
      "  |=========================                                             |  36%  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[152] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=7\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[153] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=8\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[154] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[155] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[156] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=11\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[157] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=13\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[158] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[159] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=18\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[160] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=19\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[161] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=20\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[162] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=22\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[163] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=23\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[164] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=24\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[165] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=25\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[166] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=26\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[167] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=28\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[168] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=31\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[169] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=32\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[170] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=42\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[171] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=59\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[172] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=60\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[173] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=72\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[174] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=88\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[175] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=154\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[176] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=300\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[177] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-0.5B-Instruct | min_token_size=320\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[178] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=1\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[179] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[180] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[181] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[182] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[183] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=6\n",
      "  |=========================                                             |  36%  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[184] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=7\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[185] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=8\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[186] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[187] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[188] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=11\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[189] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=13\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[190] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[191] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=18\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[192] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=19\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[193] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=20\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[194] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=22\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[195] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=23\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[196] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=24\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[197] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=25\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[198] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=26\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[199] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=28\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[200] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=31\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[201] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=32\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[202] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=42\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[203] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=59\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[204] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=60\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[205] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=72\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[206] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=88\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[207] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=154\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[208] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=300\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[209] data_type=test | corpus=Wiki | scoring_model=Qwen2.5-1.5B-Instruct | min_token_size=320\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[210] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[211] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[212] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[213] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[214] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=6\n",
      "  |======================================================================| 100%\n",
      "[215] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=7\n",
      "  |======================================================                |  76%  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[216] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=8\n",
      "  |=======================                                               |  33%  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[217] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=9\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[218] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[219] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=11\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[220] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=14\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[221] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[222] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=18\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[223] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=19\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[224] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=20\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[225] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=21\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[226] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=22\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[227] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=23\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[228] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=25\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[229] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=26\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[230] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=28\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[231] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=29\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[232] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=30\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[233] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=31\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[234] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=44\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[235] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=63\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[236] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=75\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[237] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=91\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[238] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=162\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[239] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=309\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[240] data_type=test | corpus=Wiki | scoring_model=gemma-3-270m | min_token_size=323\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[241] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=1\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[242] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=2\n",
      "  |======================================================================| 100%\n",
      "[243] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=3\n",
      "  |======================================================================| 100%\n",
      "[244] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=4\n",
      "  |======================================================================| 100%\n",
      "[245] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=5\n",
      "  |======================================================================| 100%\n",
      "[246] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=6\n",
      "  |======================================================================| 100%\n",
      "[247] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=7\n",
      "  |==========================                                            |  38%  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[248] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=8\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[249] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=9\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[250] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=10\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[251] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=12\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[252] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=14\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[253] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=15\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[254] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=19\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[255] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=20\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[256] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=21\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[257] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=22\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[258] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=24\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[259] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=25\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[260] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=26\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[261] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=27\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[262] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=28\n",
      "  -> FAILED (Argument mu must be a nonempty numeric vector)\n",
      "[263] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=31\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[264] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=33\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[265] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=37\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[266] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=44\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[267] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=62\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[268] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=63\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[269] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=76\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[270] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=94\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[271] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=165\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[272] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=315\n",
      "  -> FAILED (must have 'max' > 'min')\n",
      "[273] data_type=test | corpus=Wiki | scoring_model=gpt2 | min_token_size=331\n",
      "  -> FAILED (must have 'max' > 'min')\n"
     ]
    }
   ],
   "source": [
    "results <- distinct_model_sizes %>%\n",
    "  mutate(i = row_number()) %>%\n",
    "  pmap_dfr(process_group_all_files) %>%\n",
    "  arrange(data_type, corpus, scoring_model, min_token_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9723780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;5;246m# A tibble: 51 × 20\u001b[39m\n",
       "   data_type corpus scoring_model         min_token_size    Cllr Cllr_min   EER\n",
       "   \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m                          \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m\n",
       "\u001b[38;5;250m 1\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct              2   0.740    0.650  22  \n",
       "\u001b[38;5;250m 2\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct              3   0.605    0.561  20.2\n",
       "\u001b[38;5;250m 3\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct              4   0.726    0.682  24.1\n",
       "\u001b[38;5;250m 4\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct              5   0.784    0.721  30.3\n",
       "\u001b[38;5;250m 5\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct              6   1.05     0.558  19.8\n",
       "\u001b[38;5;250m 6\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct              7 134.       0.993  40.9\n",
       "\u001b[38;5;250m 7\u001b[39m test      Enron  Qwen2.5-0.5B-Instruct              8   1.47     0.964  41.7\n",
       "\u001b[38;5;250m 8\u001b[39m test      Enron  gemma-3-270m                       2   0.731    0.661  22  \n",
       "\u001b[38;5;250m 9\u001b[39m test      Enron  gemma-3-270m                       3   0.622    0.559  22  \n",
       "\u001b[38;5;250m10\u001b[39m test      Enron  gemma-3-270m                       4   0.686    0.653  24.7\n",
       "\u001b[38;5;246m# ℹ 41 more rows\u001b[39m\n",
       "\u001b[38;5;246m# ℹ 13 more variables: `Mean TRUE LLR` <dbl>, `Mean FALSE LLR` <dbl>,\u001b[39m\n",
       "\u001b[38;5;246m#   `TRUE trials` <dbl>, `FALSE trials` <dbl>, AUC <dbl>,\u001b[39m\n",
       "\u001b[38;5;246m#   `Balanced Accuracy` <dbl>, Precision <dbl>, Recall <dbl>, F1 <dbl>,\u001b[39m\n",
       "\u001b[38;5;246m#   TP <int>, FN <int>, FP <int>, TN <int>\u001b[39m\n",
       "\u001b[38;5;246m# ℹ Use `print(n = ...)` to see more rows\u001b[39m"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05c4cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results %>% write_xlsx(save_loc)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
