{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19672287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from typing import Iterable, Optional\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edd3b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt2\"]\n",
    "\n",
    "corpora = [\n",
    "    \"Wiki\", \"Enron\", \"Perverted Justice\", \"StackExchange\", \"ACL\",\n",
    "    \"TripAdvisor\", \"The Apricity\", \"Koppel's Blogs\"\n",
    "]\n",
    "\n",
    "data_types = [\"training\", \"test\"]\n",
    "\n",
    "base_loc = \"/Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2203a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complete_problems(\n",
    "    score_df: pd.DataFrame,\n",
    "    metadata: pd.DataFrame,\n",
    "    join_cols: Optional[Iterable[str]] = None,\n",
    "    *,\n",
    "    completed_col: str = \"problem_completed\",\n",
    "    save_loc: str | Path | None = None,\n",
    "    overwrite: bool = False,\n",
    "    engine: str = \"openpyxl\",\n",
    "    return_df: bool = True,\n",
    ") -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Filter metadata to completed problems, inner-join to score_df on join_cols,\n",
    "    optionally save to Excel, and optionally return the joined DataFrame.\n",
    "\n",
    "    - Drops duplicate completed problems on join_cols to avoid multiplying rows.\n",
    "    - Expects metadata[completed_col] to already be boolean.\n",
    "    \"\"\"\n",
    "\n",
    "    if join_cols is None:\n",
    "        join_cols = [\"data_type\", \"corpus\", \"scoring_model\", \"max_context_tokens\", \"problem\"]\n",
    "    join_cols = list(join_cols)\n",
    "\n",
    "    # Validate required columns\n",
    "    missing_meta = [c for c in ([completed_col] + join_cols) if c not in metadata.columns]\n",
    "    if missing_meta:\n",
    "        raise KeyError(f\"metadata is missing required columns: {missing_meta}\")\n",
    "\n",
    "    missing_score = [c for c in join_cols if c not in score_df.columns]\n",
    "    if missing_score:\n",
    "        raise KeyError(f\"score_df is missing required columns: {missing_score}\")\n",
    "\n",
    "    if metadata[completed_col].dtype != bool:\n",
    "        raise TypeError(f\"Expected metadata['{completed_col}'] to be boolean.\")\n",
    "\n",
    "    completed_probs = (\n",
    "        metadata.loc[metadata[completed_col], join_cols]\n",
    "        .drop_duplicates(join_cols)\n",
    "        .copy()\n",
    "    )\n",
    "\n",
    "    joined_df = score_df.merge(completed_probs, how=\"inner\", on=join_cols)\n",
    "\n",
    "    if save_loc is not None:\n",
    "        save_loc = Path(save_loc)\n",
    "        if save_loc.exists() and not overwrite:\n",
    "            raise FileExistsError(f\"File already exists and overwrite=False: {save_loc}\")\n",
    "        save_loc.parent.mkdir(parents=True, exist_ok=True)\n",
    "        joined_df.to_excel(save_loc, index=False, engine=engine)\n",
    "\n",
    "    return joined_df if return_df else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62fdec9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing/failed for model=gpt2, data_type=test, corpus=Koppel's Blogs: [Errno 2] No such file or directory: \"/Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Koppel's Blogs/gpt2/raw_problem_completed_metadata_combined.xlsx\"\n"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    for data_type in data_types:\n",
    "        for corpus in corpora:\n",
    "            try:\n",
    "                \n",
    "                metadata = pd.read_excel(f\"{base_loc}/{data_type}/{corpus}/{model_name}/raw_problem_completed_metadata_combined.xlsx\")\n",
    "                score_df = pd.read_excel(f\"{base_loc}/{data_type}/{corpus}/{model_name}/raw_token_level_scores_combined.xlsx\")\n",
    "                save_loc = f\"{base_loc}/{data_type}/{corpus}/{model_name}/raw_token_level_scores_complete.xlsx\"\n",
    "                \n",
    "                get_complete_problems(\n",
    "                    score_df,\n",
    "                    metadata,\n",
    "                    join_cols=[\"data_type\", \"corpus\", \"scoring_model\", \"max_context_tokens\", \"problem\"],\n",
    "                    save_loc=save_loc,\n",
    "                    overwrite=True\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Missing/failed for model={model_name}, data_type={data_type}, corpus={corpus}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
