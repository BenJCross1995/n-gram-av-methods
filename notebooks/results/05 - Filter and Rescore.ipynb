{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54b5a1c",
   "metadata": {},
   "source": [
    "# Filter and Rescore\n",
    "\n",
    "This code is used to complete some filtering steps for previously scored data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dccf23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import contextlib\n",
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Iterable, Optional, Union\n",
    "from from_root import from_root\n",
    "\n",
    "sys.path.insert(0, str(from_root(\"src\")))\n",
    "\n",
    "from n_gram_filtering import apply_ngram_filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "55a3a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_by_token_num(\n",
    "    per_phrase_table: pd.DataFrame,\n",
    "    *,\n",
    "    group_cols: Optional[Union[str, Iterable[str]]] = None,\n",
    "    key_col: str = \"num_tokens\",\n",
    "    sum_cols: Optional[Iterable[str]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Group (optionally) by `group_cols`. For each group and each threshold t in\n",
    "    sorted unique values of `key_col`, sum `sum_cols` over rows where key_col >= t.\n",
    "\n",
    "    If `sum_cols` is None, it is inferred as all numeric columns excluding\n",
    "    group_cols and key_col.\n",
    "    \"\"\"\n",
    "    if group_cols is None:\n",
    "        group_cols_list: list[str] = []\n",
    "    elif isinstance(group_cols, str):\n",
    "        group_cols_list = [group_cols]\n",
    "    else:\n",
    "        group_cols_list = list(group_cols)\n",
    "\n",
    "    if sum_cols is None:\n",
    "        exclude = set(group_cols_list) | {key_col}\n",
    "        sum_cols_list = [\n",
    "            c for c in per_phrase_table.columns\n",
    "            if c not in exclude and pd.api.types.is_numeric_dtype(per_phrase_table[c])\n",
    "        ]\n",
    "    else:\n",
    "        sum_cols_list = list(sum_cols)\n",
    "\n",
    "    def _build_rows(df: pd.DataFrame, group_vals: dict) -> list[dict]:\n",
    "        token_thresholds = sorted(df[key_col].dropna().unique())\n",
    "        out: list[dict] = []\n",
    "        for t in token_thresholds:\n",
    "            filt = df[df[key_col] >= t]\n",
    "            sums = filt[sum_cols_list].sum(numeric_only=True)\n",
    "\n",
    "            row = {**group_vals, \"min_token_size\": int(t), \"n_rows\": int(len(filt))}\n",
    "            row.update(sums.to_dict())\n",
    "            out.append(row)\n",
    "        return out\n",
    "\n",
    "    rows: list[dict] = []\n",
    "    if group_cols_list:\n",
    "        for keys, gdf in per_phrase_table.groupby(group_cols_list, dropna=False, sort=False):\n",
    "            if len(group_cols_list) == 1:\n",
    "                keys = (keys,)\n",
    "            group_vals = dict(zip(group_cols_list, keys))\n",
    "            rows.extend(_build_rows(gdf, group_vals))\n",
    "        sort_by = group_cols_list + [\"min_token_size\"]\n",
    "    else:\n",
    "        rows.extend(_build_rows(per_phrase_table, {}))\n",
    "        sort_by = [\"min_token_size\"]\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(sort_by).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab13d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filtering_and_rescore(\n",
    "    df,\n",
    "    metadata,\n",
    "    model_loc = \"/Volumes/BCross/models/gpt2\",\n",
    "    token_col = 'tokens',\n",
    "    min_tokens = 2,\n",
    "    sum_cols = [\"no_context_sum_log_probs\", \"known_sum_log_probs\", \"unknown_sum_log_probs\"]\n",
    "):\n",
    "    meta_slim = (\n",
    "        metadata[[\"data_type\", \"corpus\", \"scoring_model\",\n",
    "                \"max_context_tokens\", \"problem\", \"problem_completed\"]]\n",
    "    )\n",
    "    \n",
    "    filtered_df = apply_ngram_filtering(\n",
    "        df,\n",
    "        model_loc = \"/Volumes/BCross/models/gpt2\",\n",
    "        token_col = 'tokens',\n",
    "        min_tokens = 2\n",
    "    )\n",
    "    \n",
    "    scored_df = create_summary_by_token_num(\n",
    "        per_phrase_table=filtered_df,\n",
    "        group_cols=['data_type', 'corpus', 'scoring_model', 'max_context_tokens',\n",
    "                    'problem', 'target'],\n",
    "        key_col=\"num_tokens\",\n",
    "        sum_cols=sum_cols\n",
    "    )\n",
    "    \n",
    "    scored_df = scored_df[\n",
    "        ['data_type', 'corpus', 'scoring_model', 'max_context_tokens',\n",
    "         'min_token_size', 'problem', 'target'] + sum_cols\n",
    "    ]\n",
    "    \n",
    "    scored_df = scored_df.sort_values(\n",
    "        by=[\n",
    "            \"data_type\", \"corpus\", \"scoring_model\", \"max_context_tokens\",\n",
    "            \"min_token_size\", \"problem\", \"target\"\n",
    "        ]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    final_df = (\n",
    "        pd.merge(\n",
    "            scored_df,\n",
    "            meta_slim,\n",
    "            how=\"left\",\n",
    "            on=[\"data_type\", \"corpus\", \"scoring_model\", \"max_context_tokens\", \"problem\"],\n",
    "        )\n",
    "        .loc[lambda d: d[\"problem_completed\"].eq(True)]\n",
    "        .drop(columns=[\"problem_completed\"])\n",
    "    )\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "41c4e019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: training | Wiki | gpt2\n",
      "Working on: training | Enron | gpt2\n",
      "Working on: training | Perverted Justice | gpt2\n",
      "Working on: training | StackExchange | gpt2\n",
      "Working on: training | ACL | gpt2\n",
      "Working on: training | TripAdvisor | gpt2\n",
      "Working on: training | The Apricity | gpt2\n",
      "Working on: training | Koppel's Blogs | gpt2\n",
      "Working on: training | The Telegraph | gpt2\n",
      "Working on: training | Reddit | gpt2\n",
      "Working on: test | Wiki | gpt2\n",
      "Working on: test | Enron | gpt2\n",
      "Working on: test | Perverted Justice | gpt2\n",
      "Working on: test | StackExchange | gpt2\n",
      "Working on: test | ACL | gpt2\n",
      "Working on: test | TripAdvisor | gpt2\n",
      "Working on: test | The Apricity | gpt2\n",
      "Working on: test | Koppel's Blogs | gpt2\n",
      "Working on: test | The Telegraph | gpt2\n",
      "Working on: test | Reddit | gpt2\n"
     ]
    }
   ],
   "source": [
    "models = [\"gpt2\"]\n",
    "\n",
    "corpora = [\n",
    "    \"Wiki\", \"Enron\", \"Perverted Justice\", \"StackExchange\", \"ACL\",\n",
    "    \"TripAdvisor\", \"The Apricity\", \"Koppel's Blogs\", \"The Telegraph\",\n",
    "    \"Reddit\"\n",
    "]\n",
    "\n",
    "data_types = [\"training\", \"test\"]\n",
    "\n",
    "raw_levels = [\n",
    "    \"raw_100\", \"raw_200\", \"raw_300\", \"raw_400\", \"raw_500\", \"raw_600\",\n",
    "    \"raw_700\", \"raw_800\", \"raw_900\", \"raw_1000\", \"raw\"\n",
    "]\n",
    "\n",
    "base_loc = \"/Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs\"\n",
    "\n",
    "for d_type in data_types:\n",
    "    for corpus in corpora:\n",
    "        for model in models:\n",
    "            print(f\"Working on: {d_type} | {corpus} | {model}\")\n",
    "            read_files_dir = f\"{base_loc}/{d_type}/{corpus}/{model}/raw_results\"\n",
    "            save_file_loc = f\"{base_loc}/{d_type}/{corpus}/{model}/filtered_agg_scores.xlsx\"\n",
    "            \n",
    "            data_list = []\n",
    "            for level in raw_levels:\n",
    "                file_name = f\"phrase_scores_{level}\"\n",
    "                data_loc = f\"{read_files_dir}/phrase_scores_{level}.xlsx\"\n",
    "                metadata_loc = f\"{read_files_dir}/problem_completed_metadata_{level}.xlsx\"\n",
    "                \n",
    "                df = pd.read_excel(data_loc, engine=\"openpyxl\")\n",
    "                metadata = pd.read_excel(metadata_loc, engine=\"openpyxl\")\n",
    "                \n",
    "                # Suppres printed output\n",
    "                with contextlib.redirect_stdout(io.StringIO()):\n",
    "                    rescored_df = apply_filtering_and_rescore(\n",
    "                        df,\n",
    "                        metadata\n",
    "                    )\n",
    "                \n",
    "                data_list.append(rescored_df)\n",
    "            \n",
    "            results = pd.concat(data_list, ignore_index=True)\n",
    "            \n",
    "            results.to_excel(save_file_loc, engine=\"openpyxl\", index=None)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
