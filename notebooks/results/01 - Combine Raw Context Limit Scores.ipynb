{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9aff6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Union, Sequence, Optional\n",
    "from from_root import from_root\n",
    "\n",
    "sys.path.insert(0, str(from_root(\"src\")))\n",
    "\n",
    "from read_and_write_docs import read_excel_sheets, read_rds\n",
    "from utils import list_xlsx_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c921685",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt2\"]\n",
    "\n",
    "corpora = [\n",
    "    \"Wiki\", \"Enron\", \"Perverted Justice\", \"StackExchange\", \"ACL\",\n",
    "    \"TripAdvisor\", \"The Apricity\", \"Koppel's Blogs\", \"The Telegraph\",\n",
    "    \"Reddit\"\n",
    "]\n",
    "\n",
    "data_types = [\"training\", \"test\"]\n",
    "\n",
    "raw_subdirs = (\n",
    "    \"raw\", \"raw_100\", \"raw_200\", \"raw_300\", \"raw_400\", \"raw_500\",\n",
    "    \"raw_600\", \"raw_700\", \"raw_800\", \"raw_900\", \"raw_1000\"\n",
    ")\n",
    "\n",
    "base_loc = \"/Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs\"\n",
    "\n",
    "metadata_base_loc = \"/Volumes/BCross/datasets/author_verification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb95d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_complete_to_metadata(metadata_base_loc, data_type, corpus, model, excel_files, max_context_tokens=None):\n",
    "    \n",
    "    metadata_loc = f\"{metadata_base_loc}/{data_type}/doc_level_metadata.rds\"\n",
    "    \n",
    "    metadata = read_rds(metadata_loc)\n",
    "    metadata = metadata[metadata['corpus'] == corpus]\n",
    "    metadata['scoring_model'] = model\n",
    "    metadata['max_context_tokens'] = max_context_tokens\n",
    "    \n",
    "    file_names = [ef.name for ef in excel_files]\n",
    "    # df with filename + completed=True\n",
    "    df = pd.DataFrame({\n",
    "        \"filename\": file_names,\n",
    "        \"completed\": True\n",
    "    })\n",
    "\n",
    "    # left join onto metadata_df and fill missing completed with False\n",
    "    metadata_df = (\n",
    "        metadata\n",
    "        .merge(df, on=\"filename\", how=\"left\")\n",
    "    )\n",
    "\n",
    "    metadata_df[\"completed\"] = metadata_df[\"completed\"].fillna(False).astype(bool)\n",
    "    metadata_df[\"scored\"] = False\n",
    "    \n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3317d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_problem_complete_metadata(metadata: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Groups by (data_type, corpus, scoring_model, problem) and returns:\n",
    "      - num_files: total rows\n",
    "      - files_completed: count where completed == True\n",
    "      - files_scored: count where scored == True\n",
    "      - problem_completed: True if num_files == files_scored\n",
    "    \"\"\"\n",
    "    group_cols = [\"data_type\", \"corpus\", \"scoring_model\", \"max_context_tokens\", \"problem\"]\n",
    "\n",
    "    out = (\n",
    "        metadata\n",
    "        .groupby(group_cols, dropna=False)\n",
    "        .agg(\n",
    "            num_files=(\"filename\", \"size\"),\n",
    "            files_completed=(\"completed\", lambda s: int(s.fillna(False).astype(bool).sum())),\n",
    "            files_scored=(\"scored\", lambda s: int(s.fillna(False).astype(bool).sum())),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    out[\"problem_completed\"] = out[\"num_files\"] == out[\"files_scored\"]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7740e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_max_context_tokens(raw_dir_name: Optional[str]) -> Union[int, str, None]:\n",
    "    \"\"\"\n",
    "    raw_dir_name: \"raw\" or \"raw_200\" / \"raw_300\" etc (or None).\n",
    "    Returns:\n",
    "      - \"None\" (string) if raw_dir_name == \"raw\"\n",
    "      - int if suffix exists (e.g. \"raw_200\" -> 200)\n",
    "      - None (Python) if raw_dir_name is None or doesn't match expected pattern\n",
    "    \"\"\"\n",
    "    if raw_dir_name is None:\n",
    "        return None\n",
    "\n",
    "    s = str(raw_dir_name).strip()\n",
    "    if s == \"raw\":\n",
    "        return \"None\"\n",
    "\n",
    "    m = re.fullmatch(r\"raw_(\\d+)\", s)\n",
    "    return int(m.group(1)) if m else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da16350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_for_combine(path: Path, *, engine: str | None = None) -> pd.DataFrame:\n",
    "    # keep_default_na=False stops pandas treating \"None\" as NaN\n",
    "    df = pd.read_excel(path, engine=engine, keep_default_na=False)\n",
    "\n",
    "    # Normalise max_context_length so blanks become the string \"None\"\n",
    "    if \"max_context_length\" in df.columns:\n",
    "        def _norm(v):\n",
    "            # \"\" happens if Excel cell is blank; NaN can still appear in some cases\n",
    "            if v == \"\" or v is None or (isinstance(v, float) and pd.isna(v)):\n",
    "                return \"None\"\n",
    "            # make 200.0 -> 200 (optional nicety)\n",
    "            if isinstance(v, float) and v.is_integer():\n",
    "                return int(v)\n",
    "            return v\n",
    "\n",
    "        df[\"max_context_length\"] = df[\"max_context_length\"].map(_norm)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78949547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_save_token_level_raw_scores(\n",
    "    base_loc: str | Path,\n",
    "    metadata_base_loc: str | Path,\n",
    "    data_type: str,\n",
    "    corpus: str,\n",
    "    model: str,\n",
    "    *,\n",
    "    raw_subdirs: Sequence[str] = (\"raw\",),\n",
    "    save_dirname: str | None = None,   # NEW: e.g. \"compiled\" or \"aggregates\"\n",
    "    sheet_name: str = \"metadata\",\n",
    "    output_name: str = \"token_level_raw_scores.xlsx\",\n",
    "    recursive: bool = False,\n",
    "    engine: str | None = None,\n",
    "    overwrite: bool = False,\n",
    "    combine_files: bool = False,\n",
    "    combined_file_prefix: str = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    For each row in completed_df, read all .xlsx files in:\n",
    "        {base_loc}/{data_type}/{corpus}/{model}/{raw_subdir}\n",
    "\n",
    "    Save outputs either:\n",
    "      - alongside raw_subdir parent (default, original behaviour), OR\n",
    "      - under {base_loc}/{data_type}/{corpus}/{model}/{save_dirname}/ (if provided)\n",
    "\n",
    "    If multiple raw_subdirs are provided and output_name does NOT include \"{raw_subdir}\",\n",
    "    output files are auto-suffixed to avoid collisions.\n",
    "    \"\"\"\n",
    "    \n",
    "    base_loc = Path(base_loc)\n",
    "    metadata_base_loc = Path(metadata_base_loc)\n",
    "    \n",
    "    model_dir = base_loc / data_type / corpus / model\n",
    "    save_base = (model_dir / save_dirname) if save_dirname else model_dir\n",
    "    \n",
    "    def _render_name(name: str, raw_subdir: str, *, disambiguate: bool) -> str:\n",
    "        if \"{raw_subdir}\" in name:\n",
    "            return name.format(raw_subdir=raw_subdir)\n",
    "        if disambiguate:\n",
    "            p = Path(name)\n",
    "            return f\"{p.stem}_{raw_subdir}{p.suffix}\"\n",
    "        return name\n",
    "    \n",
    "    def _combined_name(name: str, combined_file_prefix: str) -> str:\n",
    "        # if the user used a template name, swap raw_subdir for \"combined\"\n",
    "        if \"{raw_subdir}\" in name:\n",
    "            return name.format(raw_subdir=\"combined\")\n",
    "        p = Path(name)\n",
    "        return f\"{combined_file_prefix}{p.stem}_combined{p.suffix}\"\n",
    "\n",
    "    if isinstance(raw_subdirs, str):\n",
    "        raw_subdirs = (raw_subdirs,)\n",
    "\n",
    "    disambiguate_names = len(tuple(raw_subdirs)) > 1\n",
    "    \n",
    "    def _paths_for(raw_subdir: str):\n",
    "        out_name = _render_name(output_name, raw_subdir, disambiguate=disambiguate_names)\n",
    "        meta_name = _render_name(\"problem_metadata.xlsx\", raw_subdir, disambiguate=disambiguate_names)\n",
    "        summary_meta_name = _render_name(\n",
    "            \"problem_completed_metadata.xlsx\", raw_subdir, disambiguate=disambiguate_names\n",
    "        )\n",
    "        return (\n",
    "            model_dir / raw_subdir,                 # raw_dir\n",
    "            save_base / out_name,                   # out_path\n",
    "            save_base / meta_name,                  # metadata_out_path\n",
    "            save_base / summary_meta_name,          # summary_metadata_out_path\n",
    "        )\n",
    "        \n",
    "    for raw_subdir in raw_subdirs:\n",
    "        \n",
    "        raw_dir = model_dir / raw_subdir\n",
    "\n",
    "        out_name = _render_name(output_name, raw_subdir, disambiguate=disambiguate_names)\n",
    "        meta_name = _render_name(\"problem_metadata.xlsx\", raw_subdir, disambiguate=disambiguate_names)\n",
    "        summary_meta_name = _render_name(\n",
    "            \"problem_completed_metadata.xlsx\", raw_subdir, disambiguate=disambiguate_names\n",
    "        )\n",
    "\n",
    "        out_path = save_base / out_name\n",
    "        metadata_out_path = save_base / meta_name\n",
    "        summary_metadata_out_path = save_base / summary_meta_name\n",
    "\n",
    "        max_context_tokens = parse_max_context_tokens(raw_subdir)\n",
    "        \n",
    "        # skip if output already exists\n",
    "        if not overwrite and out_path.exists():\n",
    "            print(f\"SKIP (exists): {out_path}\")\n",
    "            continue\n",
    "\n",
    "        # if raw dir missing / empty, skip\n",
    "        if not raw_dir.exists():\n",
    "            print(f\"SKIP (no dir): {raw_dir}\")\n",
    "            continue\n",
    "\n",
    "        excel_files = list_xlsx_files(raw_dir, recursive=recursive)\n",
    "        if not excel_files:\n",
    "            print(f\"SKIP (no files): {raw_dir}\")\n",
    "            continue\n",
    "\n",
    "        base_metadata = compare_complete_to_metadata(\n",
    "            metadata_base_loc, data_type, corpus, model, excel_files, max_context_tokens=max_context_tokens\n",
    "        )\n",
    "        \n",
    "        combined_metadata: list[pd.DataFrame] = []\n",
    "\n",
    "        for ef in excel_files:\n",
    "            f_name = ef.name\n",
    "            try:\n",
    "                data = read_excel_sheets(ef, [sheet_name])\n",
    "                combined_metadata.append(data[sheet_name])\n",
    "\n",
    "                # âœ… mark as scored if read succeeded\n",
    "                base_metadata.loc[base_metadata[\"filename\"] == f_name, \"scored\"] = True\n",
    "            except Exception as e:\n",
    "                print(f\"  WARN: failed reading {sheet_name} from {ef}: {e}\")\n",
    "\n",
    "        if not combined_metadata:\n",
    "            print(f\"SKIP (no readable sheets): {raw_dir}\")\n",
    "            continue\n",
    "        \n",
    "        results = (\n",
    "            pd.concat(combined_metadata, ignore_index=True)\n",
    "            .sort_values([\"sample_id\", \"min_token_size\"], ascending=[True, True], kind=\"mergesort\")\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        # insert data_type before corpus, scoring_model after corpus\n",
    "        if \"corpus\" in results.columns:\n",
    "            corpus_idx = results.columns.get_loc(\"corpus\")\n",
    "\n",
    "            if \"data_type\" in results.columns:\n",
    "                results.drop(columns=[\"data_type\"], inplace=True)\n",
    "            results.insert(corpus_idx, \"data_type\", data_type)\n",
    "\n",
    "            corpus_idx = results.columns.get_loc(\"corpus\")  # re-fetch\n",
    "            if \"scoring_model\" in results.columns:\n",
    "                results.drop(columns=[\"scoring_model\"], inplace=True)\n",
    "            results.insert(corpus_idx + 1, \"scoring_model\", model)\n",
    "            \n",
    "        # move problem before known_author\n",
    "        if \"problem\" in results.columns and \"known_author\" in results.columns:\n",
    "            problem_idx = results.columns.get_loc(\"problem\")\n",
    "            known_author_idx = results.columns.get_loc(\"known_author\")\n",
    "\n",
    "            problem_col = results.pop(\"problem\")\n",
    "            if problem_idx < known_author_idx:\n",
    "                known_author_idx -= 1\n",
    "\n",
    "            results.insert(known_author_idx, \"problem\", problem_col)\n",
    "\n",
    "        # ensure save dir exists, then save\n",
    "        save_base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        results.to_excel(out_path, index=False, engine=engine)\n",
    "        print(f\"SAVED: {out_path}  (rows={len(results)})\")\n",
    "\n",
    "        base_metadata.to_excel(metadata_out_path, index=False, engine=engine)\n",
    "\n",
    "        summary_metadata = create_problem_complete_metadata(base_metadata)\n",
    "        summary_metadata.to_excel(summary_metadata_out_path, index=False, engine=engine)\n",
    "        \n",
    "# -------------------------\n",
    "    # Combined outputs (optional)\n",
    "    # -------------------------\n",
    "    if not combine_files:\n",
    "        return\n",
    "\n",
    "    # Determine combined output paths\n",
    "    combined_results_path = model_dir / _combined_name(output_name, combined_file_prefix)\n",
    "    combined_summary_path = model_dir / _combined_name(\"problem_completed_metadata.xlsx\", combined_file_prefix)\n",
    "\n",
    "    if not overwrite and combined_results_path.exists() and combined_summary_path.exists():\n",
    "        print(f\"SKIP (combined exists): {combined_results_path}\")\n",
    "        print(f\"SKIP (combined exists): {combined_summary_path}\")\n",
    "        return\n",
    "\n",
    "    results_dfs: list[pd.DataFrame] = []\n",
    "    summary_dfs: list[pd.DataFrame] = []\n",
    "\n",
    "    for raw_subdir in raw_subdirs:\n",
    "        _, out_path, _, summary_metadata_out_path = _paths_for(raw_subdir)\n",
    "\n",
    "        # Read existing per-raw_subdir files (even if we skipped creating them above)\n",
    "        if out_path.exists():\n",
    "            df = _read_for_combine(out_path, engine=engine)\n",
    "            if \"raw_subdir\" not in df.columns:\n",
    "                df.insert(len(df.columns), \"raw_subdir\", raw_subdir)\n",
    "            results_dfs.append(df)\n",
    "        else:\n",
    "            print(f\"  WARN: missing per-subdir results file (skip in combine): {out_path}\")\n",
    "\n",
    "        if summary_metadata_out_path.exists():\n",
    "            sdf = _read_for_combine(summary_metadata_out_path, engine=engine)\n",
    "            if \"raw_subdir\" not in sdf.columns:\n",
    "                sdf.insert(len(sdf.columns), \"raw_subdir\", raw_subdir)\n",
    "            summary_dfs.append(sdf)\n",
    "        else:\n",
    "            print(f\"  WARN: missing per-subdir summary file (skip in combine): {summary_metadata_out_path}\")\n",
    "\n",
    "    if results_dfs:\n",
    "        combined_results = pd.concat(results_dfs, ignore_index=True)\n",
    "\n",
    "        # nice deterministic ordering if columns exist\n",
    "        sort_cols = [c for c in [\"data_type\", \"corpus\", \"scoring_model\", \"max_context_length\", \"sample_id\", \"min_token_size\"]\n",
    "                     if c in combined_results.columns]\n",
    "        if sort_cols:\n",
    "            combined_results = combined_results.sort_values(sort_cols, kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "        save_base.mkdir(parents=True, exist_ok=True)\n",
    "        combined_results.to_excel(combined_results_path, index=False, engine=engine)\n",
    "        print(f\"SAVED (combined): {combined_results_path}  (rows={len(combined_results)})\")\n",
    "    else:\n",
    "        print(\"SKIP (combined results): no per-subdir result files found to combine\")\n",
    "\n",
    "    if summary_dfs:\n",
    "        combined_summary = pd.concat(summary_dfs, ignore_index=True)\n",
    "\n",
    "        sort_cols = [c for c in [\"data_type\", \"corpus\", \"scoring_model\", \"max_context_length\", \"problem\"]\n",
    "                     if c in combined_summary.columns]\n",
    "        if sort_cols:\n",
    "            combined_summary = combined_summary.sort_values(sort_cols, kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "        save_base.mkdir(parents=True, exist_ok=True)\n",
    "        combined_summary.to_excel(combined_summary_path, index=False, engine=engine)\n",
    "        print(f\"SAVED (combined): {combined_summary_path}  (rows={len(combined_summary)})\")\n",
    "    else:\n",
    "        print(\"SKIP (combined summary): no per-subdir summary files found to combine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e971ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Wiki/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Enron/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Perverted Justice/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/StackExchange/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/StackExchange/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/StackExchange/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/StackExchange/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/StackExchange/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/StackExchange/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/StackExchange/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/StackExchange/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/StackExchange/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/StackExchange/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/StackExchange/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/StackExchange/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/StackExchange/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/ACL/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/TripAdvisor/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/TripAdvisor/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/TripAdvisor/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/TripAdvisor/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/TripAdvisor/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/TripAdvisor/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/TripAdvisor/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/TripAdvisor/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/TripAdvisor/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/TripAdvisor/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/TripAdvisor/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/TripAdvisor/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/TripAdvisor/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Apricity/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Apricity/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Apricity/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Apricity/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Apricity/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Apricity/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Apricity/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Apricity/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Apricity/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Apricity/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Apricity/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Apricity/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Apricity/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Koppel's Blogs/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Koppel's Blogs/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Telegraph/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Telegraph/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Telegraph/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Telegraph/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Telegraph/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Telegraph/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Telegraph/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Telegraph/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Telegraph/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Telegraph/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Telegraph/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Telegraph/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/The Telegraph/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (no dir): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw\n",
      "SKIP (no dir): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_100\n",
      "SKIP (no dir): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_200\n",
      "SKIP (no dir): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_300\n",
      "SKIP (no dir): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_400\n",
      "SKIP (no dir): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_500\n",
      "SKIP (no dir): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_600\n",
      "SKIP (no dir): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_700\n",
      "SKIP (no dir): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_800\n",
      "SKIP (no dir): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_900\n",
      "SKIP (no dir): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_1000\n",
      "  WARN: missing per-subdir results file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "  WARN: missing per-subdir summary file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/problem_completed_metadata_raw.xlsx\n",
      "  WARN: missing per-subdir results file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "  WARN: missing per-subdir summary file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/problem_completed_metadata_raw_100.xlsx\n",
      "  WARN: missing per-subdir results file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "  WARN: missing per-subdir summary file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/problem_completed_metadata_raw_200.xlsx\n",
      "  WARN: missing per-subdir results file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "  WARN: missing per-subdir summary file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/problem_completed_metadata_raw_300.xlsx\n",
      "  WARN: missing per-subdir results file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "  WARN: missing per-subdir summary file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/problem_completed_metadata_raw_400.xlsx\n",
      "  WARN: missing per-subdir results file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "  WARN: missing per-subdir summary file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/problem_completed_metadata_raw_500.xlsx\n",
      "  WARN: missing per-subdir results file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "  WARN: missing per-subdir summary file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/problem_completed_metadata_raw_600.xlsx\n",
      "  WARN: missing per-subdir results file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "  WARN: missing per-subdir summary file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/problem_completed_metadata_raw_700.xlsx\n",
      "  WARN: missing per-subdir results file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "  WARN: missing per-subdir summary file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/problem_completed_metadata_raw_800.xlsx\n",
      "  WARN: missing per-subdir results file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "  WARN: missing per-subdir summary file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/problem_completed_metadata_raw_900.xlsx\n",
      "  WARN: missing per-subdir results file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "  WARN: missing per-subdir summary file (skip in combine): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_results/problem_completed_metadata_raw_1000.xlsx\n",
      "SKIP (combined results): no per-subdir result files found to combine\n",
      "SKIP (combined summary): no per-subdir summary files found to combine\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Wiki/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Enron/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Perverted Justice/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/StackExchange/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/StackExchange/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/StackExchange/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/StackExchange/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/StackExchange/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/StackExchange/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/StackExchange/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/StackExchange/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/StackExchange/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/StackExchange/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/StackExchange/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/StackExchange/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/StackExchange/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/ACL/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/TripAdvisor/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/TripAdvisor/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/TripAdvisor/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/TripAdvisor/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/TripAdvisor/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/TripAdvisor/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/TripAdvisor/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/TripAdvisor/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/TripAdvisor/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/TripAdvisor/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/TripAdvisor/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/TripAdvisor/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/TripAdvisor/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Apricity/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Apricity/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Apricity/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Apricity/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Apricity/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Apricity/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Apricity/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Apricity/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Apricity/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Apricity/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Apricity/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Apricity/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Apricity/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Koppel's Blogs/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Koppel's Blogs/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Koppel's Blogs/gpt2/raw_problem_completed_metadata_combined.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Telegraph/gpt2/raw_results/token_level_scores_raw.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Telegraph/gpt2/raw_results/token_level_scores_raw_100.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Telegraph/gpt2/raw_results/token_level_scores_raw_200.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Telegraph/gpt2/raw_results/token_level_scores_raw_300.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Telegraph/gpt2/raw_results/token_level_scores_raw_400.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Telegraph/gpt2/raw_results/token_level_scores_raw_500.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Telegraph/gpt2/raw_results/token_level_scores_raw_600.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Telegraph/gpt2/raw_results/token_level_scores_raw_700.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Telegraph/gpt2/raw_results/token_level_scores_raw_800.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Telegraph/gpt2/raw_results/token_level_scores_raw_900.xlsx\n",
      "SKIP (exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Telegraph/gpt2/raw_results/token_level_scores_raw_1000.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Telegraph/gpt2/raw_token_level_scores_combined.xlsx\n",
      "SKIP (combined exists): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/The Telegraph/gpt2/raw_problem_completed_metadata_combined.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-8>:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Reddit/gpt2/raw_results/token_level_scores_raw.xlsx  (rows=203)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-8>:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Reddit/gpt2/raw_results/token_level_scores_raw_100.xlsx  (rows=10561)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-8>:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Reddit/gpt2/raw_results/token_level_scores_raw_200.xlsx  (rows=10561)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-8>:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Reddit/gpt2/raw_results/token_level_scores_raw_300.xlsx  (rows=10561)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-8>:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Reddit/gpt2/raw_results/token_level_scores_raw_400.xlsx  (rows=10561)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-8>:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Reddit/gpt2/raw_results/token_level_scores_raw_500.xlsx  (rows=10561)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-8>:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Reddit/gpt2/raw_results/token_level_scores_raw_600.xlsx  (rows=10561)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-8>:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Reddit/gpt2/raw_results/token_level_scores_raw_700.xlsx  (rows=10561)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-8>:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Reddit/gpt2/raw_results/token_level_scores_raw_800.xlsx  (rows=10556)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-8>:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Reddit/gpt2/raw_results/token_level_scores_raw_900.xlsx  (rows=10544)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-8>:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Reddit/gpt2/raw_results/token_level_scores_raw_1000.xlsx  (rows=10533)\n",
      "SAVED (combined): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Reddit/gpt2/raw_token_level_scores_combined.xlsx  (rows=105763)\n",
      "SAVED (combined): /Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/test/Reddit/gpt2/raw_problem_completed_metadata_combined.xlsx  (rows=13200)\n"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    for data_type in data_types:\n",
    "        for corpus in corpora:\n",
    "            try:\n",
    "                build_and_save_token_level_raw_scores(\n",
    "                    base_loc=base_loc,\n",
    "                    metadata_base_loc=metadata_base_loc,\n",
    "                    data_type=data_type,\n",
    "                    corpus=corpus,\n",
    "                    model=model_name,\n",
    "                    raw_subdirs=raw_subdirs,\n",
    "                    save_dirname=\"raw_results\",\n",
    "                    sheet_name=\"metadata\",\n",
    "                    output_name=\"token_level_scores.xlsx\",\n",
    "                    recursive=False,\n",
    "                    engine=\"openpyxl\",\n",
    "                    overwrite=False,\n",
    "                    combine_files=True,\n",
    "                    combined_file_prefix=\"raw_\",\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Missing/failed for model={model_name}, data_type={data_type}, corpus={corpus}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
