{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bab5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7667f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt2\"]\n",
    "\n",
    "corpora = [\n",
    "    \"Wiki\", \"Enron\", \"Perverted Justice\", \"StackExchange\", \"ACL\",\n",
    "    \"TripAdvisor\", \"The Apricity\", \"Koppel's Blogs\", \"The Telegraph\",\n",
    "    \"Reddit\"\n",
    "]\n",
    "\n",
    "data_types = [\"training\", \"test\"]\n",
    "\n",
    "base_loc = \"/Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs\"\n",
    "\n",
    "file_name = \"raw_token_level_scores_complete.xlsx\"\n",
    "\n",
    "save_name = \"raw_agg_scores.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff8c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agg_problem_scores(\n",
    "    score_df: pd.DataFrame,\n",
    "    group_cols: list[str] | None = None,\n",
    "    sum_cols: list[str] | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate per-row scores up to the problem level by summing selected columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    score_df : pd.DataFrame\n",
    "        Input table with grouping columns + score columns.\n",
    "    group_cols : list[str], optional\n",
    "        Columns to group by. Defaults to the common set you described.\n",
    "    sum_cols : list[str], optional\n",
    "        Numeric columns to sum. Defaults to the three you listed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Grouped/aggregated DataFrame with summed score columns.\n",
    "    \"\"\"\n",
    "    if group_cols is None:\n",
    "        group_cols = [\n",
    "            \"data_type\", \"corpus\", \"scoring_model\", \"max_context_tokens\",\n",
    "            \"min_token_size\", \"problem\", \"target\"\n",
    "        ]\n",
    "\n",
    "    if sum_cols is None:\n",
    "        sum_cols = [\"no_context_sum_log_probs\", \"known_sum_log_probs\", \"unknown_sum_log_probs\"]\n",
    "\n",
    "    missing_g = [c for c in group_cols if c not in score_df.columns]\n",
    "    missing_s = [c for c in sum_cols if c not in score_df.columns]\n",
    "    if missing_g or missing_s:\n",
    "        raise KeyError(\n",
    "            f\"Missing columns. group_cols missing={missing_g}; sum_cols missing={missing_s}\"\n",
    "        )\n",
    "\n",
    "    # Ensure sum columns are numeric-ish (coerce bad strings to NaN, then treat NaN as 0 for sums)\n",
    "    df = score_df.copy()\n",
    "    for c in sum_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    out = (\n",
    "        df.groupby(group_cols, dropna=False)[sum_cols]\n",
    "          .sum(min_count=1)          # if a group is all-NaN for a col, keep NaN (not 0)\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac68e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing/failed for model=gpt2, data_type=training, corpus=Reddit: [Errno 2] No such file or directory: '/Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs/training/Reddit/gpt2/raw_token_level_scores_complete.xlsx'\n"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    for data_type in data_types:\n",
    "        for corpus in corpora:\n",
    "            try:\n",
    "                \n",
    "                file_loc = f\"{base_loc}/{data_type}/{corpus}/{model_name}/{file_name}\"\n",
    "                save_loc = f\"{base_loc}/{data_type}/{corpus}/{model_name}/{save_name}\"\n",
    "                \n",
    "                df = pd.read_excel(file_loc)\n",
    "                \n",
    "                agg_df  = create_agg_problem_scores(df)\n",
    "                \n",
    "                agg_df.to_excel(save_loc)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Missing/failed for model={model_name}, data_type={data_type}, corpus={corpus}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
