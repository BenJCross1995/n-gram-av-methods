{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1d3fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import sys\n",
    "import unicodedata\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from from_root import from_root\n",
    "\n",
    "sys.path.insert(0, str(from_root(\"src\")))\n",
    "\n",
    "from model_loading import load_model, distinct_special_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa6dcd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loc = \"/Volumes/BCross/av_datasets_experiments/ngram_masking_logrpobs\"\n",
    "\n",
    "file_name = \"raw_all_tokens.xlsx\"\n",
    "\n",
    "file_loc = f\"{base_loc}/{file_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20a50984",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loc = \"/Volumes/BCross/models/gpt2\"\n",
    "\n",
    "tokenizer, model = load_model(model_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf247128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġ', 'ĉ', 'Ċ', 'č', 'ċ']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens = distinct_special_chars(tokenizer=tokenizer)\n",
    "special_tokens[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2601f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_tokens_are_lists(df):\n",
    "    df = df.copy()\n",
    "    df[\"tokens\"] = df[\"tokens\"].apply(\n",
    "        lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f180784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_min_length(df, min_tokens: int = 2):\n",
    "    \n",
    "    df = df[df['num_tokens'] >= min_tokens]\n",
    "    \n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2379f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_only_special_tokens(df: pd.DataFrame, special_token_list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    REMOVE rows where df['tokens'] contains ONLY special tokens (and at least 1 token).\n",
    "    Assumes df['tokens'] is a list of token strings per row.\n",
    "    \"\"\"\n",
    "    special = set(special_token_list)\n",
    "    only_special = df[\"tokens\"].apply(lambda toks: bool(toks) and all(t in special for t in toks))\n",
    "    return df.loc[~only_special].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa2ed05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_only_numbers_and_special_tokens(df: pd.DataFrame, special_token_list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    REMOVE rows where df['tokens'] contains ONLY numbers plus any strings in special_token_list.\n",
    "    Example removed: [\"<special>19\", \"<special>97\", \"112\"]  (assuming \"<special>\" is in special_token_list)\n",
    "    Assumes df['tokens'] is a list (items can be str/int).\n",
    "    \"\"\"\n",
    "    special = sorted(set(map(str, special_token_list)), key=len, reverse=True)\n",
    "\n",
    "    def is_only_numbers_plus_special(toks) -> bool:\n",
    "        s = \"\".join(map(str, toks))  # combine tokens into one string\n",
    "        for sp in special:\n",
    "            s = s.replace(sp, \"\")\n",
    "        s = \"\".join(s.split())       # drop any remaining whitespace\n",
    "        return bool(s) and bool(re.fullmatch(r\"\\d+\", s))\n",
    "\n",
    "    mask = df[\"tokens\"].apply(is_only_numbers_plus_special)\n",
    "    return df.loc[~mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "94305666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_only_punct_and_special_tokens(df: pd.DataFrame, special_token_list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    REMOVE rows where df['tokens'] contains ONLY punctuation and/or special tokens,\n",
    "    allowing special tokens to appear as substrings inside tokens (e.g. \"<special>,\").\n",
    "    Assumes df['tokens'] is a list (items will be cast to str).\n",
    "    \"\"\"\n",
    "    specials = sorted(set(map(str, special_token_list)), key=len, reverse=True)\n",
    "    special_re = re.compile(\"|\".join(re.escape(s) for s in specials)) if specials else None\n",
    "\n",
    "    def strip_specials(s: str) -> str:\n",
    "        s = str(s)\n",
    "        return special_re.sub(\"\", s) if special_re else s\n",
    "\n",
    "    def is_punct_or_empty_after_strip(tok) -> bool:\n",
    "        rem = strip_specials(tok)\n",
    "        rem = \"\".join(rem.split())  # drop whitespace\n",
    "        if rem == \"\":\n",
    "            return True\n",
    "        return all(unicodedata.category(ch).startswith(\"P\") for ch in rem)\n",
    "\n",
    "    only_punct_or_special = df[\"tokens\"].apply(\n",
    "        lambda toks: bool(toks) and all(is_punct_or_empty_after_strip(t) for t in toks)\n",
    "    )\n",
    "\n",
    "    return df.loc[~only_punct_or_special].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6ce06699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_at_least_n_minus_1_specials(df: pd.DataFrame, special_token_list, n: int | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    REMOVE rows where:\n",
    "      - if n is set: len(tokens) == n AND (# special-only tokens) >= n-1\n",
    "      - if n is None: (# special-only tokens) >= len(tokens)-1  (i.e., at most 1 non-special)\n",
    "\n",
    "    Handles specials embedded inside tokens by stripping special substrings first.\n",
    "    Assumes df['tokens'] is a list (items cast to str).\n",
    "    \"\"\"\n",
    "    specials = sorted(set(map(str, special_token_list)), key=len, reverse=True)\n",
    "    special_re = re.compile(\"|\".join(re.escape(s) for s in specials)) if specials else None\n",
    "\n",
    "    def is_special_only(tok) -> bool:\n",
    "        s = str(tok)\n",
    "        if special_re:\n",
    "            s = special_re.sub(\"\", s)\n",
    "        s = \"\".join(s.split())  # drop whitespace\n",
    "        return s == \"\"\n",
    "\n",
    "    def should_remove(toks) -> bool:\n",
    "        if not toks:\n",
    "            return False\n",
    "        L = len(toks)\n",
    "        if n is not None and L != n:\n",
    "            return False\n",
    "        special_count = sum(is_special_only(t) for t in toks)\n",
    "        threshold = (n - 1) if n is not None else (L - 1)\n",
    "        return special_count >= threshold\n",
    "\n",
    "    mask = df[\"tokens\"].apply(should_remove)\n",
    "    return df.loc[~mask].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10db8000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original token count: 49866\n",
      "After filter_min_length: 49862\n",
      "After filter_only_special_tokens: 49861\n",
      "After filter_only_number_and_special_tokens: 49850\n",
      "After filter_only_punct_and_special_tokens: 49728\n",
      "After filter_at_least_n_minus_1_specials: 49021\n"
     ]
    }
   ],
   "source": [
    "raw_tokens = pd.read_excel(file_loc)\n",
    "raw_tokens = ensure_tokens_are_lists(raw_tokens)\n",
    "print(\"Original token count:\", len(raw_tokens))\n",
    "\n",
    "filtered_tokens = filter_min_length(raw_tokens, min_tokens=2)\n",
    "print(\"After filter_min_length:\", len(filtered_tokens))\n",
    "\n",
    "filtered_tokens = filter_only_special_tokens(filtered_tokens, special_tokens)\n",
    "print(\"After filter_only_special_tokens:\", len(filtered_tokens))\n",
    "\n",
    "filtered_tokens = filter_only_numbers_and_special_tokens(filtered_tokens, special_tokens)\n",
    "print(\"After filter_only_number_and_special_tokens:\", len(filtered_tokens))\n",
    "\n",
    "filtered_tokens = filter_only_punct_and_special_tokens(filtered_tokens, special_tokens)\n",
    "print(\"After filter_only_punct_and_special_tokens:\", len(filtered_tokens))\n",
    "\n",
    "filtered_tokens = filter_at_least_n_minus_1_specials(filtered_tokens, special_tokens)\n",
    "print(\"After filter_at_least_n_minus_1_specials:\", len(filtered_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b75b10f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>. dear</td>\n",
       "      <td>[., Ġdear]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16349</th>\n",
       "      <td>purposes,</td>\n",
       "      <td>[Ġpurposes, ,]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32389</th>\n",
       "      <td>, thank god</td>\n",
       "      <td>[,, Ġthank, Ġgod]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31369</th>\n",
       "      <td>if we meet</td>\n",
       "      <td>[Ġif, Ġwe, Ġmeet]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>mmm so</td>\n",
       "      <td>[mmm, Ġso]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31799</th>\n",
       "      <td>in any way</td>\n",
       "      <td>[Ġin, Ġany, Ġway]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39397</th>\n",
       "      <td>language models,</td>\n",
       "      <td>[Ġlanguage, Ġmodels, ,]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32481</th>\n",
       "      <td>, when they</td>\n",
       "      <td>[,, Ġwhen, Ġthey]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10751</th>\n",
       "      <td>which is</td>\n",
       "      <td>[Ġwhich, Ġis]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37956</th>\n",
       "      <td>a single token</td>\n",
       "      <td>[Ġa, Ġsingle, Ġtoken]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25872</th>\n",
       "      <td>. she's</td>\n",
       "      <td>[., Ġshe, 's]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3578</th>\n",
       "      <td>but a</td>\n",
       "      <td>[Ġbut, Ġa]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38858</th>\n",
       "      <td>reproducibility</td>\n",
       "      <td>[Ġreprodu, c, ibility]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36433</th>\n",
       "      <td>, connectives</td>\n",
       "      <td>[,, Ġconnect, ives]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7547</th>\n",
       "      <td>as yet</td>\n",
       "      <td>[Ġas, Ġyet]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49470</th>\n",
       "      <td>deed restrictions as soon as possible.</td>\n",
       "      <td>[Ġdeed, Ġrestrictions, Ġas, Ġsoon, Ġas, Ġpossi...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32365</th>\n",
       "      <td>i got home</td>\n",
       "      <td>[Ġi, Ġgot, Ġhome]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>terms,</td>\n",
       "      <td>[Ġterms, ,]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14525</th>\n",
       "      <td>rules are</td>\n",
       "      <td>[Ġrules, Ġare]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10617</th>\n",
       "      <td>and saw</td>\n",
       "      <td>[Ġand, Ġsaw]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12452</th>\n",
       "      <td>i pulled</td>\n",
       "      <td>[Ġi, Ġpulled]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29571</th>\n",
       "      <td>\\nyou would</td>\n",
       "      <td>[Ċ, you, Ġwould]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30041</th>\n",
       "      <td>she is so</td>\n",
       "      <td>[Ġshe, Ġis, Ġso]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8567</th>\n",
       "      <td>is well</td>\n",
       "      <td>[Ġis, Ġwell]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22423</th>\n",
       "      <td>hockey league</td>\n",
       "      <td>[Ġhockey, Ġleague]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43091</th>\n",
       "      <td>\\nwhat u want</td>\n",
       "      <td>[Ċ, what, Ġu, Ġwant]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38302</th>\n",
       "      <td>i forgot about</td>\n",
       "      <td>[Ġi, Ġforgot, Ġabout]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17423</th>\n",
       "      <td>dinner was</td>\n",
       "      <td>[Ġdinner, Ġwas]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38793</th>\n",
       "      <td>the grammatical</td>\n",
       "      <td>[Ġthe, Ġgram, matical]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22825</th>\n",
       "      <td>and everything</td>\n",
       "      <td>[Ġand, Ġeverything]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10301</th>\n",
       "      <td>hope so</td>\n",
       "      <td>[Ġhope, Ġso]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37083</th>\n",
       "      <td>like an idiot</td>\n",
       "      <td>[Ġlike, Ġan, Ġidiot]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46149</th>\n",
       "      <td>before you know it</td>\n",
       "      <td>[Ġbefore, Ġyou, Ġknow, Ġit]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25012</th>\n",
       "      <td>\\nbut u</td>\n",
       "      <td>[Ċ, but, Ġu]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>oneok</td>\n",
       "      <td>[Ġone, ok]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36121</th>\n",
       "      <td>. please have</td>\n",
       "      <td>[., Ġplease, Ġhave]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14833</th>\n",
       "      <td>like they</td>\n",
       "      <td>[Ġlike, Ġthey]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>here:</td>\n",
       "      <td>[Ġhere, :]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13018</th>\n",
       "      <td>of every</td>\n",
       "      <td>[Ġof, Ġevery]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8421</th>\n",
       "      <td>well im</td>\n",
       "      <td>[Ġwell, Ġim]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35544</th>\n",
       "      <td>by us troops</td>\n",
       "      <td>[Ġby, Ġus, Ġtroops]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22476</th>\n",
       "      <td>materials and</td>\n",
       "      <td>[Ġmaterials, Ġand]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>fav.</td>\n",
       "      <td>[Ġfav, .]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31422</th>\n",
       "      <td>we can get</td>\n",
       "      <td>[Ġwe, Ġcan, Ġget]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46928</th>\n",
       "      <td>kelsey\\noh</td>\n",
       "      <td>[Ġke, l, sey, Ċ, oh]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34845</th>\n",
       "      <td>we arrived.</td>\n",
       "      <td>[Ġwe, Ġarrived, .]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36786</th>\n",
       "      <td>. the children</td>\n",
       "      <td>[., Ġthe, Ġchildren]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45369</th>\n",
       "      <td>room was on the</td>\n",
       "      <td>[Ġroom, Ġwas, Ġon, Ġthe]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>mdash</td>\n",
       "      <td>[Ġm, dash]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30071</th>\n",
       "      <td>. anyway..</td>\n",
       "      <td>[., Ġanyway, ..]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        phrase  \\\n",
       "4735                                    . dear   \n",
       "16349                                purposes,   \n",
       "32389                              , thank god   \n",
       "31369                               if we meet   \n",
       "4897                                    mmm so   \n",
       "31799                               in any way   \n",
       "39397                         language models,   \n",
       "32481                              , when they   \n",
       "10751                                 which is   \n",
       "37956                           a single token   \n",
       "25872                                  . she's   \n",
       "3578                                     but a   \n",
       "38858                          reproducibility   \n",
       "36433                            , connectives   \n",
       "7547                                    as yet   \n",
       "49470   deed restrictions as soon as possible.   \n",
       "32365                               i got home   \n",
       "5932                                    terms,   \n",
       "14525                                rules are   \n",
       "10617                                  and saw   \n",
       "12452                                 i pulled   \n",
       "29571                              \\nyou would   \n",
       "30041                                she is so   \n",
       "8567                                   is well   \n",
       "22423                            hockey league   \n",
       "43091                            \\nwhat u want   \n",
       "38302                           i forgot about   \n",
       "17423                               dinner was   \n",
       "38793                          the grammatical   \n",
       "22825                           and everything   \n",
       "10301                                  hope so   \n",
       "37083                            like an idiot   \n",
       "46149                       before you know it   \n",
       "25012                                  \\nbut u   \n",
       "4743                                     oneok   \n",
       "36121                            . please have   \n",
       "14833                                like they   \n",
       "4981                                     here:   \n",
       "13018                                 of every   \n",
       "8421                                   well im   \n",
       "35544                             by us troops   \n",
       "22476                            materials and   \n",
       "2733                                      fav.   \n",
       "31422                               we can get   \n",
       "46928                               kelsey\\noh   \n",
       "34845                              we arrived.   \n",
       "36786                           . the children   \n",
       "45369                          room was on the   \n",
       "4704                                     mdash   \n",
       "30071                               . anyway..   \n",
       "\n",
       "                                                  tokens  num_tokens  \n",
       "4735                                          [., Ġdear]           2  \n",
       "16349                                     [Ġpurposes, ,]           2  \n",
       "32389                                  [,, Ġthank, Ġgod]           3  \n",
       "31369                                  [Ġif, Ġwe, Ġmeet]           3  \n",
       "4897                                          [mmm, Ġso]           2  \n",
       "31799                                  [Ġin, Ġany, Ġway]           3  \n",
       "39397                            [Ġlanguage, Ġmodels, ,]           3  \n",
       "32481                                  [,, Ġwhen, Ġthey]           3  \n",
       "10751                                      [Ġwhich, Ġis]           2  \n",
       "37956                              [Ġa, Ġsingle, Ġtoken]           3  \n",
       "25872                                      [., Ġshe, 's]           3  \n",
       "3578                                          [Ġbut, Ġa]           2  \n",
       "38858                             [Ġreprodu, c, ibility]           3  \n",
       "36433                                [,, Ġconnect, ives]           3  \n",
       "7547                                         [Ġas, Ġyet]           2  \n",
       "49470  [Ġdeed, Ġrestrictions, Ġas, Ġsoon, Ġas, Ġpossi...           7  \n",
       "32365                                  [Ġi, Ġgot, Ġhome]           3  \n",
       "5932                                         [Ġterms, ,]           2  \n",
       "14525                                     [Ġrules, Ġare]           2  \n",
       "10617                                       [Ġand, Ġsaw]           2  \n",
       "12452                                      [Ġi, Ġpulled]           2  \n",
       "29571                                   [Ċ, you, Ġwould]           3  \n",
       "30041                                   [Ġshe, Ġis, Ġso]           3  \n",
       "8567                                        [Ġis, Ġwell]           2  \n",
       "22423                                 [Ġhockey, Ġleague]           2  \n",
       "43091                               [Ċ, what, Ġu, Ġwant]           4  \n",
       "38302                              [Ġi, Ġforgot, Ġabout]           3  \n",
       "17423                                    [Ġdinner, Ġwas]           2  \n",
       "38793                             [Ġthe, Ġgram, matical]           3  \n",
       "22825                                [Ġand, Ġeverything]           2  \n",
       "10301                                       [Ġhope, Ġso]           2  \n",
       "37083                               [Ġlike, Ġan, Ġidiot]           3  \n",
       "46149                        [Ġbefore, Ġyou, Ġknow, Ġit]           4  \n",
       "25012                                       [Ċ, but, Ġu]           3  \n",
       "4743                                          [Ġone, ok]           2  \n",
       "36121                                [., Ġplease, Ġhave]           3  \n",
       "14833                                     [Ġlike, Ġthey]           2  \n",
       "4981                                          [Ġhere, :]           2  \n",
       "13018                                      [Ġof, Ġevery]           2  \n",
       "8421                                        [Ġwell, Ġim]           2  \n",
       "35544                                [Ġby, Ġus, Ġtroops]           3  \n",
       "22476                                 [Ġmaterials, Ġand]           2  \n",
       "2733                                           [Ġfav, .]           2  \n",
       "31422                                  [Ġwe, Ġcan, Ġget]           3  \n",
       "46928                               [Ġke, l, sey, Ċ, oh]           5  \n",
       "34845                                 [Ġwe, Ġarrived, .]           3  \n",
       "36786                               [., Ġthe, Ġchildren]           3  \n",
       "45369                           [Ġroom, Ġwas, Ġon, Ġthe]           4  \n",
       "4704                                          [Ġm, dash]           2  \n",
       "30071                                   [., Ġanyway, ..]           3  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tokens.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5ff28a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>’</td>\n",
       "      <td>[âĢ, Ļ]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a,</td>\n",
       "      <td>[a, ,]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-i</td>\n",
       "      <td>[-, i]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>e,</td>\n",
       "      <td>[e, ,]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>c.</td>\n",
       "      <td>[c, .]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>,i</td>\n",
       "      <td>[,, i]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>,k</td>\n",
       "      <td>[,, k]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>,s</td>\n",
       "      <td>[,, s]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>;t</td>\n",
       "      <td>[;, t]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>.i</td>\n",
       "      <td>[., i]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>;i</td>\n",
       "      <td>[;, i]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>/f</td>\n",
       "      <td>[/, f]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>'l</td>\n",
       "      <td>[', l]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>\"m</td>\n",
       "      <td>[\", m]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>e.</td>\n",
       "      <td>[e, .]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>v.</td>\n",
       "      <td>[v, .]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-d</td>\n",
       "      <td>[-, d]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>s,</td>\n",
       "      <td>[s, ,]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-n</td>\n",
       "      <td>[-, n]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-s</td>\n",
       "      <td>[-, s]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>.g</td>\n",
       "      <td>[., g]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>.k</td>\n",
       "      <td>[., k]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-h</td>\n",
       "      <td>[-, h]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-t</td>\n",
       "      <td>[-, t]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>s.</td>\n",
       "      <td>[s, .]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>k-</td>\n",
       "      <td>[k, -]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>u,</td>\n",
       "      <td>[u, ,]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>t.</td>\n",
       "      <td>[t, .]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>g,</td>\n",
       "      <td>[g, ,]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>i.</td>\n",
       "      <td>[i, .]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>n.</td>\n",
       "      <td>[n, .]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-l</td>\n",
       "      <td>[-, l]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>o-</td>\n",
       "      <td>[o, -]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-v</td>\n",
       "      <td>[-, v]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>/d</td>\n",
       "      <td>[/, d]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>y,</td>\n",
       "      <td>[y, ,]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>k.</td>\n",
       "      <td>[k, .]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>.5</td>\n",
       "      <td>[., 5]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>y\"</td>\n",
       "      <td>[y, \"]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-p</td>\n",
       "      <td>[-, p]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>s?</td>\n",
       "      <td>[s, ?]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1a</td>\n",
       "      <td>[1, a]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>y.</td>\n",
       "      <td>[y, .]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>a.</td>\n",
       "      <td>[a, .]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>i,</td>\n",
       "      <td>[i, ,]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>o,</td>\n",
       "      <td>[o, ,]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>o.</td>\n",
       "      <td>[o, .]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>-b</td>\n",
       "      <td>[-, b]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>.a</td>\n",
       "      <td>[., a]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>.4</td>\n",
       "      <td>[., 4]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phrase   tokens  num_tokens\n",
       "4       ’  [âĢ, Ļ]           2\n",
       "12     a,   [a, ,]           2\n",
       "13     -i   [-, i]           2\n",
       "16     e,   [e, ,]           2\n",
       "17     c.   [c, .]           2\n",
       "32     ,i   [,, i]           2\n",
       "33     ,k   [,, k]           2\n",
       "34     ,s   [,, s]           2\n",
       "41     ;t   [;, t]           2\n",
       "49     .i   [., i]           2\n",
       "50     ;i   [;, i]           2\n",
       "52     /f   [/, f]           2\n",
       "53     'l   [', l]           2\n",
       "54     \"m   [\", m]           2\n",
       "55     e.   [e, .]           2\n",
       "56     v.   [v, .]           2\n",
       "57     -d   [-, d]           2\n",
       "58     s,   [s, ,]           2\n",
       "59     -n   [-, n]           2\n",
       "60     -s   [-, s]           2\n",
       "62     .g   [., g]           2\n",
       "63     .k   [., k]           2\n",
       "64     -h   [-, h]           2\n",
       "65     -t   [-, t]           2\n",
       "66     s.   [s, .]           2\n",
       "68     k-   [k, -]           2\n",
       "69     u,   [u, ,]           2\n",
       "70     t.   [t, .]           2\n",
       "71     g,   [g, ,]           2\n",
       "72     i.   [i, .]           2\n",
       "73     n.   [n, .]           2\n",
       "74     -l   [-, l]           2\n",
       "75     o-   [o, -]           2\n",
       "77     -v   [-, v]           2\n",
       "78     /d   [/, d]           2\n",
       "79     y,   [y, ,]           2\n",
       "80     k.   [k, .]           2\n",
       "81     .5   [., 5]           2\n",
       "82     y\"   [y, \"]           2\n",
       "83     -p   [-, p]           2\n",
       "84     s?   [s, ?]           2\n",
       "85     1a   [1, a]           2\n",
       "86     y.   [y, .]           2\n",
       "87     a.   [a, .]           2\n",
       "88     i,   [i, ,]           2\n",
       "89     o,   [o, ,]           2\n",
       "90     o.   [o, .]           2\n",
       "91     -b   [-, b]           2\n",
       "92     .a   [., a]           2\n",
       "93     .4   [., 4]           2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tokens.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a0fdc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>’</td>\n",
       "      <td>['âĢ', 'Ļ']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\ni</td>\n",
       "      <td>['Ċ', 'i']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>?\\n</td>\n",
       "      <td>['?', 'Ċ']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\na</td>\n",
       "      <td>['Ċ', 'a']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>!\\n</td>\n",
       "      <td>['!', 'Ċ']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.\\n</td>\n",
       "      <td>['.', 'Ċ']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,</td>\n",
       "      <td>[',', 'Ġ']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\nd</td>\n",
       "      <td>['Ċ', 'd']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a,</td>\n",
       "      <td>['a', ',']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-i</td>\n",
       "      <td>['-', 'i']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'\\n</td>\n",
       "      <td>[\"'\", 'Ċ']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>.</td>\n",
       "      <td>['.', 'Ġ']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>e,</td>\n",
       "      <td>['e', ',']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>c.</td>\n",
       "      <td>['c', '.']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>y\\n</td>\n",
       "      <td>['y', 'Ċ']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\nh</td>\n",
       "      <td>['Ċ', 'h']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\nn</td>\n",
       "      <td>['Ċ', 'n']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\\ns</td>\n",
       "      <td>['Ċ', 's']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\\nu</td>\n",
       "      <td>['Ċ', 'u']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\\nw</td>\n",
       "      <td>['Ċ', 'w']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phrase       tokens  num_tokens\n",
       "4       ’  ['âĢ', 'Ļ']           2\n",
       "5     \\ni   ['Ċ', 'i']           2\n",
       "6     ?\\n   ['?', 'Ċ']           2\n",
       "7     \\na   ['Ċ', 'a']           2\n",
       "8     !\\n   ['!', 'Ċ']           2\n",
       "9     .\\n   ['.', 'Ċ']           2\n",
       "10     ,    [',', 'Ġ']           2\n",
       "11    \\nd   ['Ċ', 'd']           2\n",
       "12     a,   ['a', ',']           2\n",
       "13     -i   ['-', 'i']           2\n",
       "14    '\\n   [\"'\", 'Ċ']           2\n",
       "15     .    ['.', 'Ġ']           2\n",
       "16     e,   ['e', ',']           2\n",
       "17     c.   ['c', '.']           2\n",
       "18    y\\n   ['y', 'Ċ']           2\n",
       "19    \\nh   ['Ċ', 'h']           2\n",
       "20    \\nn   ['Ċ', 'n']           2\n",
       "21    \\ns   ['Ċ', 's']           2\n",
       "22    \\nu   ['Ċ', 'u']           2\n",
       "23    \\nw   ['Ċ', 'w']           2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tokens.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b13d419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special_tokens_map: {'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}\n",
      "all_special_tokens: ['<|endoftext|>']\n",
      "all_special_ids: [50256]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"/Volumes/BCross/models/gpt2\")\n",
    "\n",
    "print(\"special_tokens_map:\", tok.special_tokens_map)\n",
    "print(\"all_special_tokens:\", tok.all_special_tokens)\n",
    "print(\"all_special_ids:\", tok.all_special_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af261f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = distinct_special_chars(tokenizer=tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64e57968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġ', 'ĉ', 'Ċ', 'č', 'ċ']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens[0:5]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
